{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Learning Rate, Batch Size, FashionMNIST\n",
    "\n",
    "Recall cyclical learning rate policy discussed in Lecture 4. The learning rate changes in cyclical manner between lrmin and lrmax, which are hyperparameters that need to be specified. For this problem you first need to read carefully the article referenced below as you will be making use of the code there (in Keras) and modifying it as needed. For those who want to work in Pytorch there are open source implementations of this policy available which you can easily search for and build over them. You will work with FashionMNIST dataset and LeNet-5.\n",
    "\n",
    "References:\n",
    "1. Leslie N. Smith Cyclical Learning Rates for Training Neural Networks. Available at https://arxiv.org/abs/1506.01186.\n",
    "2. Keras implementation of cyclical learning rate policy. Available at https://www.pyimagesearch.com/2019/08/05/keras-\n",
    "learning-rate-finder/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Fix batch size to 64 and start with 10 candidate learning rates between 10âˆ’9 and 101 and train your model for 5 epochs for each learning rate. Plot the training loss as a function of learning rate. You should see a curve like Figure 3 in reference below. From that figure identify the values of lrmin and lrmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: /Users/aragaom/opt/anaconda3/envs/Python3\n",
      "\n",
      "Installed kernelspec python3 in /usr/local/share/jupyter/kernels/python3\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/Users/aragaom/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! conda install ipykernel --name Python3\n",
    "! python -m ipykernel install\n",
    "! pip3 install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "# initialize the list of class label names\n",
    "CLASSES = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
    "# define the minimum learning rate, maximum learning rate, batch size,\n",
    "# step size, CLR method, and number of epochs\n",
    "MIN_LR = 1e-10\n",
    "MAX_LR = 1e1\n",
    "BATCH_SIZE = 64\n",
    "STEP_SIZE = 5\n",
    "CLR_METHOD = \"triangular\"\n",
    "NUM_EPOCHS = 50\n",
    "# define the path to the output learning rate finder plot, training\n",
    "# history plot and cyclical learning rate plot\n",
    "LRFIND_PLOT_PATH = os.path.sep.join([\"output\", \"lrfind_plot.png\"])\n",
    "TRAINING_PLOT_PATH = os.path.sep.join([\"output\", \"training_plot.png\"])\n",
    "CLR_PLOT_PATH = os.path.sep.join([\"output\", \"clr_plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "\n",
    "def create_model():\n",
    "  model = models.Sequential()\n",
    "\n",
    "  model.add(layers.Conv2D(6, 5, activation='tanh', input_shape=trainX.shape[1:]))\n",
    "  model.add(layers.AveragePooling2D(2))\n",
    "\n",
    "\n",
    "  model.add(layers.Conv2D(16, 5, activation='tanh'))\n",
    "  model.add(layers.AveragePooling2D(2))\n",
    "\n",
    "  model.add(layers.Conv2D(120, 5, activation='tanh'))\n",
    "\n",
    "  model.add(layers.Flatten()) # dense layer is a linear layer and we flatten the input before putting it there.\n",
    "  model.add(layers.Dense(84, activation='tanh'))\n",
    "\n",
    "  model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# def load_data_mnist_tf(batch_size, resize=None):   \n",
    "    \n",
    "#     # load dataset\n",
    "#     mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#     # normalisation and cast as Int datatype\n",
    "#     process = lambda X, y: (tf.expand_dims(X, axis=3) / 255,tf.cast(y, dtype='int32')) \n",
    "#     # the pixel values must be personalized, so each feature has the same affect ont he output \n",
    "\n",
    "#     # resize images if resize is not None\n",
    "#     resize_fn = lambda X, y: (tf.image.resize_with_pad(X, resize, resize) if resize else X, y)\n",
    "#     # resizing of the image fucntion ?? \n",
    "\n",
    "\n",
    "#     # load train and test batches\n",
    "#     train_iter = tf.data.Dataset.from_tensor_slices(process(*mnist_train)).batch(batch_size).shuffle(len(mnist_train[0])).map(resize_fn)\n",
    "#     test_iter = tf.data.Dataset.from_tensor_slices(process(*mnist_test)).batch(batch_size).map(resize_fn)\n",
    "    \n",
    "#     return (train_iter, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST data...\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "# import matplotlib\n",
    "# matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from learningratefinder import LearningRateFinder\n",
    "from clr_callback import CyclicLR\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "# import cv2\n",
    "import sys\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-f\", \"--lr-find\", type=int, default=0,\n",
    "\thelp=\"whether or not to find optimal learning rate\")\n",
    "args, unknown = ap.parse_known_args()\n",
    "\n",
    "resize_fn = lambda X, y: (tf.image.resize_with_pad(X, resize, resize) if resize else X, y)\n",
    "# load the training and testing data\n",
    "print(\"[INFO] loading Fashion MNIST data...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "# Fashion MNIST images are 28x28 but the network we will be training\n",
    "# is expecting 32x32 images\n",
    "# trainX = np.array([tf.image.resize(x, [32,32]) for x in trainX])\n",
    "# testX = np.array([tf.image.resize(x [32,32]) for x in testX])\n",
    "# scale the pixel intensities to the range [0, 1]\n",
    "trainX = tf.pad(trainX, [[0, 0], [2,2], [2,2]])/255\n",
    "testX = tf.pad(testX, [[0, 0], [2,2], [2,2]])/255\n",
    "\n",
    "trainX = tf.expand_dims(trainX, axis=3, name=None)\n",
    "testX = tf.expand_dims(testX, axis=3, name=None)\n",
    "\n",
    "\n",
    "# reshape the data matrices to include a channel dimension (required\n",
    "# for training)\n",
    "# trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "# testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, horizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(lr_find=0)\n",
      "[INFO] finding learning rate...\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 2.3042 - accuracy: 0.0889\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 2.3040 - accuracy: 0.0904\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 26s 27ms/step - loss: 2.3041 - accuracy: 0.0891\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 2.3041 - accuracy: 0.0884\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 2.3041 - accuracy: 0.0881\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 2.3040 - accuracy: 0.0893\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 2.3039 - accuracy: 0.0903\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 2.3040 - accuracy: 0.0888\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 2.3042 - accuracy: 0.0895\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 2.3040 - accuracy: 0.0906\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 20s 22ms/step - loss: 2.3040 - accuracy: 0.0883\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 2.3040 - accuracy: 0.0901\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 2.3040 - accuracy: 0.0894\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 2.3038 - accuracy: 0.0900\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 2.3036 - accuracy: 0.0891\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 2.3031 - accuracy: 0.0895\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 2.3023 - accuracy: 0.0906\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 2.3012 - accuracy: 0.0908\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 2.2993 - accuracy: 0.0924\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 2.2961 - accuracy: 0.0936\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 2.2912 - accuracy: 0.0991\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 2.2833 - accuracy: 0.1035\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 2.2712 - accuracy: 0.1101\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 2.2516 - accuracy: 0.1253\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 20s 22ms/step - loss: 2.2156 - accuracy: 0.1923\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 2.1364 - accuracy: 0.3104\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 1.9122 - accuracy: 0.4261\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.5188 - accuracy: 0.5212\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.2735 - accuracy: 0.5747\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.1131 - accuracy: 0.6197\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.9794 - accuracy: 0.6554\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.8833 - accuracy: 0.6795\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.7916 - accuracy: 0.7053\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.7199 - accuracy: 0.7270\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.6553 - accuracy: 0.7496\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.5932 - accuracy: 0.7745\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.5423 - accuracy: 0.7920\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.5109 - accuracy: 0.8069\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.4957 - accuracy: 0.8136\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.5003 - accuracy: 0.8129\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.5445 - accuracy: 0.8008\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.6879 - accuracy: 0.7588\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 1.3491 - accuracy: 0.6153\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0126 - accuracy: 0.5329\n",
      "[INFO] learning rate finder complete\n",
      "[INFO] examine plot and adjust learning rates before training\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aragaom/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "print(args)\n",
    "if args.lr_find == 0:\n",
    "    \t# initialize the learning rate finder and then train with learning\n",
    "\t# rates ranging from 1e-10 to 1e+1\n",
    "\tprint(\"[INFO] finding learning rate...\")\n",
    "\tlrf = LearningRateFinder(model)\n",
    "\tlrf.find(\n",
    "\t\taug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "\t\t1e-10, 1e+1,\n",
    "\t\tstepsPerEpoch=np.ceil((len(trainX) / float(BATCH_SIZE))),epochs=50,\n",
    "\t\tbatchSize=BATCH_SIZE)\n",
    "\t# plot the loss for the various learning rates and save the\n",
    "\t# resulting plot to disk\n",
    "\tlrf.plot_loss()\n",
    "\tplt.savefig(\"learn_rate_finder.png\")\n",
    "\t# gracefully exit the script so we can adjust our learning rates\n",
    "\t# in the config and then train the network for our full set of\n",
    "\t# epochs\n",
    "\tprint(\"[INFO] learning rate finder complete\")\n",
    "\tprint(\"[INFO] examine plot and adjust learning rates before training\")\n",
    "\tsys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***See figure learn_rate_finder.png***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the cyclical learning rate policy (with exponential decay) and train your network using batch size 64 and lrmin and lrmax values obtained in part 1. Plot train/validation loss and accuracy curve (similar to Figure 4 in reference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer:***\n",
    "\n",
    "if you look at the learn_rate_finder.png file, you will notice that the loss starts to decrease with the learn rate 1e-5 and then spikes up after the learn rate 1e-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "MIN_LR = 1e-5\n",
    "MAX_LR = 1e-2\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(learning_rate=MIN_LR, momentum=0.9)\n",
    "model = create_model()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "937/937 [==============================] - 22s 22ms/step - loss: 1.6415 - accuracy: 0.4202 - val_loss: 0.9228 - val_accuracy: 0.6700\n",
      "Epoch 2/50\n",
      "937/937 [==============================] - 20s 22ms/step - loss: 0.8634 - accuracy: 0.6818 - val_loss: 0.7052 - val_accuracy: 0.7247\n",
      "Epoch 3/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.7005 - accuracy: 0.7338 - val_loss: 0.5840 - val_accuracy: 0.7802\n",
      "Epoch 4/50\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.6128 - accuracy: 0.7646 - val_loss: 0.5261 - val_accuracy: 0.7985\n",
      "Epoch 5/50\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.5496 - accuracy: 0.7914 - val_loss: 0.4930 - val_accuracy: 0.8094\n",
      "Epoch 6/50\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.4912 - accuracy: 0.8147 - val_loss: 0.4462 - val_accuracy: 0.8315\n",
      "Epoch 7/50\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.4496 - accuracy: 0.8324 - val_loss: 0.3957 - val_accuracy: 0.8513\n",
      "Epoch 8/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.4226 - accuracy: 0.8418 - val_loss: 0.3955 - val_accuracy: 0.8480\n",
      "Epoch 9/50\n",
      "937/937 [==============================] - 19s 21ms/step - loss: 0.4006 - accuracy: 0.8511 - val_loss: 0.3692 - val_accuracy: 0.8629\n",
      "Epoch 10/50\n",
      "937/937 [==============================] - 19s 20ms/step - loss: 0.3842 - accuracy: 0.8564 - val_loss: 0.3635 - val_accuracy: 0.8643\n",
      "Epoch 11/50\n",
      "937/937 [==============================] - 19s 20ms/step - loss: 0.3797 - accuracy: 0.8598 - val_loss: 0.3718 - val_accuracy: 0.8608\n",
      "Epoch 12/50\n",
      "937/937 [==============================] - 20s 22ms/step - loss: 0.3880 - accuracy: 0.8557 - val_loss: 0.3745 - val_accuracy: 0.8602\n",
      "Epoch 13/50\n",
      "937/937 [==============================] - 20s 22ms/step - loss: 0.3908 - accuracy: 0.8538 - val_loss: 0.3970 - val_accuracy: 0.8491\n",
      "Epoch 14/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3944 - accuracy: 0.8513 - val_loss: 0.3608 - val_accuracy: 0.8594\n",
      "Epoch 15/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3955 - accuracy: 0.8506 - val_loss: 0.3622 - val_accuracy: 0.8656\n",
      "Epoch 16/50\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.3836 - accuracy: 0.8566 - val_loss: 0.3626 - val_accuracy: 0.8655\n",
      "Epoch 17/50\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.3641 - accuracy: 0.8627 - val_loss: 0.3361 - val_accuracy: 0.8726\n",
      "Epoch 18/50\n",
      "937/937 [==============================] - 21s 22ms/step - loss: 0.3494 - accuracy: 0.8694 - val_loss: 0.3294 - val_accuracy: 0.8765\n",
      "Epoch 19/50\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3357 - accuracy: 0.8746 - val_loss: 0.3277 - val_accuracy: 0.8763\n",
      "Epoch 20/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3254 - accuracy: 0.8789 - val_loss: 0.3194 - val_accuracy: 0.8811\n",
      "Epoch 21/50\n",
      "937/937 [==============================] - 21s 23ms/step - loss: 0.3216 - accuracy: 0.8803 - val_loss: 0.3243 - val_accuracy: 0.8774\n",
      "Epoch 22/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3309 - accuracy: 0.8770 - val_loss: 0.3399 - val_accuracy: 0.8745\n",
      "Epoch 23/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3369 - accuracy: 0.8734 - val_loss: 0.3336 - val_accuracy: 0.8752\n",
      "Epoch 24/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3471 - accuracy: 0.8695 - val_loss: 0.3476 - val_accuracy: 0.8666\n",
      "Epoch 25/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3484 - accuracy: 0.8694 - val_loss: 0.3398 - val_accuracy: 0.8730\n",
      "Epoch 26/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3430 - accuracy: 0.8724 - val_loss: 0.3298 - val_accuracy: 0.8756\n",
      "Epoch 27/50\n",
      "937/937 [==============================] - 19s 21ms/step - loss: 0.3327 - accuracy: 0.8753 - val_loss: 0.3150 - val_accuracy: 0.8810\n",
      "Epoch 28/50\n",
      "937/937 [==============================] - 23s 24ms/step - loss: 0.3176 - accuracy: 0.8814 - val_loss: 0.3179 - val_accuracy: 0.8815\n",
      "Epoch 29/50\n",
      "937/937 [==============================] - 23s 24ms/step - loss: 0.3064 - accuracy: 0.8839 - val_loss: 0.3035 - val_accuracy: 0.8857\n",
      "Epoch 30/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.2982 - accuracy: 0.8882 - val_loss: 0.2984 - val_accuracy: 0.8909\n",
      "Epoch 31/50\n",
      "937/937 [==============================] - 21s 22ms/step - loss: 0.2967 - accuracy: 0.8884 - val_loss: 0.3024 - val_accuracy: 0.8886\n",
      "Epoch 32/50\n",
      "937/937 [==============================] - 21s 22ms/step - loss: 0.3040 - accuracy: 0.8857 - val_loss: 0.3015 - val_accuracy: 0.8892\n",
      "Epoch 33/50\n",
      "937/937 [==============================] - 20s 22ms/step - loss: 0.3129 - accuracy: 0.8833 - val_loss: 0.3140 - val_accuracy: 0.8821\n",
      "Epoch 34/50\n",
      "937/937 [==============================] - 21s 22ms/step - loss: 0.3174 - accuracy: 0.8815 - val_loss: 0.3066 - val_accuracy: 0.8864\n",
      "Epoch 35/50\n",
      "937/937 [==============================] - 20s 22ms/step - loss: 0.3276 - accuracy: 0.8775 - val_loss: 0.3220 - val_accuracy: 0.8801\n",
      "Epoch 36/50\n",
      "937/937 [==============================] - 21s 22ms/step - loss: 0.3239 - accuracy: 0.8794 - val_loss: 0.3047 - val_accuracy: 0.8855\n",
      "Epoch 37/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.3092 - accuracy: 0.8840 - val_loss: 0.3072 - val_accuracy: 0.8867\n",
      "Epoch 38/50\n",
      "937/937 [==============================] - 23s 24ms/step - loss: 0.3016 - accuracy: 0.8877 - val_loss: 0.2998 - val_accuracy: 0.8908\n",
      "Epoch 39/50\n",
      "937/937 [==============================] - 23s 24ms/step - loss: 0.2911 - accuracy: 0.8906 - val_loss: 0.2940 - val_accuracy: 0.8912\n",
      "Epoch 40/50\n",
      "937/937 [==============================] - 22s 24ms/step - loss: 0.2797 - accuracy: 0.8955 - val_loss: 0.2860 - val_accuracy: 0.8943\n",
      "Epoch 41/50\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.2784 - accuracy: 0.8963 - val_loss: 0.2882 - val_accuracy: 0.8939\n",
      "Epoch 42/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.2859 - accuracy: 0.8927 - val_loss: 0.3026 - val_accuracy: 0.8877\n",
      "Epoch 43/50\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2939 - accuracy: 0.8908 - val_loss: 0.2933 - val_accuracy: 0.8895\n",
      "Epoch 44/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.3005 - accuracy: 0.8874 - val_loss: 0.3199 - val_accuracy: 0.8786\n",
      "Epoch 45/50\n",
      "937/937 [==============================] - 21s 23ms/step - loss: 0.3113 - accuracy: 0.8824 - val_loss: 0.3160 - val_accuracy: 0.8809\n",
      "Epoch 46/50\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.3078 - accuracy: 0.8850 - val_loss: 0.2991 - val_accuracy: 0.8853\n",
      "Epoch 47/50\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.2947 - accuracy: 0.8889 - val_loss: 0.3038 - val_accuracy: 0.8885\n",
      "Epoch 48/50\n",
      "937/937 [==============================] - 23s 24ms/step - loss: 0.2851 - accuracy: 0.8931 - val_loss: 0.2921 - val_accuracy: 0.8920\n",
      "Epoch 49/50\n",
      "937/937 [==============================] - 23s 24ms/step - loss: 0.2757 - accuracy: 0.8972 - val_loss: 0.2776 - val_accuracy: 0.8964\n",
      "Epoch 50/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.2683 - accuracy: 0.9002 - val_loss: 0.2764 - val_accuracy: 0.8977\n",
      "[INFO] evaluating network...\n",
      "157/157 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.84      0.85      0.85      1000\n",
      "     trouser       0.99      0.97      0.98      1000\n",
      "    pullover       0.82      0.85      0.83      1000\n",
      "       dress       0.89      0.92      0.90      1000\n",
      "        coat       0.82      0.82      0.82      1000\n",
      "      sandal       0.98      0.97      0.97      1000\n",
      "       shirt       0.74      0.69      0.71      1000\n",
      "     sneaker       0.93      0.97      0.95      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.98      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stepSize = STEP_SIZE * (trainX.shape[0] // BATCH_SIZE)\n",
    "clr = CyclicLR(\n",
    "\tmode=CLR_METHOD,\n",
    "\tbase_lr=MIN_LR,\n",
    "\tmax_lr=MAX_LR,\n",
    "\tstep_size=stepSize)\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(\n",
    "\tx=aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=trainX.shape[0] // BATCH_SIZE,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tcallbacks=[clr],\n",
    "\tverbose=1)\n",
    "# evaluate the network and show a classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX, batch_size=BATCH_SIZE)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.arange(0, NUM_EPOCHS)\n",
    "# plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"training_plot.png\")\n",
    "# plot the learning rate history\n",
    "N = np.arange(0, len(clr.history[\"lr\"]))\n",
    "plt.figure()\n",
    "plt.plot(N, clr.history[\"lr\"])\n",
    "plt.title(\"Cyclical Learning Rate (CLR)\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.savefig(\"crl_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We want to test if increasing batch size for a fixed learning rate has the same effect as decreasing learning rate for a fixed batch size. Fix learning rate to lrmax and train your network starting with batch size 32 and incrementally going upto 4096 (in increments of a factor of 2; like 32, 64...). You can choose a step size (in terms of number of epochs) to increment the batch size. Plot the training loss vs. log2(batch size). Is the generalization of your final model similar or different than cyclical learning rate policy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Answer:***\n",
    "\n",
    "Very very similar, but the biggest trade-off is that by increasing the batches I reduce training time by almost 25% of the time spent with the cyclical learning rate, possibly, because as we increase the batch, we need fewer iterations at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.7799 - accuracy: 0.7033 - val_loss: 0.5456 - val_accuracy: 0.7917\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.5524 - accuracy: 0.7894 - val_loss: 0.5259 - val_accuracy: 0.8023\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4855 - accuracy: 0.8187 - val_loss: 0.4129 - val_accuracy: 0.8428\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4445 - accuracy: 0.8338 - val_loss: 0.4283 - val_accuracy: 0.8403\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4210 - accuracy: 0.8427 - val_loss: 0.3864 - val_accuracy: 0.8526\n",
      "[INFO] evaluating network...\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.80      0.81      0.80      1000\n",
      "     trouser       0.98      0.97      0.98      1000\n",
      "    pullover       0.86      0.62      0.72      1000\n",
      "       dress       0.85      0.91      0.88      1000\n",
      "        coat       0.67      0.88      0.76      1000\n",
      "      sandal       0.94      0.95      0.95      1000\n",
      "       shirt       0.66      0.57      0.61      1000\n",
      "     sneaker       0.94      0.90      0.92      1000\n",
      "         bag       0.96      0.96      0.96      1000\n",
      "  ankle boot       0.91      0.96      0.93      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "937/937 [==============================] - 18s 20ms/step - loss: 0.3747 - accuracy: 0.8603 - val_loss: 0.3624 - val_accuracy: 0.8644\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 20s 21ms/step - loss: 0.3638 - accuracy: 0.8638 - val_loss: 0.3497 - val_accuracy: 0.8715\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 20s 22ms/step - loss: 0.3553 - accuracy: 0.8678 - val_loss: 0.3425 - val_accuracy: 0.8775\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 21s 23ms/step - loss: 0.3518 - accuracy: 0.8695 - val_loss: 0.3630 - val_accuracy: 0.8643\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 21s 23ms/step - loss: 0.3458 - accuracy: 0.8706 - val_loss: 0.3474 - val_accuracy: 0.8711\n",
      "[INFO] evaluating network...\n",
      "157/157 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.81      0.83      0.82      1000\n",
      "     trouser       0.98      0.98      0.98      1000\n",
      "    pullover       0.79      0.81      0.80      1000\n",
      "       dress       0.89      0.88      0.89      1000\n",
      "        coat       0.75      0.84      0.79      1000\n",
      "      sandal       0.98      0.89      0.93      1000\n",
      "       shirt       0.72      0.60      0.66      1000\n",
      "     sneaker       0.86      0.98      0.92      1000\n",
      "         bag       0.98      0.97      0.97      1000\n",
      "  ankle boot       0.97      0.93      0.95      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "468/468 [==============================] - 22s 47ms/step - loss: 0.3265 - accuracy: 0.8782 - val_loss: 0.3368 - val_accuracy: 0.8733\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 22s 47ms/step - loss: 0.3229 - accuracy: 0.8788 - val_loss: 0.3228 - val_accuracy: 0.8791\n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 25s 53ms/step - loss: 0.3214 - accuracy: 0.8806 - val_loss: 0.3268 - val_accuracy: 0.8793\n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 23s 49ms/step - loss: 0.3164 - accuracy: 0.8815 - val_loss: 0.3118 - val_accuracy: 0.8844\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 24s 50ms/step - loss: 0.3159 - accuracy: 0.8811 - val_loss: 0.3079 - val_accuracy: 0.8886\n",
      "[INFO] evaluating network...\n",
      "79/79 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.78      0.89      0.83      1000\n",
      "     trouser       0.99      0.97      0.98      1000\n",
      "    pullover       0.83      0.81      0.82      1000\n",
      "       dress       0.89      0.91      0.90      1000\n",
      "        coat       0.81      0.82      0.82      1000\n",
      "      sandal       0.97      0.96      0.96      1000\n",
      "       shirt       0.75      0.64      0.69      1000\n",
      "     sneaker       0.95      0.94      0.94      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.95      0.96      0.95      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "234/234 [==============================] - 23s 99ms/step - loss: 0.3011 - accuracy: 0.8870 - val_loss: 0.3068 - val_accuracy: 0.8879\n",
      "Epoch 2/5\n",
      "234/234 [==============================] - 25s 106ms/step - loss: 0.3026 - accuracy: 0.8877 - val_loss: 0.3095 - val_accuracy: 0.8842\n",
      "Epoch 3/5\n",
      "234/234 [==============================] - 23s 96ms/step - loss: 0.2999 - accuracy: 0.8879 - val_loss: 0.3031 - val_accuracy: 0.8874\n",
      "Epoch 4/5\n",
      "234/234 [==============================] - 21s 92ms/step - loss: 0.2983 - accuracy: 0.8882 - val_loss: 0.3170 - val_accuracy: 0.8818\n",
      "Epoch 5/5\n",
      "234/234 [==============================] - 22s 93ms/step - loss: 0.2969 - accuracy: 0.8890 - val_loss: 0.3027 - val_accuracy: 0.8857\n",
      "[INFO] evaluating network...\n",
      "40/40 [==============================] - 1s 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.83      0.82      0.83      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.77      0.86      0.81      1000\n",
      "       dress       0.87      0.92      0.89      1000\n",
      "        coat       0.85      0.74      0.79      1000\n",
      "      sandal       0.96      0.97      0.96      1000\n",
      "       shirt       0.71      0.69      0.70      1000\n",
      "     sneaker       0.94      0.96      0.95      1000\n",
      "         bag       0.98      0.97      0.98      1000\n",
      "  ankle boot       0.97      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "117/117 [==============================] - 21s 182ms/step - loss: 0.2918 - accuracy: 0.8918 - val_loss: 0.2995 - val_accuracy: 0.8888\n",
      "Epoch 2/5\n",
      "117/117 [==============================] - 23s 199ms/step - loss: 0.2931 - accuracy: 0.8905 - val_loss: 0.2957 - val_accuracy: 0.8915\n",
      "Epoch 3/5\n",
      "117/117 [==============================] - 24s 206ms/step - loss: 0.2902 - accuracy: 0.8914 - val_loss: 0.3016 - val_accuracy: 0.8874\n",
      "Epoch 4/5\n",
      "117/117 [==============================] - 25s 211ms/step - loss: 0.2898 - accuracy: 0.8931 - val_loss: 0.2968 - val_accuracy: 0.8899\n",
      "Epoch 5/5\n",
      "117/117 [==============================] - 22s 187ms/step - loss: 0.2889 - accuracy: 0.8923 - val_loss: 0.3004 - val_accuracy: 0.8904\n",
      "[INFO] evaluating network...\n",
      "20/20 [==============================] - 1s 31ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.86      0.84      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.80      0.84      0.82      1000\n",
      "       dress       0.89      0.91      0.90      1000\n",
      "        coat       0.79      0.83      0.81      1000\n",
      "      sandal       0.98      0.95      0.97      1000\n",
      "       shirt       0.77      0.63      0.69      1000\n",
      "     sneaker       0.92      0.98      0.95      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.97      0.94      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.2848 - accuracy: 0.8949 - val_loss: 0.2964 - val_accuracy: 0.8903\n",
      "Epoch 2/5\n",
      "58/58 [==============================] - 22s 371ms/step - loss: 0.2843 - accuracy: 0.8937 - val_loss: 0.2940 - val_accuracy: 0.8922\n",
      "Epoch 3/5\n",
      "58/58 [==============================] - 21s 355ms/step - loss: 0.2863 - accuracy: 0.8927 - val_loss: 0.2934 - val_accuracy: 0.8919\n",
      "Epoch 4/5\n",
      "58/58 [==============================] - 24s 407ms/step - loss: 0.2856 - accuracy: 0.8934 - val_loss: 0.2951 - val_accuracy: 0.8890\n",
      "Epoch 5/5\n",
      "58/58 [==============================] - 23s 384ms/step - loss: 0.2818 - accuracy: 0.8963 - val_loss: 0.2942 - val_accuracy: 0.8905\n",
      "[INFO] evaluating network...\n",
      "10/10 [==============================] - 1s 62ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.85      0.84      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.79      0.85      0.82      1000\n",
      "       dress       0.90      0.90      0.90      1000\n",
      "        coat       0.81      0.81      0.81      1000\n",
      "      sandal       0.96      0.97      0.97      1000\n",
      "       shirt       0.75      0.65      0.69      1000\n",
      "     sneaker       0.94      0.96      0.95      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.96      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "29/29 [==============================] - 22s 787ms/step - loss: 0.2824 - accuracy: 0.8948 - val_loss: 0.2923 - val_accuracy: 0.8906\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 26s 900ms/step - loss: 0.2820 - accuracy: 0.8949 - val_loss: 0.2914 - val_accuracy: 0.8922\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 23s 771ms/step - loss: 0.2811 - accuracy: 0.8964 - val_loss: 0.2909 - val_accuracy: 0.8921\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 24s 808ms/step - loss: 0.2804 - accuracy: 0.8969 - val_loss: 0.2925 - val_accuracy: 0.8917\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 29s 998ms/step - loss: 0.2795 - accuracy: 0.8966 - val_loss: 0.2917 - val_accuracy: 0.8912\n",
      "[INFO] evaluating network...\n",
      "5/5 [==============================] - 1s 128ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.85      0.84      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.82      0.83      0.82      1000\n",
      "       dress       0.90      0.90      0.90      1000\n",
      "        coat       0.80      0.83      0.81      1000\n",
      "      sandal       0.97      0.96      0.97      1000\n",
      "       shirt       0.74      0.66      0.70      1000\n",
      "     sneaker       0.94      0.97      0.95      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.97      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 20s 1s/step - loss: 0.2809 - accuracy: 0.8951 - val_loss: 0.2918 - val_accuracy: 0.8923\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.2797 - accuracy: 0.8950 - val_loss: 0.2908 - val_accuracy: 0.8918\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.2805 - accuracy: 0.8971 - val_loss: 0.2909 - val_accuracy: 0.8927\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.2817 - accuracy: 0.8951 - val_loss: 0.2909 - val_accuracy: 0.8927\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.2801 - accuracy: 0.8967 - val_loss: 0.2906 - val_accuracy: 0.8918\n",
      "[INFO] evaluating network...\n",
      "3/3 [==============================] - 1s 186ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.86      0.84      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.81      0.84      0.82      1000\n",
      "       dress       0.89      0.91      0.90      1000\n",
      "        coat       0.81      0.81      0.81      1000\n",
      "      sandal       0.97      0.96      0.97      1000\n",
      "       shirt       0.75      0.67      0.71      1000\n",
      "     sneaker       0.94      0.96      0.95      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.97      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = 32\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(learning_rate=MAX_LR, momentum=0.9)\n",
    "model = create_model()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "loss = []\n",
    "batches = []\n",
    "\n",
    "while batch <=4096:\n",
    "    print(\"[INFO] training network...\")\n",
    "    H_b = model.fit(\n",
    "\tx=aug.flow(trainX, trainY, batch_size=batch),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=trainX.shape[0] // batch,\n",
    "\tepochs=5,\n",
    "\t# callbacks=[clr],\n",
    "\tverbose=1)\n",
    "    # evaluate the network and show a classification report\n",
    "    print(\"[INFO] evaluating network...\")\n",
    "    predictions = model.predict(x=testX, batch_size=batch)\n",
    "    print(classification_report(testY.argmax(axis=1),\n",
    "        predictions.argmax(axis=1), target_names=CLASSES))\n",
    "    \n",
    "    loss.append(H_b.history[\"loss\"][-1])\n",
    "    batches.append(batch)\n",
    "    \n",
    "    # updating the batch size\n",
    "    batch*=2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(batches, loss)\n",
    "plt.title(\"Batches vs loss\")\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.savefig(\"batches_loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0f08725565d2d00e70b9fae99b105541271f7be4baa13607a6e77e1d2c8c73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
