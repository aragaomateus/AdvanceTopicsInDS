{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Learning Rate, Batch Size, FashionMNIST\n",
    "\n",
    "Recall cyclical learning rate policy discussed in Lecture 4. The learning rate changes in cyclical manner between lrmin and lrmax, which are hyperparameters that need to be specified. For this problem you first need to read carefully the article referenced below as you will be making use of the code there (in Keras) and modifying it as needed. For those who want to work in Pytorch there are open source implementations of this policy available which you can easily search for and build over them. You will work with FashionMNIST dataset and LeNet-5.\n",
    "\n",
    "References:\n",
    "1. Leslie N. Smith Cyclical Learning Rates for Training Neural Networks. Available at https://arxiv.org/abs/1506.01186.\n",
    "2. Keras implementation of cyclical learning rate policy. Available at https://www.pyimagesearch.com/2019/08/05/keras-\n",
    "learning-rate-finder/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Fix batch size to 64 and start with 10 candidate learning rates between 10âˆ’9 and 101 and train your model for 5 epochs for each learning rate. Plot the training loss as a function of learning rate. You should see a curve like Figure 3 in reference below. From that figure identify the values of lrmin and lrmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentLocationNotFound: Not a conda environment: /Users/aragaom/opt/anaconda3/envs/Python3\n",
      "\n",
      "Installed kernelspec python3 in /usr/local/share/jupyter/kernels/python3\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/Users/aragaom/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! conda install ipykernel --name Python3\n",
    "! python -m ipykernel install\n",
    "! pip3 install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "# initialize the list of class label names\n",
    "CLASSES = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
    "# define the minimum learning rate, maximum learning rate, batch size,\n",
    "# step size, CLR method, and number of epochs\n",
    "MIN_LR = 1e-10\n",
    "MAX_LR = 1e1\n",
    "BATCH_SIZE = 64\n",
    "STEP_SIZE = 5\n",
    "CLR_METHOD = \"triangular\"\n",
    "NUM_EPOCHS = 50\n",
    "# define the path to the output learning rate finder plot, training\n",
    "# history plot and cyclical learning rate plot\n",
    "LRFIND_PLOT_PATH = os.path.sep.join([\"output\", \"lrfind_plot.png\"])\n",
    "TRAINING_PLOT_PATH = os.path.sep.join([\"output\", \"training_plot.png\"])\n",
    "CLR_PLOT_PATH = os.path.sep.join([\"output\", \"clr_plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "\n",
    "def create_model():\n",
    "  model = models.Sequential()\n",
    "\n",
    "  model.add(layers.Conv2D(6, 5, activation='tanh', input_shape=trainX.shape[1:]))\n",
    "  model.add(layers.AveragePooling2D(2))\n",
    "\n",
    "\n",
    "  model.add(layers.Conv2D(16, 5, activation='tanh'))\n",
    "  model.add(layers.AveragePooling2D(2))\n",
    "\n",
    "  model.add(layers.Conv2D(120, 5, activation='tanh'))\n",
    "\n",
    "  model.add(layers.Flatten()) # dense layer is a linear layer and we flatten the input before putting it there.\n",
    "  model.add(layers.Dense(84, activation='tanh'))\n",
    "\n",
    "  model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def load_data_mnist_tf(batch_size, resize=None):   \n",
    "    \n",
    "    # load dataset\n",
    "    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # normalisation and cast as Int datatype\n",
    "    process = lambda X, y: (tf.expand_dims(X, axis=3) / 255,tf.cast(y, dtype='int32')) \n",
    "    # the pixel values must be personalized, so each feature has the same affect ont he output \n",
    "\n",
    "    # resize images if resize is not None\n",
    "    resize_fn = lambda X, y: (tf.image.resize_with_pad(X, resize, resize) if resize else X, y)\n",
    "    # resizing of the image fucntion ?? \n",
    "\n",
    "\n",
    "    # load train and test batches\n",
    "    train_iter = tf.data.Dataset.from_tensor_slices(process(*mnist_train)).batch(batch_size).shuffle(len(mnist_train[0])).map(resize_fn)\n",
    "    test_iter = tf.data.Dataset.from_tensor_slices(process(*mnist_test)).batch(batch_size).map(resize_fn)\n",
    "    \n",
    "    return (train_iter, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST data...\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "# import matplotlib\n",
    "# matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from learningratefinder import LearningRateFinder\n",
    "from clr_callback import CyclicLR\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "# import cv2\n",
    "import sys\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-f\", \"--lr-find\", type=int, default=0,\n",
    "\thelp=\"whether or not to find optimal learning rate\")\n",
    "args, unknown = ap.parse_known_args()\n",
    "resize_fn = lambda X, y: (tf.image.resize_with_pad(X, resize, resize) if resize else X, y)\n",
    "# load the training and testing data\n",
    "print(\"[INFO] loading Fashion MNIST data...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "# Fashion MNIST images are 28x28 but the network we will be training\n",
    "# is expecting 32x32 images\n",
    "# trainX = np.array([tf.image.resize(x, [32,32]) for x in trainX])\n",
    "# testX = np.array([tf.image.resize(x [32,32]) for x in testX])\n",
    "# scale the pixel intensities to the range [0, 1]\n",
    "trainX = tf.pad(trainX, [[0, 0], [2,2], [2,2]])/255\n",
    "testX = tf.pad(testX, [[0, 0], [2,2], [2,2]])/255\n",
    "\n",
    "trainX = tf.expand_dims(trainX, axis=3, name=None)\n",
    "testX = tf.expand_dims(testX, axis=3, name=None)\n",
    "\n",
    "\n",
    "# reshape the data matrices to include a channel dimension (required\n",
    "# for training)\n",
    "# trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "# testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, horizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(lr_find=0)\n",
      "[INFO] finding learning rate...\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 2.3042 - accuracy: 0.0889\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 2.3040 - accuracy: 0.0904\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 26s 27ms/step - loss: 2.3041 - accuracy: 0.0891\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 2.3041 - accuracy: 0.0884\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 2.3041 - accuracy: 0.0881\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 2.3040 - accuracy: 0.0893\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 2.3039 - accuracy: 0.0903\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 2.3040 - accuracy: 0.0888\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 2.3042 - accuracy: 0.0895\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 2.3040 - accuracy: 0.0906\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 20s 22ms/step - loss: 2.3040 - accuracy: 0.0883\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 2.3040 - accuracy: 0.0901\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 2.3040 - accuracy: 0.0894\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 2.3038 - accuracy: 0.0900\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 19s 21ms/step - loss: 2.3036 - accuracy: 0.0891\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 2.3031 - accuracy: 0.0895\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 2.3023 - accuracy: 0.0906\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 2.3012 - accuracy: 0.0908\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 2.2993 - accuracy: 0.0924\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 2.2961 - accuracy: 0.0936\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 2.2912 - accuracy: 0.0991\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 2.2833 - accuracy: 0.1035\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 2.2712 - accuracy: 0.1101\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 2.2516 - accuracy: 0.1253\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 20s 22ms/step - loss: 2.2156 - accuracy: 0.1923\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 2.1364 - accuracy: 0.3104\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 22s 23ms/step - loss: 1.9122 - accuracy: 0.4261\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.5188 - accuracy: 0.5212\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 1.2735 - accuracy: 0.5747\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 1.1131 - accuracy: 0.6197\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.9794 - accuracy: 0.6554\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.8833 - accuracy: 0.6795\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 21s 23ms/step - loss: 0.7916 - accuracy: 0.7053\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.7199 - accuracy: 0.7270\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.6553 - accuracy: 0.7496\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 21s 22ms/step - loss: 0.5932 - accuracy: 0.7745\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.5423 - accuracy: 0.7920\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.5109 - accuracy: 0.8069\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.4957 - accuracy: 0.8136\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 22s 24ms/step - loss: 0.5003 - accuracy: 0.8129\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.5445 - accuracy: 0.8008\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.6879 - accuracy: 0.7588\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 1.3491 - accuracy: 0.6153\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 2.0126 - accuracy: 0.5329\n",
      "[INFO] learning rate finder complete\n",
      "[INFO] examine plot and adjust learning rates before training\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aragaom/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "print(args)\n",
    "if args.lr_find == 0:\n",
    "    \t# initialize the learning rate finder and then train with learning\n",
    "\t# rates ranging from 1e-10 to 1e+1\n",
    "\tprint(\"[INFO] finding learning rate...\")\n",
    "\tlrf = LearningRateFinder(model)\n",
    "\tlrf.find(\n",
    "\t\taug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "\t\t1e-10, 1e+1,\n",
    "\t\tstepsPerEpoch=np.ceil((len(trainX) / float(BATCH_SIZE))),epochs=50,\n",
    "\t\tbatchSize=BATCH_SIZE)\n",
    "\t# plot the loss for the various learning rates and save the\n",
    "\t# resulting plot to disk\n",
    "\tlrf.plot_loss()\n",
    "\tplt.savefig(\"learn_rate_finder.png\")\n",
    "\t# gracefully exit the script so we can adjust our learning rates\n",
    "\t# in the config and then train the network for our full set of\n",
    "\t# epochs\n",
    "\tprint(\"[INFO] learning rate finder complete\")\n",
    "\tprint(\"[INFO] examine plot and adjust learning rates before training\")\n",
    "\tsys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***See figure learn_rate_finder.png***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the cyclical learning rate policy (with exponential decay) and train your network using batch size 64 and lrmin and lrmax values obtained in part 1. Plot train/validation loss and accuracy curve (similar to Figure 4 in reference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer:***\n",
    "\n",
    "if you look at the learn_rate_finder.png file, you will notice that the loss starts to decrease with the learn rate 1e-5 and then spikes up after the learn rate 1e-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "MIN_LR = 1e-5\n",
    "MAX_LR = 1e-2\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(learning_rate=MIN_LR, momentum=0.9)\n",
    "model = create_model()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/50\n",
      "937/937 [==============================] - 28s 28ms/step - loss: 1.6449 - accuracy: 0.4163 - val_loss: 0.9263 - val_accuracy: 0.6548\n",
      "Epoch 2/50\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.8516 - accuracy: 0.6863 - val_loss: 0.6863 - val_accuracy: 0.7406\n",
      "Epoch 3/50\n",
      "937/937 [==============================] - 34s 36ms/step - loss: 0.6982 - accuracy: 0.7343 - val_loss: 0.6353 - val_accuracy: 0.7449\n",
      "Epoch 4/50\n",
      "937/937 [==============================] - 32s 34ms/step - loss: 0.6155 - accuracy: 0.7632 - val_loss: 0.5626 - val_accuracy: 0.7834\n",
      "Epoch 5/50\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.5562 - accuracy: 0.7887 - val_loss: 0.4831 - val_accuracy: 0.8180\n",
      "Epoch 6/50\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.5031 - accuracy: 0.8106 - val_loss: 0.4526 - val_accuracy: 0.8291\n",
      "Epoch 7/50\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.4618 - accuracy: 0.8280 - val_loss: 0.4307 - val_accuracy: 0.8368\n",
      "Epoch 8/50\n",
      "937/937 [==============================] - 30s 31ms/step - loss: 0.4324 - accuracy: 0.8386 - val_loss: 0.4050 - val_accuracy: 0.8479\n",
      "Epoch 9/50\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.4067 - accuracy: 0.8487 - val_loss: 0.3830 - val_accuracy: 0.8542\n",
      "Epoch 10/50\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.3914 - accuracy: 0.8544 - val_loss: 0.3738 - val_accuracy: 0.8579\n",
      "Epoch 11/50\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.3882 - accuracy: 0.8553 - val_loss: 0.3859 - val_accuracy: 0.8538\n",
      "Epoch 12/50\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.3942 - accuracy: 0.8525 - val_loss: 0.3765 - val_accuracy: 0.8578\n",
      "Epoch 13/50\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.4025 - accuracy: 0.8501 - val_loss: 0.3942 - val_accuracy: 0.8515\n",
      "Epoch 14/50\n",
      "937/937 [==============================] - 26s 27ms/step - loss: 0.4035 - accuracy: 0.8494 - val_loss: 0.3892 - val_accuracy: 0.8493\n",
      "Epoch 15/50\n",
      "937/937 [==============================] - 29s 30ms/step - loss: 0.4040 - accuracy: 0.8491 - val_loss: 0.3692 - val_accuracy: 0.8618\n",
      "Epoch 16/50\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.3929 - accuracy: 0.8521 - val_loss: 0.3594 - val_accuracy: 0.8674\n",
      "Epoch 17/50\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3726 - accuracy: 0.8606 - val_loss: 0.3523 - val_accuracy: 0.8665\n",
      "Epoch 18/50\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.3575 - accuracy: 0.8665 - val_loss: 0.3459 - val_accuracy: 0.8671\n",
      "Epoch 19/50\n",
      "937/937 [==============================] - 27s 28ms/step - loss: 0.3411 - accuracy: 0.8741 - val_loss: 0.3312 - val_accuracy: 0.8767\n",
      "Epoch 20/50\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3323 - accuracy: 0.8769 - val_loss: 0.3226 - val_accuracy: 0.8790\n",
      "Epoch 21/50\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3263 - accuracy: 0.8792 - val_loss: 0.3284 - val_accuracy: 0.8767\n",
      "Epoch 22/50\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3366 - accuracy: 0.8737 - val_loss: 0.3468 - val_accuracy: 0.8683\n",
      "Epoch 23/50\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.3467 - accuracy: 0.8706 - val_loss: 0.3484 - val_accuracy: 0.8680\n",
      "Epoch 24/50\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3512 - accuracy: 0.8694 - val_loss: 0.3465 - val_accuracy: 0.8745\n",
      "Epoch 25/50\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3586 - accuracy: 0.8662 - val_loss: 0.3371 - val_accuracy: 0.8751\n",
      "Epoch 26/50\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.3516 - accuracy: 0.8690 - val_loss: 0.3385 - val_accuracy: 0.8698\n",
      "Epoch 27/50\n",
      "937/937 [==============================] - 29s 31ms/step - loss: 0.3376 - accuracy: 0.8727 - val_loss: 0.3239 - val_accuracy: 0.8799\n",
      "Epoch 28/50\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.3263 - accuracy: 0.8782 - val_loss: 0.3136 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.3138 - accuracy: 0.8824 - val_loss: 0.3106 - val_accuracy: 0.8818\n",
      "Epoch 30/50\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.3043 - accuracy: 0.8869 - val_loss: 0.2989 - val_accuracy: 0.8857\n",
      "Epoch 31/50\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.3000 - accuracy: 0.8877 - val_loss: 0.3107 - val_accuracy: 0.8829\n",
      "Epoch 32/50\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.3075 - accuracy: 0.8861 - val_loss: 0.3265 - val_accuracy: 0.8751\n",
      "Epoch 33/50\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.3173 - accuracy: 0.8807 - val_loss: 0.3164 - val_accuracy: 0.8797\n",
      "Epoch 34/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.3270 - accuracy: 0.8779 - val_loss: 0.3197 - val_accuracy: 0.8795\n",
      "Epoch 35/50\n",
      "937/937 [==============================] - 21s 23ms/step - loss: 0.3300 - accuracy: 0.8763 - val_loss: 0.3325 - val_accuracy: 0.8765\n",
      "Epoch 36/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.3303 - accuracy: 0.8756 - val_loss: 0.3233 - val_accuracy: 0.8761\n",
      "Epoch 37/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.3191 - accuracy: 0.8802 - val_loss: 0.3194 - val_accuracy: 0.8803\n",
      "Epoch 38/50\n",
      "937/937 [==============================] - 21s 23ms/step - loss: 0.3048 - accuracy: 0.8856 - val_loss: 0.3051 - val_accuracy: 0.8840\n",
      "Epoch 39/50\n",
      "937/937 [==============================] - 22s 23ms/step - loss: 0.2941 - accuracy: 0.8898 - val_loss: 0.3002 - val_accuracy: 0.8855\n",
      "Epoch 40/50\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.2848 - accuracy: 0.8933 - val_loss: 0.2885 - val_accuracy: 0.8902\n",
      "Epoch 41/50\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2838 - accuracy: 0.8946 - val_loss: 0.2947 - val_accuracy: 0.8887\n",
      "Epoch 42/50\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.2921 - accuracy: 0.8904 - val_loss: 0.2942 - val_accuracy: 0.8874\n",
      "Epoch 43/50\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.2999 - accuracy: 0.8890 - val_loss: 0.3298 - val_accuracy: 0.8748\n",
      "Epoch 44/50\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.3066 - accuracy: 0.8838 - val_loss: 0.3087 - val_accuracy: 0.8861\n",
      "Epoch 45/50\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.3167 - accuracy: 0.8810 - val_loss: 0.3096 - val_accuracy: 0.8818\n",
      "Epoch 46/50\n",
      "937/937 [==============================] - 26s 27ms/step - loss: 0.3148 - accuracy: 0.8824 - val_loss: 0.3102 - val_accuracy: 0.8817\n",
      "Epoch 47/50\n",
      "937/937 [==============================] - 26s 27ms/step - loss: 0.3009 - accuracy: 0.8878 - val_loss: 0.2952 - val_accuracy: 0.8900\n",
      "Epoch 48/50\n",
      "937/937 [==============================] - 34s 36ms/step - loss: 0.2924 - accuracy: 0.8907 - val_loss: 0.2941 - val_accuracy: 0.8893\n",
      "Epoch 49/50\n",
      "937/937 [==============================] - 31s 33ms/step - loss: 0.2805 - accuracy: 0.8952 - val_loss: 0.2895 - val_accuracy: 0.8908\n",
      "Epoch 50/50\n",
      "937/937 [==============================] - 29s 31ms/step - loss: 0.2723 - accuracy: 0.8989 - val_loss: 0.2793 - val_accuracy: 0.8949\n",
      "[INFO] evaluating network...\n",
      "157/157 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.83      0.87      0.85      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.80      0.82      0.81      1000\n",
      "       dress       0.89      0.90      0.90      1000\n",
      "        coat       0.82      0.80      0.81      1000\n",
      "      sandal       0.97      0.97      0.97      1000\n",
      "       shirt       0.74      0.69      0.72      1000\n",
      "     sneaker       0.94      0.96      0.95      1000\n",
      "         bag       0.98      0.99      0.98      1000\n",
      "  ankle boot       0.97      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stepSize = STEP_SIZE * (trainX.shape[0] // BATCH_SIZE)\n",
    "clr = CyclicLR(\n",
    "\tmode=CLR_METHOD,\n",
    "\tbase_lr=MIN_LR,\n",
    "\tmax_lr=MAX_LR,\n",
    "\tstep_size=stepSize)\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(\n",
    "\tx=aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=trainX.shape[0] // BATCH_SIZE,\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tcallbacks=[clr],\n",
    "\tverbose=1)\n",
    "# evaluate the network and show a classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX, batch_size=BATCH_SIZE)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.arange(0, NUM_EPOCHS)\n",
    "# plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"training_plot.png\")\n",
    "# plot the learning rate history\n",
    "N = np.arange(0, len(clr.history[\"lr\"]))\n",
    "plt.figure()\n",
    "plt.plot(N, clr.history[\"lr\"])\n",
    "plt.title(\"Cyclical Learning Rate (CLR)\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.savefig(\"crl_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We want to test if increasing batch size for a fixed learning rate has the same effect as decreasing learning rate for a fixed batch size. Fix learning rate to lrmax and train your network starting with batch size 32 and incrementally going upto 4096 (in increments of a factor of 2; like 32, 64...). You can choose a step size (in terms of number of epochs) to increment the batch size. Plot the training loss vs. log2(batch size). Is the generalization of your final model similar or different than cyclical learning rate policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.7699 - accuracy: 0.7104 - val_loss: 0.5757 - val_accuracy: 0.7780\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.5338 - accuracy: 0.7979 - val_loss: 0.4644 - val_accuracy: 0.8301\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.4682 - accuracy: 0.8239 - val_loss: 0.4132 - val_accuracy: 0.8439\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.4331 - accuracy: 0.8367 - val_loss: 0.4129 - val_accuracy: 0.8418\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.4106 - accuracy: 0.8465 - val_loss: 0.3992 - val_accuracy: 0.8483\n",
      "[INFO] evaluating network...\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.79      0.79      0.79      1000\n",
      "     trouser       0.98      0.96      0.97      1000\n",
      "    pullover       0.86      0.64      0.73      1000\n",
      "       dress       0.89      0.84      0.87      1000\n",
      "        coat       0.74      0.79      0.77      1000\n",
      "      sandal       0.92      0.97      0.95      1000\n",
      "       shirt       0.54      0.68      0.60      1000\n",
      "     sneaker       0.95      0.88      0.91      1000\n",
      "         bag       0.98      0.96      0.97      1000\n",
      "  ankle boot       0.93      0.96      0.94      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3714 - accuracy: 0.8603 - val_loss: 0.3532 - val_accuracy: 0.8652\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3595 - accuracy: 0.8664 - val_loss: 0.3492 - val_accuracy: 0.8706\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 23s 25ms/step - loss: 0.3520 - accuracy: 0.8691 - val_loss: 0.3418 - val_accuracy: 0.8710\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3467 - accuracy: 0.8710 - val_loss: 0.3296 - val_accuracy: 0.8747\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 28s 30ms/step - loss: 0.3431 - accuracy: 0.8721 - val_loss: 0.3357 - val_accuracy: 0.8749\n",
      "[INFO] evaluating network...\n",
      "157/157 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.79      0.87      0.83      1000\n",
      "     trouser       0.99      0.96      0.98      1000\n",
      "    pullover       0.88      0.70      0.78      1000\n",
      "       dress       0.85      0.91      0.88      1000\n",
      "        coat       0.75      0.86      0.80      1000\n",
      "      sandal       0.96      0.96      0.96      1000\n",
      "       shirt       0.68      0.63      0.66      1000\n",
      "     sneaker       0.91      0.97      0.94      1000\n",
      "         bag       0.98      0.97      0.98      1000\n",
      "  ankle boot       0.98      0.92      0.95      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "468/468 [==============================] - 24s 52ms/step - loss: 0.3201 - accuracy: 0.8808 - val_loss: 0.3119 - val_accuracy: 0.8851\n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 25s 53ms/step - loss: 0.3194 - accuracy: 0.8819 - val_loss: 0.3166 - val_accuracy: 0.8828\n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 34s 72ms/step - loss: 0.3158 - accuracy: 0.8830 - val_loss: 0.3162 - val_accuracy: 0.8825\n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 23s 50ms/step - loss: 0.3119 - accuracy: 0.8841 - val_loss: 0.3092 - val_accuracy: 0.8857\n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 23s 50ms/step - loss: 0.3106 - accuracy: 0.8847 - val_loss: 0.3206 - val_accuracy: 0.8792\n",
      "[INFO] evaluating network...\n",
      "79/79 [==============================] - 1s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.84      0.83      1000\n",
      "     trouser       0.99      0.97      0.98      1000\n",
      "    pullover       0.78      0.86      0.82      1000\n",
      "       dress       0.90      0.89      0.90      1000\n",
      "        coat       0.82      0.76      0.79      1000\n",
      "      sandal       0.89      0.99      0.94      1000\n",
      "       shirt       0.71      0.68      0.69      1000\n",
      "     sneaker       0.95      0.88      0.91      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.97      0.94      0.95      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "234/234 [==============================] - 23s 99ms/step - loss: 0.3010 - accuracy: 0.8888 - val_loss: 0.3006 - val_accuracy: 0.8889\n",
      "Epoch 2/5\n",
      "234/234 [==============================] - 27s 117ms/step - loss: 0.2992 - accuracy: 0.8897 - val_loss: 0.3033 - val_accuracy: 0.8872\n",
      "Epoch 3/5\n",
      "234/234 [==============================] - 24s 101ms/step - loss: 0.2976 - accuracy: 0.8887 - val_loss: 0.3036 - val_accuracy: 0.8860\n",
      "Epoch 4/5\n",
      "234/234 [==============================] - 28s 118ms/step - loss: 0.2963 - accuracy: 0.8902 - val_loss: 0.2935 - val_accuracy: 0.8904\n",
      "Epoch 5/5\n",
      "234/234 [==============================] - 25s 109ms/step - loss: 0.2971 - accuracy: 0.8896 - val_loss: 0.2983 - val_accuracy: 0.8887\n",
      "[INFO] evaluating network...\n",
      "40/40 [==============================] - 1s 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.82      0.82      1000\n",
      "     trouser       0.99      0.97      0.98      1000\n",
      "    pullover       0.81      0.85      0.83      1000\n",
      "       dress       0.89      0.89      0.89      1000\n",
      "        coat       0.82      0.79      0.81      1000\n",
      "      sandal       0.97      0.97      0.97      1000\n",
      "       shirt       0.70      0.70      0.70      1000\n",
      "     sneaker       0.93      0.97      0.95      1000\n",
      "         bag       0.97      0.98      0.98      1000\n",
      "  ankle boot       0.98      0.94      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "117/117 [==============================] - 22s 191ms/step - loss: 0.2911 - accuracy: 0.8926 - val_loss: 0.2928 - val_accuracy: 0.8906\n",
      "Epoch 2/5\n",
      "117/117 [==============================] - 21s 176ms/step - loss: 0.2900 - accuracy: 0.8907 - val_loss: 0.2915 - val_accuracy: 0.8914\n",
      "Epoch 3/5\n",
      "117/117 [==============================] - 27s 227ms/step - loss: 0.2861 - accuracy: 0.8949 - val_loss: 0.2932 - val_accuracy: 0.8922\n",
      "Epoch 4/5\n",
      "117/117 [==============================] - 26s 223ms/step - loss: 0.2889 - accuracy: 0.8920 - val_loss: 0.2918 - val_accuracy: 0.8923\n",
      "Epoch 5/5\n",
      "117/117 [==============================] - 25s 210ms/step - loss: 0.2885 - accuracy: 0.8934 - val_loss: 0.2887 - val_accuracy: 0.8933\n",
      "[INFO] evaluating network...\n",
      "20/20 [==============================] - 1s 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.83      0.85      0.84      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.82      0.84      0.83      1000\n",
      "       dress       0.90      0.90      0.90      1000\n",
      "        coat       0.82      0.81      0.82      1000\n",
      "      sandal       0.97      0.97      0.97      1000\n",
      "       shirt       0.72      0.69      0.71      1000\n",
      "     sneaker       0.94      0.96      0.95      1000\n",
      "         bag       0.97      0.98      0.98      1000\n",
      "  ankle boot       0.97      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.2846 - accuracy: 0.8944 - val_loss: 0.2914 - val_accuracy: 0.8909\n",
      "Epoch 2/5\n",
      "58/58 [==============================] - 26s 452ms/step - loss: 0.2848 - accuracy: 0.8949 - val_loss: 0.2897 - val_accuracy: 0.8933\n",
      "Epoch 3/5\n",
      "58/58 [==============================] - 28s 474ms/step - loss: 0.2827 - accuracy: 0.8949 - val_loss: 0.2887 - val_accuracy: 0.8920\n",
      "Epoch 4/5\n",
      "58/58 [==============================] - 42s 722ms/step - loss: 0.2825 - accuracy: 0.8952 - val_loss: 0.2886 - val_accuracy: 0.8939\n",
      "Epoch 5/5\n",
      "58/58 [==============================] - 33s 559ms/step - loss: 0.2818 - accuracy: 0.8940 - val_loss: 0.2885 - val_accuracy: 0.8927\n",
      "[INFO] evaluating network...\n",
      "10/10 [==============================] - 1s 81ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.85      0.84      1000\n",
      "     trouser       0.98      0.98      0.98      1000\n",
      "    pullover       0.82      0.84      0.83      1000\n",
      "       dress       0.89      0.90      0.89      1000\n",
      "        coat       0.82      0.83      0.82      1000\n",
      "      sandal       0.97      0.97      0.97      1000\n",
      "       shirt       0.74      0.67      0.70      1000\n",
      "     sneaker       0.94      0.96      0.95      1000\n",
      "         bag       0.97      0.98      0.98      1000\n",
      "  ankle boot       0.97      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.2818 - accuracy: 0.8953 - val_loss: 0.2870 - val_accuracy: 0.8939\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 31s 993ms/step - loss: 0.2806 - accuracy: 0.8955 - val_loss: 0.2875 - val_accuracy: 0.8928\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 26s 898ms/step - loss: 0.2812 - accuracy: 0.8966 - val_loss: 0.2878 - val_accuracy: 0.8915\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 24s 806ms/step - loss: 0.2802 - accuracy: 0.8972 - val_loss: 0.2878 - val_accuracy: 0.8919\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 24s 833ms/step - loss: 0.2809 - accuracy: 0.8951 - val_loss: 0.2862 - val_accuracy: 0.8930\n",
      "[INFO] evaluating network...\n",
      "5/5 [==============================] - 1s 131ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.84      0.83      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.82      0.85      0.83      1000\n",
      "       dress       0.88      0.91      0.89      1000\n",
      "        coat       0.83      0.81      0.82      1000\n",
      "      sandal       0.97      0.97      0.97      1000\n",
      "       shirt       0.73      0.68      0.71      1000\n",
      "     sneaker       0.94      0.96      0.95      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.97      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2797 - accuracy: 0.8966 - val_loss: 0.2872 - val_accuracy: 0.8929\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 24s 2s/step - loss: 0.2790 - accuracy: 0.8964 - val_loss: 0.2864 - val_accuracy: 0.8939\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2798 - accuracy: 0.8959 - val_loss: 0.2867 - val_accuracy: 0.8938\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2804 - accuracy: 0.8957 - val_loss: 0.2862 - val_accuracy: 0.8942\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.2803 - accuracy: 0.8956 - val_loss: 0.2864 - val_accuracy: 0.8934\n",
      "[INFO] evaluating network...\n",
      "3/3 [==============================] - 1s 219ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.82      0.85      0.84      1000\n",
      "     trouser       0.99      0.98      0.98      1000\n",
      "    pullover       0.82      0.84      0.83      1000\n",
      "       dress       0.88      0.91      0.90      1000\n",
      "        coat       0.83      0.82      0.82      1000\n",
      "      sandal       0.97      0.97      0.97      1000\n",
      "       shirt       0.74      0.68      0.71      1000\n",
      "     sneaker       0.94      0.96      0.95      1000\n",
      "         bag       0.98      0.98      0.98      1000\n",
      "  ankle boot       0.97      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = 32\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(learning_rate=MAX_LR, momentum=0.9)\n",
    "model = create_model()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "loss = []\n",
    "batches = []\n",
    "\n",
    "while batch <=4096:\n",
    "    print(\"[INFO] training network...\")\n",
    "    H = model.fit(\n",
    "\tx=aug.flow(trainX, trainY, batch_size=batch),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=trainX.shape[0] // batch,\n",
    "\tepochs=5,\n",
    "\t# callbacks=[clr],\n",
    "\tverbose=1)\n",
    "    # evaluate the network and show a classification report\n",
    "    print(\"[INFO] evaluating network...\")\n",
    "    predictions = model.predict(x=testX, batch_size=batch)\n",
    "    print(classification_report(testY.argmax(axis=1),\n",
    "        predictions.argmax(axis=1), target_names=CLASSES))\n",
    "    \n",
    "    loss.append(H.history[\"loss\"][-1])\n",
    "    batches.append(batch)\n",
    "    \n",
    "    # updating the batch size\n",
    "    batch*=2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(batches, loss)\n",
    "plt.title(\"Batches vs loss\")\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.savefig(\"batches_loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0f08725565d2d00e70b9fae99b105541271f7be4baa13607a6e77e1d2c8c73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
