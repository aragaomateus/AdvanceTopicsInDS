{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXEwChQKcKBO"
      },
      "source": [
        "# Problem 3 - Ray Tune for Hyperparameter Optimization 10 points\n",
        "\n",
        "\n",
        "In this problem, we will compare the performance of Grid Search, Bayesian Search and Hyperband for hyperparameter optimization for a deep learning problem using Ray Tune. We will use the MNIST dataset alongwith the Lenet model. The hyperparameters to tune are:\n",
        "\n",
        "• Number of filters in the first Conv2d layer: 64 to 256 \n",
        "\n",
        "• Learning Rate: 0.001 to 0.1\n",
        "\n",
        "• Batch Size: 64,128,256\n",
        "\n",
        "• Dropout: probability between 0 and 1\n",
        "\n",
        "Use Ray Tune (https://docs.ray.io/en/latest/tune/index.html) for the search. You can use the same resources per trial and metric as those in Lab 8 and Lab 10 in class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmIa79k3cKBR",
        "outputId": "9536f661-16ec-494c-f693-18308eb64c37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.8/dist-packages (2.1.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (22.1.0)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.51.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (6.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (3.19.6)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (20.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (3.8.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (1.3.5)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (2.5.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from ray[tune]) (0.8.10)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[tune]) (2.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[tune]) (0.3.6)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[tune]) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[tune]) (3.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->ray[tune]) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray[tune]) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from pyarrow) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"ray[tune]\"\n",
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "je0FQ-UXcKBT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune.integration.keras import TuneReportCallback\n",
        "from ray.tune.schedulers import HyperBandScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HPwLva3IcKBU"
      },
      "outputs": [],
      "source": [
        "def train_mnist(config):\n",
        "    batch_size = int(config['batch_size'])\n",
        "    epochs = 2\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=int(config[\"conv_filters\"]), kernel_size=(5, 5), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(config[\"dropout\"]),\n",
        "        tf.keras.layers.Dense(84, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    \n",
        "    \n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            lr=config[\"lr\"]),\n",
        "        metrics=[\"accuracy\"])\n",
        "\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        verbose=0,\n",
        "        validation_data=(x_test, y_test),\n",
        "        callbacks=[TuneReportCallback({\n",
        "            \"accuracy\": \"accuracy\"\n",
        "        })])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftCuMyMtcKBV"
      },
      "source": [
        "1. Perform Grid Search, Bayesian Search and Hyperband for the given hyperparameter configurations. For Grid Search, you can either sample uniformly between the given ranges, or specify a list of values in the given range (for e.g., filters = [64,128,256], lr=[0.001,0.01,0.1], etc). (6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9TdErDmlcKBW",
        "outputId": "4e973f8f-9149-4ecd-8b3d-98f9c8e372ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2022-12-11 19:44:06</td></tr>\n",
              "<tr><td>Running for: </td><td>00:05:40.60        </td></tr>\n",
              "<tr><td>Memory:      </td><td>2.8/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using HyperBand: num_stopped=3 total_brackets=3<br>Round #0:<br>  Bracket(Max Size (n)=3, Milestone (r)=10, completed=100.0%): {TERMINATED: 3} <br>  Bracket(Max Size (n)=2, Milestone (r)=7, completed=100.0%): {TERMINATED: 5} <br>  Bracket(Max Size (n)=1, Milestone (r)=7, completed=100.0%): {TERMINATED: 1} <br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:T4)\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_filters</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_6167f_00000</td><td>TERMINATED</td><td>172.28.0.12:1679</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.373763 </td><td style=\"text-align: right;\">0.0223396 </td><td style=\"text-align: right;\">0.1085  </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         43.1493</td><td style=\"text-align: right;\">    </td></tr>\n",
              "<tr><td>train_mnist_6167f_00001</td><td>TERMINATED</td><td>172.28.0.12:2247</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.0861023</td><td style=\"text-align: right;\">0.014111  </td><td style=\"text-align: right;\">0.978833</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         30.8554</td><td style=\"text-align: right;\">    </td></tr>\n",
              "<tr><td>train_mnist_6167f_00002</td><td>TERMINATED</td><td>172.28.0.12:2655</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.353302 </td><td style=\"text-align: right;\">0.0973313 </td><td style=\"text-align: right;\">0.105167</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         23.2188</td><td style=\"text-align: right;\">    </td></tr>\n",
              "<tr><td>train_mnist_6167f_00003</td><td>TERMINATED</td><td>172.28.0.12:2446</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.224768 </td><td style=\"text-align: right;\">0.0723921 </td><td style=\"text-align: right;\">0.105633</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         55.6887</td><td style=\"text-align: right;\">   0</td></tr>\n",
              "<tr><td>train_mnist_6167f_00004</td><td>TERMINATED</td><td>172.28.0.12:2000</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.685153 </td><td style=\"text-align: right;\">0.0622605 </td><td style=\"text-align: right;\">0.103967</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         16.3711</td><td style=\"text-align: right;\">    </td></tr>\n",
              "<tr><td>train_mnist_6167f_00005</td><td>TERMINATED</td><td>172.28.0.12:2548</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">0.166145 </td><td style=\"text-align: right;\">0.00787397</td><td style=\"text-align: right;\">0.988517</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         37.3817</td><td style=\"text-align: right;\">   0</td></tr>\n",
              "<tr><td>train_mnist_6167f_00006</td><td>TERMINATED</td><td>172.28.0.12:2163</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.481493 </td><td style=\"text-align: right;\">0.0576298 </td><td style=\"text-align: right;\">0.10375 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         25.0217</td><td style=\"text-align: right;\">    </td></tr>\n",
              "<tr><td>train_mnist_6167f_00007</td><td>TERMINATED</td><td>172.28.0.12:2365</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.475957 </td><td style=\"text-align: right;\">0.096512  </td><td style=\"text-align: right;\">0.1038  </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         21.1456</td><td style=\"text-align: right;\">    </td></tr>\n",
              "<tr><td>train_mnist_6167f_00008</td><td>TERMINATED</td><td>172.28.0.12:1889</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">0.735513 </td><td style=\"text-align: right;\">0.0843475 </td><td style=\"text-align: right;\">0.1022  </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         36.6678</td><td style=\"text-align: right;\">    </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1679)\u001b[0m 2022-12-11 19:38:32.246458: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1679)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1679)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mean_accuracy</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_6167f_00000</td><td>2022-12-11_19-39-13</td><td>False </td><td style=\"text-align: right;\">                </td><td>59717ba6d9ca4f13b18429358274da57</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">       0.1085  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 1679</td><td style=\"text-align: right;\">             43.1493</td><td style=\"text-align: right;\">           3.65664</td><td style=\"text-align: right;\">       43.1493</td><td style=\"text-align: right;\"> 1670787553</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                  10</td><td>6167f_00000</td><td style=\"text-align: right;\">   0.00554705</td></tr>\n",
              "<tr><td>train_mnist_6167f_00001</td><td>2022-12-11_19-42-01</td><td>False </td><td style=\"text-align: right;\">                </td><td>28a3aa4120e74f19a72a9f4f1ca2a449</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">       0.978833</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2247</td><td style=\"text-align: right;\">             30.8554</td><td style=\"text-align: right;\">           2.60831</td><td style=\"text-align: right;\">       30.8554</td><td style=\"text-align: right;\"> 1670787721</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                  10</td><td>6167f_00001</td><td style=\"text-align: right;\">   0.00332403</td></tr>\n",
              "<tr><td>train_mnist_6167f_00002</td><td>2022-12-11_19-44-06</td><td>True  </td><td style=\"text-align: right;\">                </td><td>7a86f0843d8c47ac9af0a5e8e250288c</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        10</td><td style=\"text-align: right;\">       0.105167</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2655</td><td style=\"text-align: right;\">             23.2188</td><td style=\"text-align: right;\">           1.8015 </td><td style=\"text-align: right;\">       23.2188</td><td style=\"text-align: right;\"> 1670787846</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                  10</td><td>6167f_00002</td><td style=\"text-align: right;\">   0.0032196 </td></tr>\n",
              "<tr><td>train_mnist_6167f_00003</td><td>2022-12-11_19-43-08</td><td>False </td><td style=\"text-align: right;\">               0</td><td>4762503d03f34cdfbe0c98cfbce83fe3</td><td>db50b83514e2</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">       0.105633</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2446</td><td style=\"text-align: right;\">             36.9919</td><td style=\"text-align: right;\">           4.53338</td><td style=\"text-align: right;\">       55.6887</td><td style=\"text-align: right;\"> 1670787788</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                   7</td><td>6167f_00003</td><td style=\"text-align: right;\">   0.00726557</td></tr>\n",
              "<tr><td>train_mnist_6167f_00004</td><td>2022-12-11_19-40-38</td><td>False </td><td style=\"text-align: right;\">                </td><td>7426f833d27f418dad3fe0a942636153</td><td>db50b83514e2</td><td style=\"text-align: right;\">                         3</td><td style=\"text-align: right;\">       0.103967</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2000</td><td style=\"text-align: right;\">             16.3711</td><td style=\"text-align: right;\">           3.69682</td><td style=\"text-align: right;\">       16.3711</td><td style=\"text-align: right;\"> 1670787638</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   3</td><td>6167f_00004</td><td style=\"text-align: right;\">   0.00346971</td></tr>\n",
              "<tr><td>train_mnist_6167f_00005</td><td>2022-12-11_19-43-38</td><td>True  </td><td style=\"text-align: right;\">               0</td><td>c547a6f7c6314421821ea4eace202598</td><td>db50b83514e2</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">       0.988517</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2548</td><td style=\"text-align: right;\">             24.0879</td><td style=\"text-align: right;\">           2.68242</td><td style=\"text-align: right;\">       37.3817</td><td style=\"text-align: right;\"> 1670787818</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">                   7</td><td>6167f_00005</td><td style=\"text-align: right;\">   0.00717592</td></tr>\n",
              "<tr><td>train_mnist_6167f_00006</td><td>2022-12-11_19-41-26</td><td>False </td><td style=\"text-align: right;\">                </td><td>9ce22bdb009f410d9ade3686019a602a</td><td>db50b83514e2</td><td style=\"text-align: right;\">                         3</td><td style=\"text-align: right;\">       0.10375 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2163</td><td style=\"text-align: right;\">             25.0217</td><td style=\"text-align: right;\">           6.66575</td><td style=\"text-align: right;\">       25.0217</td><td style=\"text-align: right;\"> 1670787686</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   3</td><td>6167f_00006</td><td style=\"text-align: right;\">   0.0050025 </td></tr>\n",
              "<tr><td>train_mnist_6167f_00007</td><td>2022-12-11_19-42-27</td><td>True  </td><td style=\"text-align: right;\">                </td><td>0797be25ad404276ba0e63b8ff36f000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                         3</td><td style=\"text-align: right;\">       0.1038  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2365</td><td style=\"text-align: right;\">             21.1456</td><td style=\"text-align: right;\">           5.49264</td><td style=\"text-align: right;\">       21.1456</td><td style=\"text-align: right;\"> 1670787747</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   3</td><td>6167f_00007</td><td style=\"text-align: right;\">   0.00316238</td></tr>\n",
              "<tr><td>train_mnist_6167f_00008</td><td>2022-12-11_19-40-17</td><td>True  </td><td style=\"text-align: right;\">                </td><td>74bdce6262304ca4bd8fdf323df210e3</td><td>db50b83514e2</td><td style=\"text-align: right;\">                         7</td><td style=\"text-align: right;\">       0.1022  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 1889</td><td style=\"text-align: right;\">             36.6678</td><td style=\"text-align: right;\">           4.48088</td><td style=\"text-align: right;\">       36.6678</td><td style=\"text-align: right;\"> 1670787617</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   7</td><td>6167f_00008</td><td style=\"text-align: right;\">   0.00319815</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1807)\u001b[0m 2022-12-11 19:39:19.666498: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1807)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1807)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1889)\u001b[0m 2022-12-11 19:39:42.667389: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1889)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1889)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2000)\u001b[0m 2022-12-11 19:40:23.800325: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2000)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2000)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2082)\u001b[0m 2022-12-11 19:40:44.681771: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2082)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2082)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2163)\u001b[0m 2022-12-11 19:41:03.024102: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2163)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2163)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2247)\u001b[0m 2022-12-11 19:41:32.930701: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2247)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2247)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2365)\u001b[0m 2022-12-11 19:42:08.682764: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2365)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2365)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2446)\u001b[0m 2022-12-11 19:42:32,000\tINFO trainable.py:766 -- Restored on 172.28.0.12 from checkpoint: /root/ray_results/exp/train_mnist_6167f_00003_3_batch_size=64,conv_filters=128,dropout=0.2248,lr=0.0724_2022-12-11_19-39-14/checkpoint_tmp117eb4\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2446)\u001b[0m 2022-12-11 19:42:32,000\tINFO trainable.py:775 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 18.696871519088745, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2446)\u001b[0m 2022-12-11 19:42:33.863919: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2446)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2446)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "2022-12-11 19:42:41,620\tINFO hyperband.py:472 -- Restoring from a previous point in time. Previous=3; Now=1\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2548)\u001b[0m 2022-12-11 19:43:13,983\tINFO trainable.py:766 -- Restored on 172.28.0.12 from checkpoint: /root/ray_results/exp/train_mnist_6167f_00005_5_batch_size=256,conv_filters=128,dropout=0.1661,lr=0.0079_2022-12-11_19-40-39/checkpoint_tmp65e403\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2548)\u001b[0m 2022-12-11 19:43:13,983\tINFO trainable.py:775 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': 0, '_time_total': 13.293773174285889, '_episodes_total': 0}\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2548)\u001b[0m 2022-12-11 19:43:15.834904: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2548)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2548)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "2022-12-11 19:43:21,844\tINFO hyperband.py:472 -- Restoring from a previous point in time. Previous=3; Now=1\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2655)\u001b[0m 2022-12-11 19:43:45.158723: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2655)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2655)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "2022-12-11 19:44:06,715\tINFO tune.py:777 -- Total run time: 340.74 seconds (340.59 seconds for the tuning loop).\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------Hyperband --------------------------\n",
        "search_list = {\n",
        "            \"batch_size\": tune.grid_search([64,128,256]),\n",
        "            \"conv_filters\": tune.grid_search([64,128,256]),\n",
        "            \"dropout\": tune.uniform(0, 1),\n",
        "            \"lr\": tune.uniform(0.001, 0.1)\n",
        "        }\n",
        "hyperband_scheduler = HyperBandScheduler(\n",
        "    time_attr='training_iteration',\n",
        "    metric='mean_accuracy',\n",
        "    mode='max',\n",
        "    max_t=10,\n",
        "    reduction_factor=3)\n",
        "\n",
        "Hype_analysis = tune.run(\n",
        "        train_mnist,\n",
        "        name=\"exp\",\n",
        "        resources_per_trial={\n",
        "            \"gpu\": 1\n",
        "        },\n",
        "        config=search_list,\n",
        "        scheduler=hyperband_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dn69p6a8-6-a",
        "outputId": "f9d119fd-9642-4610-cdce-39e1286cc8b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2022-12-11 20:23:16</td></tr>\n",
              "<tr><td>Running for: </td><td>00:39:10.02        </td></tr>\n",
              "<tr><td>Memory:      </td><td>3.0/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:T4)\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_filters</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2c8b9_00000</td><td>TERMINATED</td><td>172.28.0.12:2781 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.955933</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.75708</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00001</td><td>TERMINATED</td><td>172.28.0.12:2878 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.946267</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.71541</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00002</td><td>TERMINATED</td><td>172.28.0.12:2948 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9279  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.13757</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00003</td><td>TERMINATED</td><td>172.28.0.12:3017 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.959417</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.61661</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00004</td><td>TERMINATED</td><td>172.28.0.12:3088 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9483  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.88195</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00005</td><td>TERMINATED</td><td>172.28.0.12:3157 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.935833</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.90216</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00006</td><td>TERMINATED</td><td>172.28.0.12:3227 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.959083</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.9363 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00007</td><td>TERMINATED</td><td>172.28.0.12:3295 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.949617</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.2091 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00008</td><td>TERMINATED</td><td>172.28.0.12:3362 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.929783</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.92268</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00009</td><td>TERMINATED</td><td>172.28.0.12:3429 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.945617</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.79353</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00010</td><td>TERMINATED</td><td>172.28.0.12:3498 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.93185 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.76541</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00011</td><td>TERMINATED</td><td>172.28.0.12:3564 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.911383</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.91614</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00012</td><td>TERMINATED</td><td>172.28.0.12:3631 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.948283</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.67545</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00013</td><td>TERMINATED</td><td>172.28.0.12:3698 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9381  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.94112</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00014</td><td>TERMINATED</td><td>172.28.0.12:3765 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.91825 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.89725</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00015</td><td>TERMINATED</td><td>172.28.0.12:3831 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.95205 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.8509 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00016</td><td>TERMINATED</td><td>172.28.0.12:3899 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.936567</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.4426 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00017</td><td>TERMINATED</td><td>172.28.0.12:3967 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.914633</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.98923</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00018</td><td>TERMINATED</td><td>172.28.0.12:4034 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.918967</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.63787</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00019</td><td>TERMINATED</td><td>172.28.0.12:4103 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9034  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.74332</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00020</td><td>TERMINATED</td><td>172.28.0.12:4169 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.970267</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.75021</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00021</td><td>TERMINATED</td><td>172.28.0.12:4240 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9218  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.72637</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00022</td><td>TERMINATED</td><td>172.28.0.12:4308 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.912767</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.92852</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00023</td><td>TERMINATED</td><td>172.28.0.12:4376 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.97095 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.6394 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00024</td><td>TERMINATED</td><td>172.28.0.12:4448 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9285  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.7548 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00025</td><td>TERMINATED</td><td>172.28.0.12:4516 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.906433</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.4578 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00026</td><td>TERMINATED</td><td>172.28.0.12:4585 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">0.9722  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        14.6347 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00027</td><td>TERMINATED</td><td>172.28.0.12:4657 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.94825 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.9089 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00028</td><td>TERMINATED</td><td>172.28.0.12:4729 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.942483</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.76921</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00029</td><td>TERMINATED</td><td>172.28.0.12:4799 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9399  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.89123</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00030</td><td>TERMINATED</td><td>172.28.0.12:4868 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.937517</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.69923</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00031</td><td>TERMINATED</td><td>172.28.0.12:4935 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.919233</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.86495</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00032</td><td>TERMINATED</td><td>172.28.0.12:5003 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.979433</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.76   </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00033</td><td>TERMINATED</td><td>172.28.0.12:5076 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.935033</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        18.3532 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00034</td><td>TERMINATED</td><td>172.28.0.12:5151 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.929833</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.6054 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00035</td><td>TERMINATED</td><td>172.28.0.12:5221 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.911333</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.2973 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00036</td><td>TERMINATED</td><td>172.28.0.12:5290 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.92355 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.93025</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00037</td><td>TERMINATED</td><td>172.28.0.12:5357 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.919033</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.82352</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00038</td><td>TERMINATED</td><td>172.28.0.12:5424 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.936383</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.06657</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00039</td><td>TERMINATED</td><td>172.28.0.12:5491 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.92975 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.82449</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00040</td><td>TERMINATED</td><td>172.28.0.12:5559 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.96175 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        12.9771 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00041</td><td>TERMINATED</td><td>172.28.0.12:5634 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.928333</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.91705</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00042</td><td>TERMINATED</td><td>172.28.0.12:5701 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.915717</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.9028 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00043</td><td>TERMINATED</td><td>172.28.0.12:5768 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.90925 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.4771 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00044</td><td>TERMINATED</td><td>172.28.0.12:5835 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.977167</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        14.5141 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00045</td><td>TERMINATED</td><td>172.28.0.12:5909 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.909733</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.82883</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00046</td><td>TERMINATED</td><td>172.28.0.12:5975 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.956017</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.4239 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00047</td><td>TERMINATED</td><td>172.28.0.12:6047 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9664  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         8.84412</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00048</td><td>TERMINATED</td><td>172.28.0.12:6119 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9495  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        14.5407 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00049</td><td>TERMINATED</td><td>172.28.0.12:6193 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.962967</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        13.0538 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00050</td><td>TERMINATED</td><td>172.28.0.12:6267 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.941783</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        10.7996 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00051</td><td>TERMINATED</td><td>172.28.0.12:6339 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.945383</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        18.5669 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00052</td><td>TERMINATED</td><td>172.28.0.12:6413 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.900783</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.4492 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00053</td><td>TERMINATED</td><td>172.28.0.12:6481 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.01 </td><td style=\"text-align: right;\">0.9677  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        14.4748 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00054</td><td>TERMINATED</td><td>172.28.0.12:6559 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.103233</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        49.546  </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00055</td><td>TERMINATED</td><td>172.28.0.12:6690 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.105267</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        36.6764 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00056</td><td>TERMINATED</td><td>172.28.0.12:6824 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.104233</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        27.902  </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00057</td><td>TERMINATED</td><td>172.28.0.12:6957 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.104433</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        60.8785 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00058</td><td>TERMINATED</td><td>172.28.0.12:7101 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.102883</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        51.0039 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00059</td><td>TERMINATED</td><td>172.28.0.12:7239 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.106267</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        37.6718 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00060</td><td>TERMINATED</td><td>172.28.0.12:7369 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1027  </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        85.9483 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00061</td><td>TERMINATED</td><td>172.28.0.12:7525 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.70805 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        68.2748 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00062</td><td>TERMINATED</td><td>172.28.0.12:7676 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0   </td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.105233</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        60.0225 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00063</td><td>TERMINATED</td><td>172.28.0.12:7810 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.104133</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        51.1525 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00064</td><td>TERMINATED</td><td>172.28.0.12:7941 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.102733</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        37.2579 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00065</td><td>TERMINATED</td><td>172.28.0.12:8069 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.106067</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        26.9515 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00066</td><td>TERMINATED</td><td>172.28.0.12:8194 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.104383</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        61.6778 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00067</td><td>TERMINATED</td><td>172.28.0.12:8327 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.106817</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        50.876  </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00068</td><td>TERMINATED</td><td>172.28.0.12:8458 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.106683</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        38.166  </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00069</td><td>TERMINATED</td><td>172.28.0.12:8586 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.103267</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        86.0436 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00070</td><td>TERMINATED</td><td>172.28.0.12:8724 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.105283</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        68.4855 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00071</td><td>TERMINATED</td><td>172.28.0.12:8859 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.33</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.106383</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        60.1117 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00072</td><td>TERMINATED</td><td>172.28.0.12:8994 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.10375 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        51.0283 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00073</td><td>TERMINATED</td><td>172.28.0.12:9131 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.102667</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        38.5885 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00074</td><td>TERMINATED</td><td>172.28.0.12:9263 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.106783</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        27.5173 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00075</td><td>TERMINATED</td><td>172.28.0.12:9389 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.104133</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        60.4529 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00076</td><td>TERMINATED</td><td>172.28.0.12:9524 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1049  </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        50.572  </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00077</td><td>TERMINATED</td><td>172.28.0.12:9654 </td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.105967</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        39.0538 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00078</td><td>TERMINATED</td><td>172.28.0.12:9782 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1054  </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        84.9002 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00079</td><td>TERMINATED</td><td>172.28.0.12:9920 </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.1052  </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        68.2888 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00080</td><td>TERMINATED</td><td>172.28.0.12:10059</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">           256</td><td style=\"text-align: right;\">     0.66</td><td style=\"text-align: right;\">0.1  </td><td style=\"text-align: right;\">0.106333</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        59.3706 </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2781)\u001b[0m 2022-12-11 19:44:13.715221: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2781)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2781)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag                                             </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  mean_accuracy</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2c8b9_00000</td><td>2022-12-11_19-44-20</td><td>True  </td><td>                </td><td>4e7f41b4e97041baa75ba8d33e9fa0f4</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.955933</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2781</td><td style=\"text-align: right;\">             8.75708</td><td style=\"text-align: right;\">           8.75708</td><td style=\"text-align: right;\">       8.75708</td><td style=\"text-align: right;\"> 1670787860</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00000</td><td style=\"text-align: right;\">   0.00308466</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00001</td><td>2022-12-11_19-44-32</td><td>True  </td><td>                </td><td>ccb15e6c4c2d435389f8038c0d972733</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.946267</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2878</td><td style=\"text-align: right;\">             7.71541</td><td style=\"text-align: right;\">           7.71541</td><td style=\"text-align: right;\">       7.71541</td><td style=\"text-align: right;\"> 1670787872</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00001</td><td style=\"text-align: right;\">   0.00330329</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00002</td><td>2022-12-11_19-44-44</td><td>True  </td><td>                </td><td>2587f9f05ee04dbaa175cd0eae3f6de6</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.9279  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2948</td><td style=\"text-align: right;\">             7.13757</td><td style=\"text-align: right;\">           7.13757</td><td style=\"text-align: right;\">       7.13757</td><td style=\"text-align: right;\"> 1670787884</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00002</td><td style=\"text-align: right;\">   0.00329351</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00003</td><td>2022-12-11_19-44-58</td><td>True  </td><td>                </td><td>2d3c2d857b48449cbf46c011cc70af0b</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.959417</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3017</td><td style=\"text-align: right;\">             9.61661</td><td style=\"text-align: right;\">           9.61661</td><td style=\"text-align: right;\">       9.61661</td><td style=\"text-align: right;\"> 1670787898</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00003</td><td style=\"text-align: right;\">   0.003263  </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00004</td><td>2022-12-11_19-45-11</td><td>True  </td><td>                </td><td>ced839828dbc44ab85e24df4e4e5a614</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.9483  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3088</td><td style=\"text-align: right;\">             8.88195</td><td style=\"text-align: right;\">           8.88195</td><td style=\"text-align: right;\">       8.88195</td><td style=\"text-align: right;\"> 1670787911</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00004</td><td style=\"text-align: right;\">   0.00336003</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00005</td><td>2022-12-11_19-45-23</td><td>True  </td><td>                </td><td>96909d12a1304eca8775bd0b8134ca3b</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.935833</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3157</td><td style=\"text-align: right;\">             7.90216</td><td style=\"text-align: right;\">           7.90216</td><td style=\"text-align: right;\">       7.90216</td><td style=\"text-align: right;\"> 1670787923</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00005</td><td style=\"text-align: right;\">   0.00443244</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00006</td><td>2022-12-11_19-45-39</td><td>True  </td><td>                </td><td>e84918dffdf747bbaf5e297b7634194f</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.959083</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3227</td><td style=\"text-align: right;\">            11.9363 </td><td style=\"text-align: right;\">          11.9363 </td><td style=\"text-align: right;\">      11.9363 </td><td style=\"text-align: right;\"> 1670787939</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00006</td><td style=\"text-align: right;\">   0.00359702</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00007</td><td>2022-12-11_19-45-55</td><td>True  </td><td>                </td><td>be4746c598454095984ea0e42a7576e4</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.949617</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3295</td><td style=\"text-align: right;\">            11.2091 </td><td style=\"text-align: right;\">          11.2091 </td><td style=\"text-align: right;\">      11.2091 </td><td style=\"text-align: right;\"> 1670787955</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00007</td><td style=\"text-align: right;\">   0.00762749</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00008</td><td>2022-12-11_19-46-09</td><td>True  </td><td>                </td><td>603bc2f0d33c4a848cbf6df7f2cccf75</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.929783</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3362</td><td style=\"text-align: right;\">             9.92268</td><td style=\"text-align: right;\">           9.92268</td><td style=\"text-align: right;\">       9.92268</td><td style=\"text-align: right;\"> 1670787969</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00008</td><td style=\"text-align: right;\">   0.00320888</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00009</td><td>2022-12-11_19-46-22</td><td>True  </td><td>                </td><td>bb99c6a2c5784a1998fb898da5a9d0a7</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.945617</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3429</td><td style=\"text-align: right;\">             8.79353</td><td style=\"text-align: right;\">           8.79353</td><td style=\"text-align: right;\">       8.79353</td><td style=\"text-align: right;\"> 1670787982</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00009</td><td style=\"text-align: right;\">   0.00342584</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00010</td><td>2022-12-11_19-46-34</td><td>True  </td><td>                </td><td>f9a5ac4e15524edabeb5f0eec2a4207c</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.93185 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3498</td><td style=\"text-align: right;\">             7.76541</td><td style=\"text-align: right;\">           7.76541</td><td style=\"text-align: right;\">       7.76541</td><td style=\"text-align: right;\"> 1670787994</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00010</td><td style=\"text-align: right;\">   0.00328112</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00011</td><td>2022-12-11_19-46-45</td><td>True  </td><td>                </td><td>63468cfd2fc448daaa4065386fd616d1</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.911383</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3564</td><td style=\"text-align: right;\">             6.91614</td><td style=\"text-align: right;\">           6.91614</td><td style=\"text-align: right;\">       6.91614</td><td style=\"text-align: right;\"> 1670788005</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00011</td><td style=\"text-align: right;\">   0.00315881</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00012</td><td>2022-12-11_19-46-59</td><td>True  </td><td>                </td><td>bff5fc3cd8a14c59a2b96362c7fda0a7</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.948283</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3631</td><td style=\"text-align: right;\">             9.67545</td><td style=\"text-align: right;\">           9.67545</td><td style=\"text-align: right;\">       9.67545</td><td style=\"text-align: right;\"> 1670788019</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00012</td><td style=\"text-align: right;\">   0.00331855</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00013</td><td>2022-12-11_19-47-12</td><td>True  </td><td>                </td><td>a19ff48552344c83aaba51d63e98fdfe</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.9381  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3698</td><td style=\"text-align: right;\">             8.94112</td><td style=\"text-align: right;\">           8.94112</td><td style=\"text-align: right;\">       8.94112</td><td style=\"text-align: right;\"> 1670788032</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00013</td><td style=\"text-align: right;\">   0.00343513</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00014</td><td>2022-12-11_19-47-24</td><td>True  </td><td>                </td><td>ca4b797518774f28a6f616115723585c</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.91825 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3765</td><td style=\"text-align: right;\">             7.89725</td><td style=\"text-align: right;\">           7.89725</td><td style=\"text-align: right;\">       7.89725</td><td style=\"text-align: right;\"> 1670788044</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00014</td><td style=\"text-align: right;\">   0.00313616</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00015</td><td>2022-12-11_19-47-40</td><td>True  </td><td>                </td><td>bce965cbb9a54db7a481020f47c09233</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.95205 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3831</td><td style=\"text-align: right;\">            11.8509 </td><td style=\"text-align: right;\">          11.8509 </td><td style=\"text-align: right;\">      11.8509 </td><td style=\"text-align: right;\"> 1670788060</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00015</td><td style=\"text-align: right;\">   0.00313401</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00016</td><td>2022-12-11_19-47-55</td><td>True  </td><td>                </td><td>a10bc85c032046e1891ece59070729b2</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.936567</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3899</td><td style=\"text-align: right;\">            10.4426 </td><td style=\"text-align: right;\">          10.4426 </td><td style=\"text-align: right;\">      10.4426 </td><td style=\"text-align: right;\"> 1670788075</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00016</td><td style=\"text-align: right;\">   0.0044353 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00017</td><td>2022-12-11_19-48-09</td><td>True  </td><td>                </td><td>65b61be53160464b8afb04db1f4ef4f0</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.914633</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 3967</td><td style=\"text-align: right;\">             9.98923</td><td style=\"text-align: right;\">           9.98923</td><td style=\"text-align: right;\">       9.98923</td><td style=\"text-align: right;\"> 1670788089</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00017</td><td style=\"text-align: right;\">   0.00364876</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00018</td><td>2022-12-11_19-48-22</td><td>True  </td><td>                </td><td>ef83eb2bf4204c9db0d1195646dc3175</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.918967</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4034</td><td style=\"text-align: right;\">             8.63787</td><td style=\"text-align: right;\">           8.63787</td><td style=\"text-align: right;\">       8.63787</td><td style=\"text-align: right;\"> 1670788102</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00018</td><td style=\"text-align: right;\">   0.00399017</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00019</td><td>2022-12-11_19-48-34</td><td>True  </td><td>                </td><td>1d2de1355331437eabd64a4330ea2fc9</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.9034  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4103</td><td style=\"text-align: right;\">             7.74332</td><td style=\"text-align: right;\">           7.74332</td><td style=\"text-align: right;\">       7.74332</td><td style=\"text-align: right;\"> 1670788114</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00019</td><td style=\"text-align: right;\">   0.00319338</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00020</td><td>2022-12-11_19-48-47</td><td>True  </td><td>                </td><td>7444dffde80042b094714c0a4705d26b</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.970267</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4169</td><td style=\"text-align: right;\">             8.75021</td><td style=\"text-align: right;\">           1.8306 </td><td style=\"text-align: right;\">       8.75021</td><td style=\"text-align: right;\"> 1670788127</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00020</td><td style=\"text-align: right;\">   0.00310588</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00021</td><td>2022-12-11_19-49-01</td><td>True  </td><td>                </td><td>307dc59fb370484bb33b9a2472b4fb9c</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.9218  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4240</td><td style=\"text-align: right;\">             9.72637</td><td style=\"text-align: right;\">           9.72637</td><td style=\"text-align: right;\">       9.72637</td><td style=\"text-align: right;\"> 1670788141</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00021</td><td style=\"text-align: right;\">   0.00577188</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00022</td><td>2022-12-11_19-49-16</td><td>True  </td><td>                </td><td>1bfba003da754835b27e8d6d0f278603</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.912767</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4308</td><td style=\"text-align: right;\">             9.92852</td><td style=\"text-align: right;\">           9.92852</td><td style=\"text-align: right;\">       9.92852</td><td style=\"text-align: right;\"> 1670788156</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00022</td><td style=\"text-align: right;\">   0.00702977</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00023</td><td>2022-12-11_19-49-31</td><td>True  </td><td>                </td><td>c5ce3199d95c4b2d94f003c4dcb3f6d2</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.97095 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4376</td><td style=\"text-align: right;\">            10.6394 </td><td style=\"text-align: right;\">           2.74421</td><td style=\"text-align: right;\">      10.6394 </td><td style=\"text-align: right;\"> 1670788171</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00023</td><td style=\"text-align: right;\">   0.00339437</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00024</td><td>2022-12-11_19-49-47</td><td>True  </td><td>                </td><td>ee714ab76fce4f31b0ebf51ed07cc000</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.9285  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4448</td><td style=\"text-align: right;\">            11.7548 </td><td style=\"text-align: right;\">          11.7548 </td><td style=\"text-align: right;\">      11.7548 </td><td style=\"text-align: right;\"> 1670788187</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00024</td><td style=\"text-align: right;\">   0.00313568</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00025</td><td>2022-12-11_19-50-02</td><td>True  </td><td>                </td><td>610c08b7cb8c44f19760162368b1e3e7</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.906433</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4516</td><td style=\"text-align: right;\">            10.4578 </td><td style=\"text-align: right;\">          10.4578 </td><td style=\"text-align: right;\">      10.4578 </td><td style=\"text-align: right;\"> 1670788202</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00025</td><td style=\"text-align: right;\">   0.00320172</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00026</td><td>2022-12-11_19-50-21</td><td>True  </td><td>                </td><td>f7ad6e8a54534af9abe14abaa1af2510</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.9722  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4585</td><td style=\"text-align: right;\">            14.6347 </td><td style=\"text-align: right;\">           4.6565 </td><td style=\"text-align: right;\">      14.6347 </td><td style=\"text-align: right;\"> 1670788221</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00026</td><td style=\"text-align: right;\">   0.00334597</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00027</td><td>2022-12-11_19-50-35</td><td>True  </td><td>                </td><td>5677285fbc4549c1b5df178296ad730e</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.94825 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4657</td><td style=\"text-align: right;\">             8.9089 </td><td style=\"text-align: right;\">           8.9089 </td><td style=\"text-align: right;\">       8.9089 </td><td style=\"text-align: right;\"> 1670788235</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00027</td><td style=\"text-align: right;\">   0.00326371</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00028</td><td>2022-12-11_19-50-47</td><td>True  </td><td>                </td><td>5266428bfbcc479889a58f5a87bb2ab3</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.942483</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4729</td><td style=\"text-align: right;\">             7.76921</td><td style=\"text-align: right;\">           7.76921</td><td style=\"text-align: right;\">       7.76921</td><td style=\"text-align: right;\"> 1670788247</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00028</td><td style=\"text-align: right;\">   0.00347114</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00029</td><td>2022-12-11_19-50-58</td><td>True  </td><td>                </td><td>ab8633e5e42d4784b8c3ce0d92e9d141</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.9399  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4799</td><td style=\"text-align: right;\">             6.89123</td><td style=\"text-align: right;\">           6.89123</td><td style=\"text-align: right;\">       6.89123</td><td style=\"text-align: right;\"> 1670788258</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00029</td><td style=\"text-align: right;\">   0.00352526</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00030</td><td>2022-12-11_19-51-12</td><td>True  </td><td>                </td><td>133d78f299684fe99a920b2a12a6ae80</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.937517</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4868</td><td style=\"text-align: right;\">             9.69923</td><td style=\"text-align: right;\">           9.69923</td><td style=\"text-align: right;\">       9.69923</td><td style=\"text-align: right;\"> 1670788272</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00030</td><td style=\"text-align: right;\">   0.00343895</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00031</td><td>2022-12-11_19-51-25</td><td>True  </td><td>                </td><td>b95e9e6518814791b388905b2848ec40</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.919233</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 4935</td><td style=\"text-align: right;\">             8.86495</td><td style=\"text-align: right;\">           8.86495</td><td style=\"text-align: right;\">       8.86495</td><td style=\"text-align: right;\"> 1670788285</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00031</td><td style=\"text-align: right;\">   0.00318098</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00032</td><td>2022-12-11_19-51-40</td><td>True  </td><td>                </td><td>d9c9efeb1c90457fa2597e1abd0877c4</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.979433</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5003</td><td style=\"text-align: right;\">            10.76   </td><td style=\"text-align: right;\">           2.77266</td><td style=\"text-align: right;\">      10.76   </td><td style=\"text-align: right;\"> 1670788300</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00032</td><td style=\"text-align: right;\">   0.00315595</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00033</td><td>2022-12-11_19-52-03</td><td>True  </td><td>                </td><td>a18c9d53d9144186988af098ad6cc3b5</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.935033</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5076</td><td style=\"text-align: right;\">            18.3532 </td><td style=\"text-align: right;\">           6.64919</td><td style=\"text-align: right;\">      18.3532 </td><td style=\"text-align: right;\"> 1670788323</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00033</td><td style=\"text-align: right;\">   0.00332427</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00034</td><td>2022-12-11_19-52-18</td><td>True  </td><td>                </td><td>23b081af6fcf43d1973f40af1c7df0bf</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.929833</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5151</td><td style=\"text-align: right;\">            10.6054 </td><td style=\"text-align: right;\">          10.6054 </td><td style=\"text-align: right;\">      10.6054 </td><td style=\"text-align: right;\"> 1670788338</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00034</td><td style=\"text-align: right;\">   0.00340366</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00035</td><td>2022-12-11_19-52-34</td><td>True  </td><td>                </td><td>56d16e82dcad4bbeaf5d8a1546906061</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.911333</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5221</td><td style=\"text-align: right;\">            11.2973 </td><td style=\"text-align: right;\">          11.2973 </td><td style=\"text-align: right;\">      11.2973 </td><td style=\"text-align: right;\"> 1670788354</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00035</td><td style=\"text-align: right;\">   0.00472355</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00036</td><td>2022-12-11_19-52-48</td><td>True  </td><td>                </td><td>fb58ae8f8efe40bca4f0d6600c7909c9</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.92355 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5290</td><td style=\"text-align: right;\">             8.93025</td><td style=\"text-align: right;\">           8.93025</td><td style=\"text-align: right;\">       8.93025</td><td style=\"text-align: right;\"> 1670788368</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00036</td><td style=\"text-align: right;\">   0.00493479</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00037</td><td>2022-12-11_19-53-00</td><td>True  </td><td>                </td><td>a7477497c6bc4fccabefd161b6651cda</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.919033</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5357</td><td style=\"text-align: right;\">             7.82352</td><td style=\"text-align: right;\">           7.82352</td><td style=\"text-align: right;\">       7.82352</td><td style=\"text-align: right;\"> 1670788380</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00037</td><td style=\"text-align: right;\">   0.00337148</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00038</td><td>2022-12-11_19-53-11</td><td>True  </td><td>                </td><td>718078845d2f43bc90726b5207a4819f</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.936383</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5424</td><td style=\"text-align: right;\">             7.06657</td><td style=\"text-align: right;\">           7.06657</td><td style=\"text-align: right;\">       7.06657</td><td style=\"text-align: right;\"> 1670788391</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00038</td><td style=\"text-align: right;\">   0.0034411 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00039</td><td>2022-12-11_19-53-25</td><td>True  </td><td>                </td><td>c71b945b52c84e79a4a6929e43b621fa</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.92975 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5491</td><td style=\"text-align: right;\">             9.82449</td><td style=\"text-align: right;\">           9.82449</td><td style=\"text-align: right;\">       9.82449</td><td style=\"text-align: right;\"> 1670788405</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00039</td><td style=\"text-align: right;\">   0.00319195</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00040</td><td>2022-12-11_19-53-43</td><td>True  </td><td>                </td><td>a5e11a2d3f3c47fda7112ee929febbcf</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.96175 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5559</td><td style=\"text-align: right;\">            12.9771 </td><td style=\"text-align: right;\">           4.02189</td><td style=\"text-align: right;\">      12.9771 </td><td style=\"text-align: right;\"> 1670788423</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00040</td><td style=\"text-align: right;\">   0.00350523</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00041</td><td>2022-12-11_19-53-55</td><td>True  </td><td>                </td><td>31f1710a2ddb47ffa33786423c5d7674</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.928333</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5634</td><td style=\"text-align: right;\">             7.91705</td><td style=\"text-align: right;\">           7.91705</td><td style=\"text-align: right;\">       7.91705</td><td style=\"text-align: right;\"> 1670788435</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00041</td><td style=\"text-align: right;\">   0.00333881</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00042</td><td>2022-12-11_19-54-11</td><td>True  </td><td>                </td><td>8638c70debf34785a5165b6a75cc0f86</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.915717</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5701</td><td style=\"text-align: right;\">            11.9028 </td><td style=\"text-align: right;\">          11.9028 </td><td style=\"text-align: right;\">      11.9028 </td><td style=\"text-align: right;\"> 1670788451</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00042</td><td style=\"text-align: right;\">   0.0033319 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00043</td><td>2022-12-11_19-54-25</td><td>True  </td><td>                </td><td>3b9e9890d6d64af6aa049e2025ec454c</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.90925 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5768</td><td style=\"text-align: right;\">            10.4771 </td><td style=\"text-align: right;\">          10.4771 </td><td style=\"text-align: right;\">      10.4771 </td><td style=\"text-align: right;\"> 1670788465</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00043</td><td style=\"text-align: right;\">   0.00323486</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00044</td><td>2022-12-11_19-54-44</td><td>True  </td><td>                </td><td>d8cd3d79fae04eb093a08181c932d245</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.977167</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5835</td><td style=\"text-align: right;\">            14.5141 </td><td style=\"text-align: right;\">           4.59992</td><td style=\"text-align: right;\">      14.5141 </td><td style=\"text-align: right;\"> 1670788484</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00044</td><td style=\"text-align: right;\">   0.00355887</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00045</td><td>2022-12-11_19-54-57</td><td>True  </td><td>                </td><td>878c356557394f9f867f689ad478f9f8</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.909733</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5909</td><td style=\"text-align: right;\">             8.82883</td><td style=\"text-align: right;\">           8.82883</td><td style=\"text-align: right;\">       8.82883</td><td style=\"text-align: right;\"> 1670788497</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00045</td><td style=\"text-align: right;\">   0.0033381 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00046</td><td>2022-12-11_19-55-12</td><td>True  </td><td>                </td><td>c1bd180fa2924f138ea0314c95f6f560</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.956017</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 5975</td><td style=\"text-align: right;\">            10.4239 </td><td style=\"text-align: right;\">           2.65652</td><td style=\"text-align: right;\">      10.4239 </td><td style=\"text-align: right;\"> 1670788512</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00046</td><td style=\"text-align: right;\">   0.00315714</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00047</td><td>2022-12-11_19-55-25</td><td>True  </td><td>                </td><td>8e2f12c00a664ba9b021fde6193a96bc</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.9664  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6047</td><td style=\"text-align: right;\">             8.84412</td><td style=\"text-align: right;\">           1.85017</td><td style=\"text-align: right;\">       8.84412</td><td style=\"text-align: right;\"> 1670788525</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00047</td><td style=\"text-align: right;\">   0.00323629</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00048</td><td>2022-12-11_19-55-44</td><td>True  </td><td>                </td><td>36745afdd17c4b01b67436bb3aaab838</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.9495  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6119</td><td style=\"text-align: right;\">            14.5407 </td><td style=\"text-align: right;\">           4.74316</td><td style=\"text-align: right;\">      14.5407 </td><td style=\"text-align: right;\"> 1670788544</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00048</td><td style=\"text-align: right;\">   0.00328326</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00049</td><td>2022-12-11_19-56-03</td><td>True  </td><td>                </td><td>8beecd241658499da84bccdc0e21c08a</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.962967</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6193</td><td style=\"text-align: right;\">            13.0538 </td><td style=\"text-align: right;\">           3.79864</td><td style=\"text-align: right;\">      13.0538 </td><td style=\"text-align: right;\"> 1670788563</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00049</td><td style=\"text-align: right;\">   0.00481987</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00050</td><td>2022-12-11_19-56-18</td><td>True  </td><td>                </td><td>e10c7108b1a7422ca7ea78d5044d82cf</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.941783</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6267</td><td style=\"text-align: right;\">            10.7996 </td><td style=\"text-align: right;\">           2.75413</td><td style=\"text-align: right;\">      10.7996 </td><td style=\"text-align: right;\"> 1670788578</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00050</td><td style=\"text-align: right;\">   0.00340414</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00051</td><td>2022-12-11_19-56-41</td><td>True  </td><td>                </td><td>2c7c2e2d19334bbeb0009d706061a858</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.945383</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6339</td><td style=\"text-align: right;\">            18.5669 </td><td style=\"text-align: right;\">           6.75183</td><td style=\"text-align: right;\">      18.5669 </td><td style=\"text-align: right;\"> 1670788601</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00051</td><td style=\"text-align: right;\">   0.0041182 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00052</td><td>2022-12-11_19-56-56</td><td>True  </td><td>                </td><td>2561096f19c7465496c7b0cf8053afc5</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">       0.900783</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6413</td><td style=\"text-align: right;\">            10.4492 </td><td style=\"text-align: right;\">          10.4492 </td><td style=\"text-align: right;\">      10.4492 </td><td style=\"text-align: right;\"> 1670788616</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>2c8b9_00052</td><td style=\"text-align: right;\">   0.00315809</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00053</td><td>2022-12-11_19-57-15</td><td>True  </td><td>                </td><td>d57e32c25a9c49428c5a72d44ece46e9</td><td>                                                           </td><td>db50b83514e2</td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">       0.9677  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6481</td><td style=\"text-align: right;\">            14.4748 </td><td style=\"text-align: right;\">           4.57874</td><td style=\"text-align: right;\">      14.4748 </td><td style=\"text-align: right;\"> 1670788635</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2c8b9_00053</td><td style=\"text-align: right;\">   0.0033071 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00054</td><td>2022-12-11_19-58-09</td><td>True  </td><td>                </td><td>5665a3449df445cda2cc0f124842717e</td><td>54_batch_size=64,conv_filters=64,dropout=0,lr=0.1000       </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.103233</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6559</td><td style=\"text-align: right;\">            49.546  </td><td style=\"text-align: right;\">           3.71863</td><td style=\"text-align: right;\">      49.546  </td><td style=\"text-align: right;\"> 1670788689</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00054</td><td style=\"text-align: right;\">   0.0031836 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00055</td><td>2022-12-11_19-58-50</td><td>True  </td><td>                </td><td>c0fe9964283e45ce893eb7060b8a44fd</td><td>55_batch_size=128,conv_filters=64,dropout=0,lr=0.1000      </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.105267</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6690</td><td style=\"text-align: right;\">            36.6764 </td><td style=\"text-align: right;\">           2.67355</td><td style=\"text-align: right;\">      36.6764 </td><td style=\"text-align: right;\"> 1670788730</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00055</td><td style=\"text-align: right;\">   0.00353193</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00056</td><td>2022-12-11_19-59-23</td><td>True  </td><td>                </td><td>8cdc89b018da4b7e98ce1fdbd51089cb</td><td>56_batch_size=256,conv_filters=64,dropout=0,lr=0.1000      </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.104233</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6824</td><td style=\"text-align: right;\">            27.902  </td><td style=\"text-align: right;\">           1.81539</td><td style=\"text-align: right;\">      27.902  </td><td style=\"text-align: right;\"> 1670788763</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00056</td><td style=\"text-align: right;\">   0.0032084 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00057</td><td>2022-12-11_20-00-28</td><td>True  </td><td>                </td><td>c2f44e83f35341bda5478bd831cb0d9d</td><td>57_batch_size=64,conv_filters=128,dropout=0,lr=0.1000      </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.104433</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 6957</td><td style=\"text-align: right;\">            60.8785 </td><td style=\"text-align: right;\">           4.61969</td><td style=\"text-align: right;\">      60.8785 </td><td style=\"text-align: right;\"> 1670788828</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00057</td><td style=\"text-align: right;\">   0.00321436</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00058</td><td>2022-12-11_20-01-23</td><td>True  </td><td>                </td><td>57ef2d80ee0c4744b930a5836ccd4bf5</td><td>58_batch_size=128,conv_filters=128,dropout=0,lr=0.1000     </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.102883</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 7101</td><td style=\"text-align: right;\">            51.0039 </td><td style=\"text-align: right;\">           3.78904</td><td style=\"text-align: right;\">      51.0039 </td><td style=\"text-align: right;\"> 1670788883</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00058</td><td style=\"text-align: right;\">   0.00320482</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00059</td><td>2022-12-11_20-02-04</td><td>True  </td><td>                </td><td>fc9814025c69404aa19d3ac574ac0dfc</td><td>59_batch_size=256,conv_filters=128,dropout=0,lr=0.1000     </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.106267</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 7239</td><td style=\"text-align: right;\">            37.6718 </td><td style=\"text-align: right;\">           2.72172</td><td style=\"text-align: right;\">      37.6718 </td><td style=\"text-align: right;\"> 1670788924</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00059</td><td style=\"text-align: right;\">   0.0032475 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00060</td><td>2022-12-11_20-03-35</td><td>True  </td><td>                </td><td>488aef664b324d58a4f6f3358f8ab889</td><td>60_batch_size=64,conv_filters=256,dropout=0,lr=0.1000      </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.1027  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 7369</td><td style=\"text-align: right;\">            85.9483 </td><td style=\"text-align: right;\">           6.66532</td><td style=\"text-align: right;\">      85.9483 </td><td style=\"text-align: right;\"> 1670789015</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00060</td><td style=\"text-align: right;\">   0.00342584</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00061</td><td>2022-12-11_20-04-47</td><td>True  </td><td>                </td><td>41fd2f6c6e49495f9f7779f8766b6b9e</td><td>61_batch_size=128,conv_filters=256,dropout=0,lr=0.1000     </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.70805 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 7525</td><td style=\"text-align: right;\">            68.2748 </td><td style=\"text-align: right;\">           5.21193</td><td style=\"text-align: right;\">      68.2748 </td><td style=\"text-align: right;\"> 1670789087</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00061</td><td style=\"text-align: right;\">   0.00429296</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00062</td><td>2022-12-11_20-05-52</td><td>True  </td><td>                </td><td>7242566e6c2c4a9ab57ea1454e782653</td><td>62_batch_size=256,conv_filters=256,dropout=0,lr=0.1000     </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.105233</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 7676</td><td style=\"text-align: right;\">            60.0225 </td><td style=\"text-align: right;\">           4.52575</td><td style=\"text-align: right;\">      60.0225 </td><td style=\"text-align: right;\"> 1670789152</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00062</td><td style=\"text-align: right;\">   0.00327587</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00063</td><td>2022-12-11_20-06-48</td><td>True  </td><td>                </td><td>fd73116e6df14c8884496553a27078d1</td><td>63_batch_size=64,conv_filters=64,dropout=0.3300,lr=0.1000  </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.104133</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 7810</td><td style=\"text-align: right;\">            51.1525 </td><td style=\"text-align: right;\">           3.83231</td><td style=\"text-align: right;\">      51.1525 </td><td style=\"text-align: right;\"> 1670789208</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00063</td><td style=\"text-align: right;\">   0.00309896</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00064</td><td>2022-12-11_20-07-30</td><td>True  </td><td>                </td><td>ebd7ce7a1bfc4a9a81c9af30ae7742a9</td><td>64_batch_size=128,conv_filters=64,dropout=0.3300,lr=0.1000 </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.102733</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 7941</td><td style=\"text-align: right;\">            37.2579 </td><td style=\"text-align: right;\">           2.66863</td><td style=\"text-align: right;\">      37.2579 </td><td style=\"text-align: right;\"> 1670789250</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00064</td><td style=\"text-align: right;\">   0.00331998</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00065</td><td>2022-12-11_20-08-02</td><td>True  </td><td>                </td><td>37c60b12e1984c5b99fc44848b6fd3a6</td><td>65_batch_size=256,conv_filters=64,dropout=0.3300,lr=0.1000 </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.106067</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8069</td><td style=\"text-align: right;\">            26.9515 </td><td style=\"text-align: right;\">           1.79069</td><td style=\"text-align: right;\">      26.9515 </td><td style=\"text-align: right;\"> 1670789282</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00065</td><td style=\"text-align: right;\">   0.00311661</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00066</td><td>2022-12-11_20-09-08</td><td>True  </td><td>                </td><td>555e8ee14fe24439b7d1a9112b81f3e0</td><td>66_batch_size=64,conv_filters=128,dropout=0.3300,lr=0.1000 </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.104383</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8194</td><td style=\"text-align: right;\">            61.6778 </td><td style=\"text-align: right;\">           5.45641</td><td style=\"text-align: right;\">      61.6778 </td><td style=\"text-align: right;\"> 1670789348</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00066</td><td style=\"text-align: right;\">   0.00328875</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00067</td><td>2022-12-11_20-10-03</td><td>True  </td><td>                </td><td>61870f0a965847aabd476b10b8d4cda1</td><td>67_batch_size=128,conv_filters=128,dropout=0.3300,lr=0.1000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.106817</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8327</td><td style=\"text-align: right;\">            50.876  </td><td style=\"text-align: right;\">           3.83164</td><td style=\"text-align: right;\">      50.876  </td><td style=\"text-align: right;\"> 1670789403</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00067</td><td style=\"text-align: right;\">   0.00335884</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00068</td><td>2022-12-11_20-10-45</td><td>True  </td><td>                </td><td>ac9538f86fca4af4966039207fd222c5</td><td>68_batch_size=256,conv_filters=128,dropout=0.3300,lr=0.1000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.106683</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8458</td><td style=\"text-align: right;\">            38.166  </td><td style=\"text-align: right;\">           2.74466</td><td style=\"text-align: right;\">      38.166  </td><td style=\"text-align: right;\"> 1670789445</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00068</td><td style=\"text-align: right;\">   0.0033474 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00069</td><td>2022-12-11_20-12-16</td><td>True  </td><td>                </td><td>8d08ac6a4bdc4ad8b7ac506cf1c8ddc6</td><td>69_batch_size=64,conv_filters=256,dropout=0.3300,lr=0.1000 </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.103267</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8586</td><td style=\"text-align: right;\">            86.0436 </td><td style=\"text-align: right;\">           6.7104 </td><td style=\"text-align: right;\">      86.0436 </td><td style=\"text-align: right;\"> 1670789536</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00069</td><td style=\"text-align: right;\">   0.00327373</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00070</td><td>2022-12-11_20-13-31</td><td>True  </td><td>                </td><td>7319b5723f434982a382999641ed2ddb</td><td>70_batch_size=128,conv_filters=256,dropout=0.3300,lr=0.1000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.105283</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8724</td><td style=\"text-align: right;\">            68.4855 </td><td style=\"text-align: right;\">           5.23308</td><td style=\"text-align: right;\">      68.4855 </td><td style=\"text-align: right;\"> 1670789611</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00070</td><td style=\"text-align: right;\">   0.00330162</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00071</td><td>2022-12-11_20-14-36</td><td>True  </td><td>                </td><td>eb282ab2d42d47f59255f81d55ef6ed4</td><td>71_batch_size=256,conv_filters=256,dropout=0.3300,lr=0.1000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.106383</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8859</td><td style=\"text-align: right;\">            60.1117 </td><td style=\"text-align: right;\">           4.53992</td><td style=\"text-align: right;\">      60.1117 </td><td style=\"text-align: right;\"> 1670789676</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00071</td><td style=\"text-align: right;\">   0.00332928</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00072</td><td>2022-12-11_20-15-32</td><td>True  </td><td>                </td><td>4a79ae9586f94433b5fc5051336a6cd9</td><td>72_batch_size=64,conv_filters=64,dropout=0.6600,lr=0.1000  </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.10375 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 8994</td><td style=\"text-align: right;\">            51.0283 </td><td style=\"text-align: right;\">           3.84541</td><td style=\"text-align: right;\">      51.0283 </td><td style=\"text-align: right;\"> 1670789732</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00072</td><td style=\"text-align: right;\">   0.00314403</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00073</td><td>2022-12-11_20-16-15</td><td>True  </td><td>                </td><td>7d19d128c5fa4b42b0ea8dcbaeecba96</td><td>73_batch_size=128,conv_filters=64,dropout=0.6600,lr=0.1000 </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.102667</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9131</td><td style=\"text-align: right;\">            38.5885 </td><td style=\"text-align: right;\">           2.66247</td><td style=\"text-align: right;\">      38.5885 </td><td style=\"text-align: right;\"> 1670789775</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00073</td><td style=\"text-align: right;\">   0.00504041</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00074</td><td>2022-12-11_20-16-47</td><td>True  </td><td>                </td><td>34ee6c2ffc5849ed9e148650b47b9a92</td><td>74_batch_size=256,conv_filters=64,dropout=0.6600,lr=0.1000 </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.106783</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9263</td><td style=\"text-align: right;\">            27.5173 </td><td style=\"text-align: right;\">           1.81393</td><td style=\"text-align: right;\">      27.5173 </td><td style=\"text-align: right;\"> 1670789807</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00074</td><td style=\"text-align: right;\">   0.00328469</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00075</td><td>2022-12-11_20-17-51</td><td>True  </td><td>                </td><td>d799335c98e246f9aac1dda4d4fe9d3d</td><td>75_batch_size=64,conv_filters=128,dropout=0.6600,lr=0.1000 </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.104133</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9389</td><td style=\"text-align: right;\">            60.4529 </td><td style=\"text-align: right;\">           4.62078</td><td style=\"text-align: right;\">      60.4529 </td><td style=\"text-align: right;\"> 1670789871</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00075</td><td style=\"text-align: right;\">   0.00309324</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00076</td><td>2022-12-11_20-18-46</td><td>True  </td><td>                </td><td>fd288aacd26b4bb69e87bcd23026cdc4</td><td>76_batch_size=128,conv_filters=128,dropout=0.6600,lr=0.1000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.1049  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9524</td><td style=\"text-align: right;\">            50.572  </td><td style=\"text-align: right;\">           3.76983</td><td style=\"text-align: right;\">      50.572  </td><td style=\"text-align: right;\"> 1670789926</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00076</td><td style=\"text-align: right;\">   0.0031445 </td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00077</td><td>2022-12-11_20-19-30</td><td>True  </td><td>                </td><td>7afd6b96e25146ee97d6e1144b5a7640</td><td>77_batch_size=256,conv_filters=128,dropout=0.6600,lr=0.1000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.105967</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9654</td><td style=\"text-align: right;\">            39.0538 </td><td style=\"text-align: right;\">           2.72972</td><td style=\"text-align: right;\">      39.0538 </td><td style=\"text-align: right;\"> 1670789970</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00077</td><td style=\"text-align: right;\">   0.00458765</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00078</td><td>2022-12-11_20-21-00</td><td>True  </td><td>                </td><td>4e18f31eb0ab4674a96b25350c92e3e9</td><td>78_batch_size=64,conv_filters=256,dropout=0.6600,lr=0.1000 </td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.1054  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9782</td><td style=\"text-align: right;\">            84.9002 </td><td style=\"text-align: right;\">           6.64334</td><td style=\"text-align: right;\">      84.9002 </td><td style=\"text-align: right;\"> 1670790060</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00078</td><td style=\"text-align: right;\">   0.00324202</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00079</td><td>2022-12-11_20-22-12</td><td>True  </td><td>                </td><td>fa5d28047a494dc5b87ec0afb05f1347</td><td>79_batch_size=128,conv_filters=256,dropout=0.6600,lr=0.1000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.1052  </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 9920</td><td style=\"text-align: right;\">            68.2888 </td><td style=\"text-align: right;\">           5.65424</td><td style=\"text-align: right;\">      68.2888 </td><td style=\"text-align: right;\"> 1670790132</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00079</td><td style=\"text-align: right;\">   0.00337744</td></tr>\n",
              "<tr><td>train_mnist_2c8b9_00080</td><td>2022-12-11_20-23-16</td><td>True  </td><td>                </td><td>a8b9c951552d4c4a8aa45ac8c338227a</td><td>80_batch_size=256,conv_filters=256,dropout=0.6600,lr=0.1000</td><td>db50b83514e2</td><td style=\"text-align: right;\">                        12</td><td style=\"text-align: right;\">       0.106333</td><td>172.28.0.12</td><td style=\"text-align: right;\">10059</td><td style=\"text-align: right;\">            59.3706 </td><td style=\"text-align: right;\">           4.49797</td><td style=\"text-align: right;\">      59.3706 </td><td style=\"text-align: right;\"> 1670790196</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                  12</td><td>2c8b9_00080</td><td style=\"text-align: right;\">   0.00330544</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=2878)\u001b[0m 2022-12-11 19:44:27.050535: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2878)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2878)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2948)\u001b[0m 2022-12-11 19:44:39.116584: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2948)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=2948)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m 2022-12-11 19:44:51.017079: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3017)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m 2022-12-11 19:45:04.810105: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3088)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3157)\u001b[0m 2022-12-11 19:45:17.827006: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3157)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3157)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3227)\u001b[0m 2022-12-11 19:45:29.912600: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3227)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3227)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3295)\u001b[0m 2022-12-11 19:45:46.467341: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3295)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3295)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3362)\u001b[0m 2022-12-11 19:46:01.801456: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3362)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3362)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3429)\u001b[0m 2022-12-11 19:46:15.891658: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3429)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3429)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3498)\u001b[0m 2022-12-11 19:46:28.910911: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3498)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3498)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3564)\u001b[0m 2022-12-11 19:46:40.781777: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3564)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3564)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3631)\u001b[0m 2022-12-11 19:46:51.740235: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3631)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3631)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3698)\u001b[0m 2022-12-11 19:47:05.830441: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3698)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3698)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3765)\u001b[0m 2022-12-11 19:47:18.818318: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3765)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3765)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3831)\u001b[0m 2022-12-11 19:47:30.824750: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3831)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3831)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3899)\u001b[0m 2022-12-11 19:47:46.758801: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3899)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3899)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3967)\u001b[0m 2022-12-11 19:48:01.822119: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3967)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=3967)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4034)\u001b[0m 2022-12-11 19:48:15.868979: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4034)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4034)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4103)\u001b[0m 2022-12-11 19:48:28.763280: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4103)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4103)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4169)\u001b[0m 2022-12-11 19:48:40.789244: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4169)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4169)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4240)\u001b[0m 2022-12-11 19:48:53.761609: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4240)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4240)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4308)\u001b[0m 2022-12-11 19:49:08.584716: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4308)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4308)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4376)\u001b[0m 2022-12-11 19:49:22.833576: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4376)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4376)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4448)\u001b[0m 2022-12-11 19:49:37.967611: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4448)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4448)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4516)\u001b[0m 2022-12-11 19:49:53.823777: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4516)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4516)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4585)\u001b[0m 2022-12-11 19:50:08.880322: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4585)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4585)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4657)\u001b[0m 2022-12-11 19:50:28.160987: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4657)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4657)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4729)\u001b[0m 2022-12-11 19:50:41.953404: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4729)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4729)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4799)\u001b[0m 2022-12-11 19:50:53.793694: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4799)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4799)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4868)\u001b[0m 2022-12-11 19:51:04.871480: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4868)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4868)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4935)\u001b[0m 2022-12-11 19:51:18.855978: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4935)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=4935)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5003)\u001b[0m 2022-12-11 19:51:31.807148: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5003)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5003)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5076)\u001b[0m 2022-12-11 19:51:46.813872: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5076)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5076)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5151)\u001b[0m 2022-12-11 19:52:09.951531: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5151)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5151)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5221)\u001b[0m 2022-12-11 19:52:25.284148: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5221)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5221)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5290)\u001b[0m 2022-12-11 19:52:41.055789: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5290)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5290)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5357)\u001b[0m 2022-12-11 19:52:54.149574: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5357)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5357)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5424)\u001b[0m 2022-12-11 19:53:06.050018: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5424)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5424)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5491)\u001b[0m 2022-12-11 19:53:17.958971: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5491)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5491)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5559)\u001b[0m 2022-12-11 19:53:32.000531: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5559)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5559)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5634)\u001b[0m 2022-12-11 19:53:49.055025: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5634)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5634)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5701)\u001b[0m 2022-12-11 19:54:01.127354: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5701)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5701)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5768)\u001b[0m 2022-12-11 19:54:17.122621: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5768)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5768)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5835)\u001b[0m 2022-12-11 19:54:31.939703: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5835)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5835)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5909)\u001b[0m 2022-12-11 19:54:51.024417: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5909)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5909)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5975)\u001b[0m 2022-12-11 19:55:03.985861: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5975)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=5975)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6047)\u001b[0m 2022-12-11 19:55:18.946657: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6047)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6047)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6119)\u001b[0m 2022-12-11 19:55:32.007155: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6119)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6119)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6193)\u001b[0m 2022-12-11 19:55:52.368070: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6193)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6193)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6267)\u001b[0m 2022-12-11 19:56:10.041042: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6267)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6267)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6339)\u001b[0m 2022-12-11 19:56:24.961333: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6339)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6339)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6413)\u001b[0m 2022-12-11 19:56:47.981601: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6413)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6413)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6481)\u001b[0m 2022-12-11 19:57:02.959016: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6481)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6481)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6559)\u001b[0m 2022-12-11 19:57:22.008303: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6559)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6559)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6690)\u001b[0m 2022-12-11 19:58:16.159559: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6690)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6690)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6824)\u001b[0m 2022-12-11 19:58:57.042398: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6824)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6824)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6957)\u001b[0m 2022-12-11 19:59:29.041536: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6957)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=6957)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7101)\u001b[0m 2022-12-11 20:00:34.148588: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7101)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7101)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7239)\u001b[0m 2022-12-11 20:01:29.221568: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7239)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7239)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7369)\u001b[0m 2022-12-11 20:02:11.054815: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7369)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7369)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7525)\u001b[0m 2022-12-11 20:03:41.117515: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7525)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7525)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7676)\u001b[0m 2022-12-11 20:04:54.236542: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7676)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7676)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7810)\u001b[0m 2022-12-11 20:05:59.068183: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7810)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7810)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7941)\u001b[0m 2022-12-11 20:06:55.174513: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7941)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=7941)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8069)\u001b[0m 2022-12-11 20:07:37.036985: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8069)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8069)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8194)\u001b[0m 2022-12-11 20:08:08.208138: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8194)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8194)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8327)\u001b[0m 2022-12-11 20:09:14.082844: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8327)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8327)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8458)\u001b[0m 2022-12-11 20:10:09.262542: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8458)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8458)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8586)\u001b[0m 2022-12-11 20:10:52.188823: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8586)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8586)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8724)\u001b[0m 2022-12-11 20:12:24.830867: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8724)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8724)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8859)\u001b[0m 2022-12-11 20:13:38.281635: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8859)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8859)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8994)\u001b[0m 2022-12-11 20:14:43.236675: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8994)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=8994)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9131)\u001b[0m 2022-12-11 20:15:39.308501: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9131)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9131)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9263)\u001b[0m 2022-12-11 20:16:21.573883: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9263)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9263)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9389)\u001b[0m 2022-12-11 20:16:53.279545: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9389)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9389)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9524)\u001b[0m 2022-12-11 20:17:58.310673: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9524)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9524)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9654)\u001b[0m 2022-12-11 20:18:54.076737: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9654)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9654)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9782)\u001b[0m 2022-12-11 20:19:37.262915: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9782)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9782)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9920)\u001b[0m 2022-12-11 20:21:06.302837: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9920)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=9920)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=10059)\u001b[0m 2022-12-11 20:22:19.264337: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=10059)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=10059)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "2022-12-11 20:23:16,991\tINFO tune.py:777 -- Total run time: 2350.20 seconds (2350.00 seconds for the tuning loop).\n"
          ]
        }
      ],
      "source": [
        "#---------------Gridsearch---------------------\n",
        "analysis = tune.run(\n",
        "        train_mnist,\n",
        "        name=\"exp\",\n",
        "        metric=\"mean_accuracy\",\n",
        "        mode=\"max\",\n",
        "        stop={\n",
        "            \"mean_accuracy\": 0.90,\n",
        "        },\n",
        "        resources_per_trial={\n",
        "            \"gpu\": 1\n",
        "        },\n",
        "        config={\n",
        "            \"conv_filters\": tune.grid_search([64, 128, 256]),\n",
        "            \"lr\": tune.grid_search([0.001,0.01,0.1]),\n",
        "            \"batch_size\": tune.grid_search([64,128,256]),\n",
        "            \"dropout\": tune.grid_search([0, .33, .66])\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqQW-x5JPHCU",
        "outputId": "a855109f-fbd9-4b5a-f9c8-370965a9cd00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.2-py3-none-any.whl (17 kB)\n",
            "Collecting colorama>=0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.2 colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "XfQrltnOOHeK",
        "outputId": "7a93919e-9463-4ff0-df79-87a5a640adc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-11 22:35:43,062\tWARNING bayesopt_search.py:423 -- BayesOpt does not support specific sampling methods. The Uniform sampler will be dropped.\n",
            "2022-12-11 22:35:43,065\tWARNING bayesopt_search.py:423 -- BayesOpt does not support specific sampling methods. The Uniform sampler will be dropped.\n",
            "2022-12-11 22:35:43,068\tWARNING bayesopt_search.py:423 -- BayesOpt does not support specific sampling methods. The Uniform sampler will be dropped.\n",
            "2022-12-11 22:35:43,069\tWARNING bayesopt_search.py:423 -- BayesOpt does not support specific sampling methods. The Uniform sampler will be dropped.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2022-12-11 22:49:28</td></tr>\n",
              "<tr><td>Running for: </td><td>00:13:45.29        </td></tr>\n",
              "<tr><td>Memory:      </td><td>1.9/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:T4)\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_filters</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2599aa8e</td><td>TERMINATED</td><td>172.28.0.12:1002</td><td style=\"text-align: right;\">    135.912 </td><td style=\"text-align: right;\">      246.537 </td><td style=\"text-align: right;\">0.731994 </td><td style=\"text-align: right;\">0.00101973</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         819.982</td><td style=\"text-align: right;\">  0.973117</td></tr>\n",
              "<tr><td>train_mnist_28c03b9c</td><td>TERMINATED</td><td>172.28.0.12:1041</td><td style=\"text-align: right;\">     93.9556</td><td style=\"text-align: right;\">       93.9509</td><td style=\"text-align: right;\">0.0580836</td><td style=\"text-align: right;\">0.00107324</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         508.505</td><td style=\"text-align: right;\">  0.986483</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(train_mnist pid=1002)\u001b[0m 2022-12-11 22:35:49.686094: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1002)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1002)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1041)\u001b[0m 2022-12-11 22:35:57.020464: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1041)\u001b[0m /usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist pid=1041)\u001b[0m   super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name          </th><th style=\"text-align: right;\">  accuracy</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag                                                      </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_2599aa8e</td><td style=\"text-align: right;\">  0.973117</td><td>2022-12-11_22-49-28</td><td>True  </td><td>                </td><td>b2650d94fd584f758090ffdb71fbcadd</td><td>1_batch_size=135.9117,conv_filters=246.5371,dropout=0.7320,lr=0.0010</td><td>3ce0fe93336a</td><td style=\"text-align: right;\">                         2</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 1002</td><td style=\"text-align: right;\">             819.982</td><td style=\"text-align: right;\">           284.745</td><td style=\"text-align: right;\">       819.982</td><td style=\"text-align: right;\"> 1670798968</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>2599aa8e  </td><td style=\"text-align: right;\">   0.00346756</td></tr>\n",
              "<tr><td>train_mnist_28c03b9c</td><td style=\"text-align: right;\">  0.986483</td><td>2022-12-11_22-44-24</td><td>True  </td><td>                </td><td>84e0b431ab1241aca1298ab06ef095ca</td><td>2_batch_size=93.9556,conv_filters=93.9509,dropout=0.0581,lr=0.0011  </td><td>3ce0fe93336a</td><td style=\"text-align: right;\">                         2</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 1041</td><td style=\"text-align: right;\">             508.505</td><td style=\"text-align: right;\">           253.163</td><td style=\"text-align: right;\">       508.505</td><td style=\"text-align: right;\"> 1670798664</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>28c03b9c  </td><td style=\"text-align: right;\">   0.0161686 </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-11 22:49:28,479\tINFO tune.py:777 -- Total run time: 825.43 seconds (825.29 seconds for the tuning loop).\n"
          ]
        }
      ],
      "source": [
        "#------------ Baysian search-----------\n",
        "from ray.tune.search import ConcurrencyLimiter\n",
        "from ray.tune.search.bayesopt import BayesOptSearch\n",
        "algo = BayesOptSearch(utility_kwargs={\"kind\": \"ucb\", \"kappa\": 2.5, \"xi\": 0.0})\n",
        "algo = ConcurrencyLimiter(algo, max_concurrent=4)\n",
        "\n",
        "search_space = {\n",
        "    \"conv_filters\": tune.uniform(64, 256),\n",
        "    \"lr\": tune.uniform(0.0009, 0.0011),\n",
        "    \"batch_size\": tune.uniform(64, 256),\n",
        "    \"dropout\": tune.uniform(0, 1)\n",
        "}\n",
        "tuner = tune.Tuner(\n",
        "    train_mnist,\n",
        "    tune_config=tune.TuneConfig(\n",
        "        metric=\"accuracy\",\n",
        "        mode=\"max\",\n",
        "        search_alg=algo,\n",
        "        num_samples=2,\n",
        "    ),\n",
        "    param_space=search_space\n",
        ")\n",
        "results = tuner.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjMJHVnEcKBW"
      },
      "source": [
        "2. For each of the search technique in part 1, display the time taken to perform the analysis and display the hyperparameters for the best model. (2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JioO50khcKBX",
        "outputId": "bd4f5577-aa57-4165-f503-7bdd8269a66f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'batch_size': 256, 'conv_filters': 128, 'dropout': 0.16614474270272972, 'lr': 0.0078739746012135}\n",
            "{'conv_filters': 128, 'lr': 0.01, 'batch_size': 256, 'dropout': 0}\n"
          ]
        }
      ],
      "source": [
        "#Hyperband best model---------\n",
        "\n",
        "print(Hype_analysis.get_best_config(\"mean_accuracy\", \"max\"))\n",
        "#Grid Search best model---------\n",
        "print(analysis.best_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH9MSSxCYo0F",
        "outputId": "23d484fe-f3a6-4d7b-bedb-51b2abdb8a06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Result(metrics={'accuracy': 0.9864833354949951, 'done': True, 'trial_id': '28c03b9c', 'experiment_tag': '2_batch_size=93.9556,conv_filters=93.9509,dropout=0.0581,lr=0.0011'}, error=None, log_dir=PosixPath('/root/ray_results/train_mnist_2022-12-11_22-35-43/train_mnist_28c03b9c_2_batch_size=93.9556,conv_filters=93.9509,dropout=0.0581,lr=0.0011_2022-12-11_22-35-48'))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Bayesian Search--------------------\n",
        "results.get_best_result(\"accuracy\", \"max\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcfeT_FLcKBX"
      },
      "source": [
        "3. What are your observations regarding time taken and performance of the best model? (2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n3dmbDW-cKBY"
      },
      "source": [
        "The best models were not the most time consuming for grid search and \n",
        "\n",
        "For the Bayesian Search algorithm we had to change the lr rate a little otherwise the time for search would take a long time because it was not converging. \n",
        "\n",
        "Also, once the learning rate was adjusted the best model was not the most time consuming. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2a0f08725565d2d00e70b9fae99b105541271f7be4baa13607a6e77e1d2c8c73"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
