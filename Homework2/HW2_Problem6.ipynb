{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6 - Batch Normalization, Dropout, MNIST\n",
    "\n",
    "Batch normalization and Dropout are used as effective regularization techniques. However its not clear which one should be preferred and whether their benefits add up when used in conjunction. In this problem we will compare batch normalization, dropout, and their conjunction using MNIST and LeNet-5 (see e.g., http://yann.lecun.com/exdb/lenet/). LeNet-5 is one of the earliest convolutional neural network developed for image classification and its implementation in all major framework is available. You can refer to Lecture 3 slides for definition of standardization and batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Explain the terms co-adaptation and internal covariance-shift. Use examples if needed. You may need to refer to two papers mentioned below to answer this question. (Papers are in my ipad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Batch normalization is traditionally used in hidden layers, for input layer standard normalization is used. In standard normalization the mean and standard deviation are calculated using the entire training dataset whereas in batch normalization these statistics are calculated for each mini-batch. Train LeNet-5 with standard normalization of input and batch normalization for hidden layers. What are the learned batch norm parameters for each layer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "norm_layer = Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "\n",
    "print(X_train.shape[1:])\n",
    "model = Sequential()\n",
    "# model.add(norm_layer)\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(84, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 48)        38448     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 10, 10, 48)       192       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 48)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               307456    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                21588     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 84)               336       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,854\n",
      "Trainable params: 370,014\n",
      "Non-trainable params: 840\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 43s 70ms/step - loss: 0.0999 - accuracy: 0.9708\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 49s 81ms/step - loss: 0.0371 - accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 58s 97ms/step - loss: 0.0235 - accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 45s 75ms/step - loss: 0.0189 - accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 46s 76ms/step - loss: 0.0163 - accuracy: 0.9947\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 47s 79ms/step - loss: 0.0133 - accuracy: 0.9958\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 48s 79ms/step - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 50s 83ms/step - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 55s 92ms/step - loss: 0.0081 - accuracy: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa11c2d0100>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build()\n",
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'], optimizer='adam')\n",
    "model.fit(X_train, Y_train,epochs= 10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'batch_normalization_4/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0.73450094, 0.9141017 , 1.1243606 , 0.5339626 , 1.0276673 ,\n",
      "       1.094946  , 1.1216943 , 0.6867287 , 1.042147  , 1.1035712 ,\n",
      "       0.81167233, 1.2454077 , 1.1565273 , 1.0886773 , 1.1389145 ,\n",
      "       1.1105791 , 0.7370587 , 0.9640114 , 0.99103576, 0.6292723 ,\n",
      "       1.027613  , 0.55818063, 0.9629782 , 0.81738734, 0.97605586,\n",
      "       1.0170078 , 1.082851  , 0.7180289 , 1.0984238 , 1.1171322 ,\n",
      "       0.62764496, 0.6367039 ], dtype=float32)> <tf.Variable 'batch_normalization_4/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([ 0.17674018,  0.13955158,  0.08101559, -0.08352515,  0.10733306,\n",
      "        0.15793419,  0.03258097,  0.1062014 ,  0.17719603,  0.12362269,\n",
      "        0.1497542 , -0.20558745, -0.00795944,  0.22255063, -0.04652973,\n",
      "        0.22432585,  0.02666678,  0.20083572,  0.16422936,  0.11957443,\n",
      "       -0.02068507,  0.1925204 ,  0.19593234,  0.0638132 ,  0.09191626,\n",
      "        0.22105731,  0.16966516,  0.1333197 ,  0.195354  ,  0.1125783 ,\n",
      "        0.10951778,  0.08248252], dtype=float32)>\n",
      "<tf.Variable 'batch_normalization_5/gamma:0' shape=(48,) dtype=float32, numpy=\n",
      "array([1.0018107 , 0.84512526, 0.8812051 , 0.8077941 , 0.8109653 ,\n",
      "       1.2489842 , 1.1286631 , 0.90114695, 1.0399543 , 1.0626868 ,\n",
      "       0.84114295, 0.8051295 , 1.0934527 , 0.90928847, 0.97865254,\n",
      "       1.0454082 , 0.9849901 , 1.0553747 , 1.0977461 , 1.024475  ,\n",
      "       0.8082591 , 0.90651107, 0.91528255, 1.0852716 , 0.8744668 ,\n",
      "       0.9229419 , 1.1744832 , 0.94796515, 0.97613496, 0.9719823 ,\n",
      "       1.069503  , 0.84176743, 0.9763394 , 0.83588666, 0.87984365,\n",
      "       1.0382934 , 1.0608535 , 0.9771497 , 0.9514339 , 1.129987  ,\n",
      "       0.9071419 , 1.0962406 , 0.9686107 , 0.9285244 , 1.0942826 ,\n",
      "       0.8847352 , 1.1673887 , 1.0106925 ], dtype=float32)> <tf.Variable 'batch_normalization_5/beta:0' shape=(48,) dtype=float32, numpy=\n",
      "array([-0.11491059, -0.18107377, -0.17698115, -0.07052396, -0.1380996 ,\n",
      "       -0.17553589, -0.14653501, -0.18327233, -0.13110101, -0.17782627,\n",
      "       -0.19646333, -0.05944131, -0.19954333, -0.12167209, -0.17440851,\n",
      "       -0.10750314, -0.12775548, -0.16025315, -0.05221483, -0.11610194,\n",
      "       -0.09129272, -0.11026869, -0.16220848, -0.1645967 , -0.15224561,\n",
      "       -0.1365686 , -0.11020917, -0.11309163, -0.1874695 , -0.13766867,\n",
      "       -0.06340905, -0.18325533, -0.13733974, -0.17553233, -0.0965318 ,\n",
      "       -0.06452616, -0.1253762 , -0.12764047, -0.22977328, -0.06624662,\n",
      "       -0.16125175, -0.10375471, -0.20402688, -0.2641764 , -0.11708312,\n",
      "       -0.1624704 , -0.12588198, -0.09392143], dtype=float32)>\n",
      "<tf.Variable 'batch_normalization_6/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1.0114212 , 1.1325338 , 0.98553747, 1.0690606 , 0.99755275,\n",
      "       1.0102744 , 1.080628  , 0.9759396 , 0.99276245, 0.9399182 ,\n",
      "       0.9356877 , 0.97245896, 1.02375   , 0.9596001 , 0.99858576,\n",
      "       1.0277597 , 0.8885809 , 0.99238765, 0.96176684, 0.98418313,\n",
      "       1.0288105 , 1.0688089 , 0.9436476 , 1.0048013 , 1.0114514 ,\n",
      "       1.0333698 , 1.0213251 , 0.9592082 , 1.0027562 , 1.0079072 ,\n",
      "       1.1219823 , 0.9657048 , 0.99468285, 1.1332031 , 0.98842925,\n",
      "       0.9507099 , 0.93617046, 1.0162832 , 1.0003506 , 0.9637836 ,\n",
      "       0.84889036, 0.977466  , 0.9694678 , 0.98897004, 1.000433  ,\n",
      "       1.1589539 , 0.93122315, 1.1685003 , 0.9819131 , 1.0495746 ,\n",
      "       0.93044484, 1.0639265 , 0.92416275, 1.064548  , 1.087517  ,\n",
      "       0.9097386 , 0.9125027 , 0.99466366, 0.9503946 , 0.91603076,\n",
      "       0.9674487 , 1.0460052 , 0.98150444, 1.0735468 , 1.0053447 ,\n",
      "       0.9636167 , 0.9166833 , 0.8185829 , 1.0737495 , 0.98410827,\n",
      "       0.94089544, 0.9521122 , 0.94376606, 0.99429595, 0.96784115,\n",
      "       1.1220435 , 0.8726745 , 1.0615684 , 0.9502829 , 0.94404936,\n",
      "       0.98780143, 1.0998079 , 0.94335914, 0.9915238 , 0.95553154,\n",
      "       0.9398079 , 1.0973413 , 1.0068728 , 1.0154139 , 0.981448  ,\n",
      "       0.9727727 , 1.0551707 , 0.974925  , 0.98448694, 0.89082086,\n",
      "       0.9315841 , 0.84682727, 1.0240197 , 0.96456754, 0.9292658 ,\n",
      "       0.979201  , 1.000361  , 1.0585591 , 0.9710804 , 0.99717253,\n",
      "       0.9739604 , 0.94488657, 0.9760017 , 1.0210421 , 0.8590973 ,\n",
      "       0.99527854, 0.92002875, 0.8789251 , 1.0095251 , 0.96913624,\n",
      "       1.0426266 , 0.97587764, 0.89256316, 1.0402584 , 0.9827563 ,\n",
      "       1.0240325 , 1.0138009 , 1.0435618 , 1.0415506 , 1.057832  ,\n",
      "       1.1019601 , 1.0422852 , 0.9796563 , 0.84947115, 0.9545382 ,\n",
      "       0.99693036, 0.9627443 , 1.0842137 , 0.894199  , 0.9356592 ,\n",
      "       1.0768522 , 1.042522  , 1.0589287 , 0.9882805 , 0.98673046,\n",
      "       0.97547036, 1.0039995 , 0.940959  , 0.83331406, 0.943511  ,\n",
      "       1.0282286 , 1.0174282 , 0.86550933, 1.025407  , 0.9659127 ,\n",
      "       0.9629577 , 1.0163083 , 0.93959343, 1.0044806 , 1.2085823 ,\n",
      "       1.0435929 , 1.0804771 , 1.0042039 , 1.0984292 , 1.0631818 ,\n",
      "       1.0062602 , 1.0439551 , 0.9961575 , 0.9700122 , 1.1032833 ,\n",
      "       0.9873224 , 0.99548435, 0.9595598 , 0.9804642 , 1.0673844 ,\n",
      "       0.9959186 , 1.0376395 , 0.8471806 , 1.049776  , 0.9749469 ,\n",
      "       1.0236746 , 1.0983824 , 1.0051234 , 0.9493986 , 0.94444376,\n",
      "       1.0156583 , 1.0074624 , 1.0001136 , 0.95572203, 0.99238455,\n",
      "       1.024752  , 0.98662764, 1.0602995 , 0.96618795, 0.89329195,\n",
      "       0.9767565 , 1.046546  , 0.96670717, 1.0758486 , 0.9840682 ,\n",
      "       0.9619896 , 1.0021166 , 1.0825883 , 1.0350363 , 0.7908982 ,\n",
      "       1.000521  , 1.0252097 , 0.89857423, 1.0606273 , 0.9599817 ,\n",
      "       0.9412235 , 1.0241731 , 1.075363  , 1.0288792 , 0.9724031 ,\n",
      "       0.9462745 , 1.017142  , 1.0089657 , 0.9839564 , 1.0136203 ,\n",
      "       1.1748188 , 0.9128252 , 0.9737679 , 1.0217408 , 1.0372775 ,\n",
      "       1.0325773 , 1.0069056 , 0.85907215, 1.0295906 , 0.93932897,\n",
      "       0.99067473, 0.95602524, 1.109612  , 1.0230178 , 0.9635519 ,\n",
      "       1.1464887 , 0.98505455, 0.9274453 , 1.0799032 , 0.98387206,\n",
      "       0.98805374, 1.0770524 , 1.108381  , 0.9935387 , 0.79271394,\n",
      "       1.0262449 , 0.94566643, 1.1154062 , 0.90436244, 0.90956175,\n",
      "       0.86131346, 1.0524615 , 0.97479546, 0.99342763, 0.84660894,\n",
      "       0.9528964 , 0.95134753, 0.95058024, 0.91521764, 0.87987745,\n",
      "       1.123102  ], dtype=float32)> <tf.Variable 'batch_normalization_6/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-6.54283315e-02,  4.59207483e-02, -7.19544590e-02,  3.46338637e-02,\n",
      "       -7.08791474e-03, -1.01219518e-02, -5.83007298e-02,  1.99628156e-02,\n",
      "        9.39372480e-02, -2.74094362e-02, -9.80004892e-02, -2.86360495e-02,\n",
      "       -4.42898758e-02,  5.95476758e-03, -3.77223864e-02, -6.14428427e-03,\n",
      "       -5.65263501e-04,  7.61603490e-02, -5.14337718e-02,  1.05173573e-01,\n",
      "        6.12497106e-02, -3.52546051e-02,  1.24058290e-03,  1.21440992e-01,\n",
      "       -8.69830027e-02, -1.31817507e-02, -4.96913381e-02,  1.36392042e-01,\n",
      "        1.09193390e-02, -3.47158313e-02, -5.19061051e-02,  4.26784419e-02,\n",
      "       -3.88353318e-02, -4.73285057e-02, -4.51331539e-03, -1.32969394e-01,\n",
      "        1.65350333e-01,  2.87928525e-02, -6.47710869e-03, -6.69142902e-02,\n",
      "       -1.39069051e-01, -1.87668130e-02,  4.80200946e-02, -4.97959591e-02,\n",
      "       -3.68552692e-02,  5.15506417e-03,  1.25156958e-02, -3.26519869e-02,\n",
      "       -3.14790048e-02, -4.10808343e-03,  3.21092643e-02, -1.04744494e-01,\n",
      "       -5.36454655e-02,  3.13236453e-02, -8.61397199e-03, -4.88758683e-02,\n",
      "       -2.35408489e-02,  1.38444714e-02, -4.25810255e-02,  3.61841768e-02,\n",
      "        1.74055733e-02, -7.15177655e-02, -7.63484389e-02,  2.07678266e-02,\n",
      "       -8.36184472e-02, -6.49427623e-02, -1.07798837e-01,  1.56290606e-02,\n",
      "       -6.07315712e-02,  3.64712328e-02, -1.15295447e-01, -5.35478815e-02,\n",
      "        1.20681360e-01,  3.76648344e-02,  6.12757588e-03,  8.69961455e-02,\n",
      "        5.04068695e-02,  1.21642530e-01,  4.85282540e-02,  6.53527491e-03,\n",
      "       -8.81151110e-03, -1.42488340e-02, -7.64928982e-02, -3.21920551e-02,\n",
      "       -7.79899284e-02,  4.04955186e-02,  1.58822075e-01,  8.84639546e-02,\n",
      "        5.99979311e-02,  1.24244681e-02,  1.27720281e-01, -1.57220196e-02,\n",
      "        4.24952954e-02,  1.64888501e-02, -8.58393013e-02,  3.16257402e-02,\n",
      "        1.35863172e-02,  7.16171600e-03,  7.42430463e-02, -3.22827585e-02,\n",
      "        7.12597892e-02, -4.09192555e-02,  1.37680583e-02,  7.92304799e-02,\n",
      "        1.13170361e-04, -8.36581178e-03,  2.01739315e-02, -4.26713750e-02,\n",
      "       -3.84801775e-02, -3.85225676e-02,  5.41006215e-02, -1.06428571e-01,\n",
      "        6.29269332e-02,  2.84178834e-02, -7.62629807e-02,  4.44372892e-02,\n",
      "       -1.41079305e-02, -9.10345688e-02,  8.87381807e-02,  2.21037474e-02,\n",
      "       -4.16156650e-02,  2.22067069e-02, -7.84171447e-02, -3.23916189e-02,\n",
      "       -1.61637813e-02, -1.66537445e-02, -8.25244710e-02, -2.41577625e-02,\n",
      "        7.57464096e-02,  2.82721650e-02, -1.25605604e-02,  6.80493042e-02,\n",
      "        5.71523458e-02,  5.88956987e-03, -3.70123163e-02,  1.14666209e-01,\n",
      "        1.67176791e-03, -1.99256223e-02, -7.85169099e-03,  1.86320301e-02,\n",
      "        5.47028594e-02, -8.45256727e-04, -8.56769383e-02,  7.62111396e-02,\n",
      "        3.21089253e-02,  5.80850542e-02,  5.66847958e-02, -9.86037701e-02,\n",
      "       -4.76429723e-02, -6.83308346e-03,  1.05174080e-01,  6.86638653e-02,\n",
      "       -9.93395690e-03, -9.26031768e-02, -4.48663235e-02,  5.64816855e-02,\n",
      "        2.75849402e-02,  4.32241783e-02, -5.76546192e-02, -5.36660627e-02,\n",
      "       -5.96532300e-02,  4.72457819e-02,  2.40803510e-02,  4.36107963e-02,\n",
      "        4.54152338e-02,  5.02656996e-02,  1.13523871e-01, -6.46115094e-02,\n",
      "        1.00250125e-01,  7.99082499e-03, -2.41203510e-04,  5.66940829e-02,\n",
      "       -4.57074610e-04,  7.47312733e-05,  1.85828172e-02,  8.70036110e-02,\n",
      "       -3.60717550e-02, -1.63484126e-01,  8.59778672e-02, -3.30788530e-02,\n",
      "        9.87747591e-03, -3.99583839e-02, -6.80181533e-02, -9.89463776e-02,\n",
      "       -1.39795234e-02, -7.67363310e-02,  4.76469509e-02, -1.82769336e-02,\n",
      "       -1.25327772e-02,  6.45054653e-02,  1.61261633e-02,  6.43663555e-02,\n",
      "       -8.66909232e-03, -1.08758295e-02, -7.05068335e-02, -8.40401426e-02,\n",
      "       -8.35407823e-02,  1.05430596e-02,  7.79180378e-02,  2.48619020e-02,\n",
      "       -3.97067517e-03, -1.17501765e-02,  1.97726749e-02,  8.43557641e-02,\n",
      "       -7.94659276e-03, -6.70493469e-02,  2.64021996e-02,  2.04183231e-03,\n",
      "        5.34033142e-02, -4.98340838e-02, -8.97285901e-03, -5.23216426e-02,\n",
      "       -8.76780972e-02,  5.43479547e-02,  2.75515504e-02, -6.20603375e-02,\n",
      "        5.23798950e-02,  2.84289196e-03,  4.00522538e-02,  5.23134246e-02,\n",
      "       -7.63162822e-02,  9.52457488e-02, -8.91874060e-02,  3.67878973e-02,\n",
      "        1.83338579e-02, -1.12692527e-02, -1.64750405e-03,  3.01526468e-02,\n",
      "        1.20832752e-02, -9.12823752e-02,  1.67166535e-02, -1.01370402e-01,\n",
      "       -2.73917150e-02, -9.36780870e-02, -6.24053702e-02, -3.74438986e-02,\n",
      "       -1.81074776e-02,  1.66326966e-02, -8.12974013e-03,  3.09701487e-02,\n",
      "        3.35104130e-02,  6.88851206e-03, -1.91632174e-02,  1.02832340e-01,\n",
      "        1.02008440e-01,  5.56988418e-02,  3.25748473e-02,  1.15679398e-01,\n",
      "        1.41646102e-01,  4.43579070e-02,  4.19447683e-02,  1.06569849e-01,\n",
      "        3.14986855e-02,  2.79464270e-03,  6.06568269e-02,  1.99322775e-02],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'batch_normalization_7/gamma:0' shape=(84,) dtype=float32, numpy=\n",
      "array([1.3700463, 1.201827 , 1.2707173, 1.1682822, 1.2473868, 1.1387174,\n",
      "       1.1162319, 1.2040786, 1.1510291, 1.1871076, 1.183501 , 1.183669 ,\n",
      "       1.2840698, 1.2482715, 1.2500892, 1.1162896, 1.1792903, 1.1541246,\n",
      "       1.3237331, 1.1670867, 1.1650286, 1.1351366, 1.2559314, 1.0518256,\n",
      "       1.1734389, 1.2266947, 1.2265272, 1.1901295, 1.2141237, 1.1651413,\n",
      "       1.1498967, 1.239383 , 1.3097001, 1.3465681, 1.1486216, 1.2528633,\n",
      "       1.2225937, 1.161158 , 1.2396511, 1.3331345, 1.1853764, 1.2375245,\n",
      "       1.1885648, 1.1870648, 1.1218325, 1.2332164, 1.3422126, 1.162867 ,\n",
      "       1.192692 , 1.1849741, 1.167483 , 1.2323006, 1.219156 , 1.2446159,\n",
      "       1.2551892, 1.1704754, 1.0973576, 1.087385 , 1.1663512, 1.1893324,\n",
      "       1.2923155, 1.1236445, 1.1976366, 1.2160685, 1.1360637, 1.113064 ,\n",
      "       1.0923649, 1.2078348, 1.1540829, 1.1773653, 1.1685401, 1.1313447,\n",
      "       1.2215803, 1.1266177, 1.208085 , 1.2409046, 1.1316855, 1.2391354,\n",
      "       1.162139 , 1.2170054, 1.1397997, 1.2461962, 1.2402347, 1.1460599],\n",
      "      dtype=float32)> <tf.Variable 'batch_normalization_6/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([-6.54283315e-02,  4.59207483e-02, -7.19544590e-02,  3.46338637e-02,\n",
      "       -7.08791474e-03, -1.01219518e-02, -5.83007298e-02,  1.99628156e-02,\n",
      "        9.39372480e-02, -2.74094362e-02, -9.80004892e-02, -2.86360495e-02,\n",
      "       -4.42898758e-02,  5.95476758e-03, -3.77223864e-02, -6.14428427e-03,\n",
      "       -5.65263501e-04,  7.61603490e-02, -5.14337718e-02,  1.05173573e-01,\n",
      "        6.12497106e-02, -3.52546051e-02,  1.24058290e-03,  1.21440992e-01,\n",
      "       -8.69830027e-02, -1.31817507e-02, -4.96913381e-02,  1.36392042e-01,\n",
      "        1.09193390e-02, -3.47158313e-02, -5.19061051e-02,  4.26784419e-02,\n",
      "       -3.88353318e-02, -4.73285057e-02, -4.51331539e-03, -1.32969394e-01,\n",
      "        1.65350333e-01,  2.87928525e-02, -6.47710869e-03, -6.69142902e-02,\n",
      "       -1.39069051e-01, -1.87668130e-02,  4.80200946e-02, -4.97959591e-02,\n",
      "       -3.68552692e-02,  5.15506417e-03,  1.25156958e-02, -3.26519869e-02,\n",
      "       -3.14790048e-02, -4.10808343e-03,  3.21092643e-02, -1.04744494e-01,\n",
      "       -5.36454655e-02,  3.13236453e-02, -8.61397199e-03, -4.88758683e-02,\n",
      "       -2.35408489e-02,  1.38444714e-02, -4.25810255e-02,  3.61841768e-02,\n",
      "        1.74055733e-02, -7.15177655e-02, -7.63484389e-02,  2.07678266e-02,\n",
      "       -8.36184472e-02, -6.49427623e-02, -1.07798837e-01,  1.56290606e-02,\n",
      "       -6.07315712e-02,  3.64712328e-02, -1.15295447e-01, -5.35478815e-02,\n",
      "        1.20681360e-01,  3.76648344e-02,  6.12757588e-03,  8.69961455e-02,\n",
      "        5.04068695e-02,  1.21642530e-01,  4.85282540e-02,  6.53527491e-03,\n",
      "       -8.81151110e-03, -1.42488340e-02, -7.64928982e-02, -3.21920551e-02,\n",
      "       -7.79899284e-02,  4.04955186e-02,  1.58822075e-01,  8.84639546e-02,\n",
      "        5.99979311e-02,  1.24244681e-02,  1.27720281e-01, -1.57220196e-02,\n",
      "        4.24952954e-02,  1.64888501e-02, -8.58393013e-02,  3.16257402e-02,\n",
      "        1.35863172e-02,  7.16171600e-03,  7.42430463e-02, -3.22827585e-02,\n",
      "        7.12597892e-02, -4.09192555e-02,  1.37680583e-02,  7.92304799e-02,\n",
      "        1.13170361e-04, -8.36581178e-03,  2.01739315e-02, -4.26713750e-02,\n",
      "       -3.84801775e-02, -3.85225676e-02,  5.41006215e-02, -1.06428571e-01,\n",
      "        6.29269332e-02,  2.84178834e-02, -7.62629807e-02,  4.44372892e-02,\n",
      "       -1.41079305e-02, -9.10345688e-02,  8.87381807e-02,  2.21037474e-02,\n",
      "       -4.16156650e-02,  2.22067069e-02, -7.84171447e-02, -3.23916189e-02,\n",
      "       -1.61637813e-02, -1.66537445e-02, -8.25244710e-02, -2.41577625e-02,\n",
      "        7.57464096e-02,  2.82721650e-02, -1.25605604e-02,  6.80493042e-02,\n",
      "        5.71523458e-02,  5.88956987e-03, -3.70123163e-02,  1.14666209e-01,\n",
      "        1.67176791e-03, -1.99256223e-02, -7.85169099e-03,  1.86320301e-02,\n",
      "        5.47028594e-02, -8.45256727e-04, -8.56769383e-02,  7.62111396e-02,\n",
      "        3.21089253e-02,  5.80850542e-02,  5.66847958e-02, -9.86037701e-02,\n",
      "       -4.76429723e-02, -6.83308346e-03,  1.05174080e-01,  6.86638653e-02,\n",
      "       -9.93395690e-03, -9.26031768e-02, -4.48663235e-02,  5.64816855e-02,\n",
      "        2.75849402e-02,  4.32241783e-02, -5.76546192e-02, -5.36660627e-02,\n",
      "       -5.96532300e-02,  4.72457819e-02,  2.40803510e-02,  4.36107963e-02,\n",
      "        4.54152338e-02,  5.02656996e-02,  1.13523871e-01, -6.46115094e-02,\n",
      "        1.00250125e-01,  7.99082499e-03, -2.41203510e-04,  5.66940829e-02,\n",
      "       -4.57074610e-04,  7.47312733e-05,  1.85828172e-02,  8.70036110e-02,\n",
      "       -3.60717550e-02, -1.63484126e-01,  8.59778672e-02, -3.30788530e-02,\n",
      "        9.87747591e-03, -3.99583839e-02, -6.80181533e-02, -9.89463776e-02,\n",
      "       -1.39795234e-02, -7.67363310e-02,  4.76469509e-02, -1.82769336e-02,\n",
      "       -1.25327772e-02,  6.45054653e-02,  1.61261633e-02,  6.43663555e-02,\n",
      "       -8.66909232e-03, -1.08758295e-02, -7.05068335e-02, -8.40401426e-02,\n",
      "       -8.35407823e-02,  1.05430596e-02,  7.79180378e-02,  2.48619020e-02,\n",
      "       -3.97067517e-03, -1.17501765e-02,  1.97726749e-02,  8.43557641e-02,\n",
      "       -7.94659276e-03, -6.70493469e-02,  2.64021996e-02,  2.04183231e-03,\n",
      "        5.34033142e-02, -4.98340838e-02, -8.97285901e-03, -5.23216426e-02,\n",
      "       -8.76780972e-02,  5.43479547e-02,  2.75515504e-02, -6.20603375e-02,\n",
      "        5.23798950e-02,  2.84289196e-03,  4.00522538e-02,  5.23134246e-02,\n",
      "       -7.63162822e-02,  9.52457488e-02, -8.91874060e-02,  3.67878973e-02,\n",
      "        1.83338579e-02, -1.12692527e-02, -1.64750405e-03,  3.01526468e-02,\n",
      "        1.20832752e-02, -9.12823752e-02,  1.67166535e-02, -1.01370402e-01,\n",
      "       -2.73917150e-02, -9.36780870e-02, -6.24053702e-02, -3.74438986e-02,\n",
      "       -1.81074776e-02,  1.66326966e-02, -8.12974013e-03,  3.09701487e-02,\n",
      "        3.35104130e-02,  6.88851206e-03, -1.91632174e-02,  1.02832340e-01,\n",
      "        1.02008440e-01,  5.56988418e-02,  3.25748473e-02,  1.15679398e-01,\n",
      "        1.41646102e-01,  4.43579070e-02,  4.19447683e-02,  1.06569849e-01,\n",
      "        3.14986855e-02,  2.79464270e-03,  6.06568269e-02,  1.99322775e-02],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "outputs = [layer.output for layer in model.layers] \n",
    "outputs\n",
    "\n",
    "print(model.layers[1].gamma, model.layers[1].beta,)\n",
    "print(model.layers[4].gamma, model.layers[4].beta,)\n",
    "print(model.layers[8].gamma, model.layers[8].beta,)\n",
    "print(model.layers[10].gamma, model.layers[8].beta,)\n",
    "\n",
    "# you need to plot the violin plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Next instead of standard normalization use batch normalization for input layer also and train the network. Plot the distribution of learned batch norm parameters for each layer (including input) using violin plots. Compare the train/test accuracy and loss for the two cases ? Did batch normalization for input layer improve performance ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape[1:])\n",
    "model = Sequential()\n",
    "# model.add(norm_layer)\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(28, 28, 1)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(84, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_4 (Batc  (None, 28, 28, 1)        4         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 48)        38448     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 10, 10, 48)       192       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 48)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               307456    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                21588     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 84)               336       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,858\n",
      "Trainable params: 370,016\n",
      "Non-trainable params: 842\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "599/600 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9701"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e65c5ff338bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       (graph_function,\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.build()\n",
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'], optimizer='adam')\n",
    "model.fit(X_train, Y_train,epochs= 10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'batch_normalization_13/gamma:0' shape=(1,) dtype=float32, numpy=array([0.98208195], dtype=float32)> <tf.Variable 'batch_normalization_13/beta:0' shape=(1,) dtype=float32, numpy=array([0.22662392], dtype=float32)>\n",
      "<tf.Variable 'batch_normalization_14/gamma:0' shape=(32,) dtype=float32, numpy=\n",
      "array([0.7684027 , 0.88733906, 1.0514632 , 1.097466  , 0.6171542 ,\n",
      "       0.70947623, 0.61347353, 1.0506831 , 1.1648184 , 1.082974  ,\n",
      "       0.99188066, 1.0628668 , 0.717255  , 1.2729177 , 0.9211315 ,\n",
      "       0.7427105 , 1.212307  , 0.88963807, 1.0939035 , 0.86567515,\n",
      "       1.1956588 , 0.92124933, 1.2822005 , 0.9025572 , 0.7598906 ,\n",
      "       1.1256709 , 0.92162013, 0.73857   , 0.8399067 , 0.9527584 ,\n",
      "       1.1395913 , 1.0719141 ], dtype=float32)> <tf.Variable 'batch_normalization_14/beta:0' shape=(32,) dtype=float32, numpy=\n",
      "array([ 0.17463677,  0.22006167,  0.08709119,  0.16212058,  0.21278928,\n",
      "        0.02032804,  0.13029206,  0.00379577,  0.07075272,  0.12857544,\n",
      "        0.06798032,  0.04045894, -0.04244972,  0.1599787 ,  0.14815512,\n",
      "        0.10255579,  0.10350142,  0.12733318,  0.16427161,  0.21529149,\n",
      "        0.02571888,  0.07189506,  0.16970775,  0.12017772,  0.06685045,\n",
      "        0.02519489,  0.19782056,  0.15198316,  0.07079856,  0.00702879,\n",
      "       -0.02170487,  0.0300934 ], dtype=float32)>\n",
      "<tf.Variable 'batch_normalization_15/gamma:0' shape=(48,) dtype=float32, numpy=\n",
      "array([0.97868025, 1.184675  , 1.001749  , 1.0792067 , 0.8208872 ,\n",
      "       0.8737642 , 1.2332873 , 0.7772831 , 0.94437796, 1.2036939 ,\n",
      "       0.7648366 , 0.88093776, 0.89308757, 0.9079559 , 0.8087122 ,\n",
      "       0.8309524 , 1.1976584 , 1.0945834 , 0.86989534, 1.1876508 ,\n",
      "       0.72829366, 1.0054003 , 1.0463569 , 1.0551212 , 1.2698152 ,\n",
      "       0.8238721 , 1.0618079 , 0.6769451 , 0.9902702 , 0.9682803 ,\n",
      "       0.77045065, 0.86978596, 0.9033602 , 0.8393826 , 0.6955527 ,\n",
      "       1.2342129 , 0.9391614 , 1.0278925 , 0.9830826 , 1.238535  ,\n",
      "       0.9962876 , 1.0766317 , 0.9714402 , 0.91220397, 0.7961742 ,\n",
      "       0.7433143 , 1.0939136 , 0.96826226], dtype=float32)> <tf.Variable 'batch_normalization_15/beta:0' shape=(48,) dtype=float32, numpy=\n",
      "array([-0.19285858,  0.01205338, -0.11020642, -0.08062796, -0.13060157,\n",
      "       -0.17746505, -0.00501031, -0.11738084, -0.20423162, -0.1050829 ,\n",
      "       -0.18697791, -0.06596903, -0.14372793, -0.05868368, -0.13401827,\n",
      "       -0.10397739, -0.11854552, -0.07724199, -0.11724387,  0.00767785,\n",
      "       -0.11077043, -0.12387305, -0.14708753, -0.11351294, -0.14552438,\n",
      "       -0.10769031, -0.09757254, -0.1445071 , -0.08639237, -0.17308986,\n",
      "       -0.18279721, -0.27495876, -0.06135013, -0.18326488, -0.03436598,\n",
      "       -0.03506614, -0.21237974, -0.01717698, -0.13178118, -0.03260077,\n",
      "       -0.02621838, -0.03864432, -0.11258955, -0.09578408, -0.2378636 ,\n",
      "       -0.15879403, -0.16042693, -0.12857293], dtype=float32)>\n",
      "<tf.Variable 'batch_normalization_16/gamma:0' shape=(256,) dtype=float32, numpy=\n",
      "array([1.0660933 , 0.9170443 , 0.90884894, 0.9873757 , 1.1365017 ,\n",
      "       0.9287208 , 1.0388467 , 1.0310842 , 0.980049  , 0.9715988 ,\n",
      "       1.0741365 , 1.028417  , 1.0273718 , 0.90494967, 1.109945  ,\n",
      "       1.0709468 , 0.9239641 , 1.0162263 , 0.96501327, 0.99702704,\n",
      "       1.0073584 , 1.0216211 , 0.9473775 , 1.0111592 , 0.99220216,\n",
      "       0.9144704 , 1.0058224 , 1.0685076 , 0.7544441 , 0.96087116,\n",
      "       1.0456145 , 1.0619857 , 1.0574684 , 0.89142245, 1.0702398 ,\n",
      "       0.97405505, 0.99947965, 0.9659294 , 1.124553  , 0.9296309 ,\n",
      "       1.0247442 , 0.92393064, 0.96404266, 1.0466827 , 1.0331663 ,\n",
      "       1.1142159 , 0.92723966, 0.97722065, 1.0741175 , 0.9807699 ,\n",
      "       1.0147816 , 1.1109176 , 1.032182  , 1.0223948 , 0.9855255 ,\n",
      "       1.0246742 , 0.9404014 , 0.97094464, 1.0552474 , 1.0087179 ,\n",
      "       0.8561738 , 0.9651203 , 0.9810727 , 1.0594473 , 0.9561602 ,\n",
      "       0.94675094, 1.021943  , 0.938661  , 1.0906937 , 0.88659394,\n",
      "       0.938372  , 0.97144085, 0.99851406, 1.075147  , 1.0071589 ,\n",
      "       1.0445557 , 1.0380926 , 1.0618263 , 1.0881877 , 0.87490356,\n",
      "       1.0078723 , 1.0776494 , 1.0339764 , 1.0498492 , 0.97901183,\n",
      "       0.88917416, 0.9075146 , 0.95966333, 0.9510124 , 1.0822214 ,\n",
      "       0.9517863 , 1.059318  , 0.97905844, 0.89959437, 1.0093343 ,\n",
      "       1.0533895 , 0.93957   , 0.99335223, 1.0123577 , 1.0428706 ,\n",
      "       0.9904632 , 1.039358  , 1.0064204 , 0.9281262 , 0.9689589 ,\n",
      "       0.9362322 , 1.0038347 , 0.955676  , 0.89310324, 0.94718176,\n",
      "       0.90937525, 1.0716683 , 1.0693722 , 0.90251297, 1.0266838 ,\n",
      "       0.959063  , 0.8852469 , 1.1140234 , 0.98412794, 1.0546551 ,\n",
      "       0.87359524, 0.92503   , 1.043202  , 1.1065769 , 1.0239444 ,\n",
      "       0.9661666 , 1.1120923 , 0.95097333, 1.0659904 , 0.94835216,\n",
      "       1.0922925 , 0.9537577 , 1.015726  , 1.005252  , 0.9473441 ,\n",
      "       0.9387158 , 1.0892979 , 1.0672913 , 1.0235146 , 1.0678682 ,\n",
      "       1.0436563 , 1.0257158 , 1.106396  , 0.9516289 , 0.9994826 ,\n",
      "       1.0632826 , 0.94261485, 1.0843962 , 1.0935421 , 0.95515877,\n",
      "       1.0353845 , 0.91754353, 1.0505241 , 0.9539479 , 1.0130547 ,\n",
      "       1.151434  , 1.0166336 , 0.96311283, 0.89156604, 1.071603  ,\n",
      "       1.0015489 , 1.0584235 , 1.0824285 , 1.014992  , 1.0092968 ,\n",
      "       0.957425  , 0.9391883 , 0.9636717 , 1.1029769 , 0.93966335,\n",
      "       1.0197731 , 0.84859926, 1.0058501 , 1.0807675 , 0.9965956 ,\n",
      "       0.8659784 , 1.0605081 , 0.97534066, 1.0349486 , 1.0657656 ,\n",
      "       0.95547146, 1.0041747 , 0.9934951 , 1.0250125 , 0.826404  ,\n",
      "       0.9614446 , 1.030064  , 0.95152414, 0.9258266 , 1.0692778 ,\n",
      "       1.0243435 , 1.0038236 , 0.9656105 , 0.9318929 , 0.98585814,\n",
      "       1.020499  , 0.923824  , 1.0275266 , 0.91551054, 0.95305705,\n",
      "       0.89502794, 0.9748387 , 1.0102412 , 0.91603905, 1.0906566 ,\n",
      "       1.0295026 , 0.8290324 , 1.0654246 , 1.0032355 , 0.9947    ,\n",
      "       0.89235383, 0.94090223, 0.96213484, 0.9749089 , 0.9343342 ,\n",
      "       0.9461266 , 1.0344725 , 1.0981282 , 1.0484973 , 0.9404156 ,\n",
      "       1.005146  , 1.0755404 , 0.8895148 , 1.0411881 , 1.0150672 ,\n",
      "       1.0007681 , 0.86850464, 0.8135221 , 0.9836149 , 0.91228896,\n",
      "       0.9736904 , 1.0898216 , 0.8727604 , 1.018148  , 1.0508294 ,\n",
      "       0.97395056, 0.82930666, 1.0200957 , 1.0047005 , 0.9726573 ,\n",
      "       1.000554  , 1.0212182 , 0.8758174 , 1.0118092 , 1.0405337 ,\n",
      "       0.87494254, 0.9925506 , 1.0520312 , 0.7214294 , 0.9749597 ,\n",
      "       1.0308154 , 0.98674506, 1.0468742 , 0.962417  , 0.9118829 ,\n",
      "       0.9084819 ], dtype=float32)> <tf.Variable 'batch_normalization_16/beta:0' shape=(256,) dtype=float32, numpy=\n",
      "array([ 0.01599485, -0.09615174,  0.13099235, -0.03245079, -0.03535755,\n",
      "       -0.00567647,  0.03668777,  0.01415513,  0.01753747,  0.03253621,\n",
      "        0.00046275,  0.06863657, -0.0196085 , -0.07076807, -0.02152175,\n",
      "        0.05488275,  0.04985791,  0.08081418,  0.00283158,  0.04251508,\n",
      "        0.01839662, -0.12566188,  0.0211706 ,  0.05319939, -0.05498035,\n",
      "        0.00769028, -0.00750571,  0.01903502,  0.02272693, -0.04897824,\n",
      "        0.03007322,  0.01691155,  0.0005548 , -0.05210526, -0.05820794,\n",
      "       -0.03365826, -0.10978393, -0.04401497,  0.03827112, -0.01990583,\n",
      "        0.06395876,  0.00273274, -0.00716603,  0.07166475,  0.03715906,\n",
      "       -0.00224311,  0.09340589, -0.07197052,  0.04007722,  0.03294463,\n",
      "        0.0093836 , -0.06171505, -0.020762  , -0.15055323,  0.08605652,\n",
      "        0.11418784, -0.06652451,  0.01726614,  0.02910066, -0.07856598,\n",
      "        0.02543963,  0.02173922, -0.04523788,  0.07195473,  0.09590658,\n",
      "        0.06374235, -0.09652025,  0.02438764, -0.05770219,  0.08933748,\n",
      "       -0.05862589,  0.09332262,  0.00736841, -0.01533905,  0.03856067,\n",
      "       -0.02025052, -0.02800113,  0.09030038, -0.03773993, -0.03362328,\n",
      "        0.07616101, -0.06695765,  0.10445767,  0.04879902,  0.04270738,\n",
      "       -0.0015355 , -0.06870321,  0.10956708, -0.05655256, -0.02891612,\n",
      "       -0.01825914, -0.08508246,  0.06723762,  0.161248  , -0.01032001,\n",
      "        0.17626506,  0.04146827, -0.05171108,  0.0689138 ,  0.06601501,\n",
      "        0.10350724, -0.06626397, -0.0509937 , -0.00368851,  0.05800221,\n",
      "        0.00915978, -0.00082327,  0.09212032, -0.08861089,  0.07197018,\n",
      "        0.01568068,  0.00768307, -0.03061121, -0.06729957,  0.02388474,\n",
      "        0.03365115, -0.03898388, -0.04814576, -0.07551929, -0.01370111,\n",
      "       -0.02954731, -0.01817862, -0.01781403,  0.07559372,  0.0670484 ,\n",
      "       -0.08832409,  0.00684242,  0.05903317, -0.01537031,  0.02447435,\n",
      "       -0.06167496,  0.03141965, -0.19000335,  0.0400241 , -0.06573994,\n",
      "        0.00135173,  0.03711579, -0.03636789,  0.02401215,  0.02344572,\n",
      "        0.01676196,  0.089991  ,  0.02871907,  0.03415738,  0.06046018,\n",
      "        0.01541316,  0.09415581,  0.02746472,  0.08150887, -0.06050137,\n",
      "        0.02458611,  0.08158021, -0.01010982,  0.07401106,  0.08629516,\n",
      "        0.01158708, -0.02775762, -0.0005892 , -0.0112194 ,  0.03004663,\n",
      "       -0.01709631,  0.01776974,  0.01013958,  0.03403186,  0.02719323,\n",
      "       -0.06185753,  0.015271  ,  0.08375372,  0.04932671,  0.01853449,\n",
      "        0.06523897,  0.05759567, -0.02405054,  0.0308354 , -0.01206898,\n",
      "       -0.09072191, -0.11124308,  0.02379928,  0.04921033, -0.01116371,\n",
      "       -0.10416391,  0.01684851,  0.00817832, -0.11647587,  0.05589106,\n",
      "        0.07171824,  0.00876507,  0.04592235,  0.02854478,  0.13378182,\n",
      "        0.02763339,  0.07368209,  0.05296   ,  0.09332131,  0.01473148,\n",
      "        0.0158813 , -0.01596352,  0.06527202, -0.02125054,  0.0205029 ,\n",
      "        0.05503798,  0.01136723, -0.03343796, -0.01173828, -0.00687679,\n",
      "       -0.05805006,  0.08611648, -0.06907723,  0.06106301,  0.099043  ,\n",
      "       -0.09682676,  0.0694597 ,  0.07533895,  0.07373594,  0.09916917,\n",
      "        0.03244978, -0.05949078, -0.02480996,  0.06988709,  0.04379164,\n",
      "        0.06894753, -0.0036713 ,  0.0499504 , -0.00716837, -0.03109096,\n",
      "       -0.08888605, -0.09712657, -0.04611361,  0.07347612,  0.01234716,\n",
      "        0.08621062, -0.10306616,  0.07320004,  0.08544806,  0.0412693 ,\n",
      "       -0.10200109,  0.13735141,  0.01646421, -0.08994077,  0.02543332,\n",
      "       -0.0568977 ,  0.09273815, -0.02425839, -0.00563821,  0.09721733,\n",
      "        0.03825409,  0.1414642 , -0.02630243,  0.08999954, -0.05611847,\n",
      "        0.0020399 ,  0.02349019,  0.00458808,  0.01639947,  0.13342138,\n",
      "        0.04777889], dtype=float32)>\n",
      "<tf.Variable 'batch_normalization_17/gamma:0' shape=(84,) dtype=float32, numpy=\n",
      "array([1.1579691, 1.1943734, 1.1975459, 1.2613264, 1.0971936, 1.1893657,\n",
      "       1.1450773, 1.1703708, 1.1773008, 1.1887177, 1.2749772, 1.195651 ,\n",
      "       1.1766143, 1.2481016, 1.2734557, 1.1737608, 1.2346674, 1.2466631,\n",
      "       1.1331862, 1.2407787, 1.1747835, 1.2488092, 1.229832 , 1.1846042,\n",
      "       1.2302071, 1.3327177, 1.1786164, 1.3017274, 1.2119738, 1.1286849,\n",
      "       1.3010637, 1.1874877, 1.1876814, 1.2690408, 1.1135353, 1.1511996,\n",
      "       1.091635 , 1.2576141, 1.1374507, 1.1702468, 1.3091933, 1.1567016,\n",
      "       1.3737063, 1.135992 , 1.2105403, 1.1975056, 1.2383281, 1.2310448,\n",
      "       1.2362652, 1.1989764, 1.066973 , 1.1925005, 1.1534735, 1.1372179,\n",
      "       1.1730609, 1.2797205, 1.2723745, 1.1512547, 1.1302158, 1.3395945,\n",
      "       1.2046007, 1.0886171, 1.1372744, 1.1656669, 1.168551 , 1.1463886,\n",
      "       1.1449137, 1.1493063, 1.1729687, 1.3050971, 1.3139416, 1.1998025,\n",
      "       1.2270722, 1.367075 , 1.1482112, 1.2299987, 1.2647716, 1.2090733,\n",
      "       1.1854753, 1.1347891, 1.1685004, 1.2006854, 1.2166839, 1.1415743],\n",
      "      dtype=float32)> <tf.Variable 'batch_normalization_17/beta:0' shape=(84,) dtype=float32, numpy=\n",
      "array([ 9.81136411e-03, -1.18624214e-02, -1.64775439e-02,  1.48216086e-02,\n",
      "        4.15218696e-02,  1.33621478e-02,  9.89993103e-03,  2.10941173e-02,\n",
      "       -1.11111375e-02,  1.44247832e-02,  2.58040372e-02, -2.57676691e-02,\n",
      "        3.51261115e-04,  2.45448258e-02, -3.18305641e-02,  1.15728788e-02,\n",
      "       -4.13239561e-02, -8.90362356e-03, -2.68333238e-02, -1.40773486e-02,\n",
      "       -1.79557351e-03,  3.06089278e-02, -1.07594104e-02,  8.56493600e-03,\n",
      "       -1.36291375e-02,  4.28162403e-02,  1.29233953e-02,  7.06753740e-03,\n",
      "       -1.06938155e-02,  6.99466513e-03, -1.15302144e-04,  4.59227003e-02,\n",
      "       -1.74339842e-02,  3.29663530e-02,  4.71917950e-02,  3.37539762e-02,\n",
      "       -7.70497881e-03,  8.29762663e-04,  5.61186252e-03,  1.62732564e-02,\n",
      "       -1.16109531e-02,  1.41757224e-02, -2.20434237e-02, -6.23091217e-03,\n",
      "        2.90866867e-02,  7.47116702e-03,  5.87632209e-02, -2.84990761e-03,\n",
      "       -5.21844588e-02, -6.31633587e-03,  4.13482673e-02,  4.40179370e-03,\n",
      "       -3.39316018e-03,  2.38621011e-02,  3.63109051e-03,  3.25185098e-02,\n",
      "        4.73111160e-02,  2.24033967e-02, -9.21136962e-05,  1.19039547e-02,\n",
      "       -2.43616588e-02,  2.70282254e-02,  1.92262661e-02,  1.49864340e-02,\n",
      "       -2.88053835e-03,  3.92060131e-02,  3.55557092e-02,  2.05513146e-02,\n",
      "        8.31281580e-03, -3.86631191e-02,  1.40944626e-02,  3.25003336e-03,\n",
      "        4.76247184e-02, -4.81665954e-02, -9.09976941e-03, -9.22639295e-03,\n",
      "       -3.11057456e-02, -6.78555388e-03,  4.00965177e-02, -1.10578407e-02,\n",
      "        1.38166221e-02, -1.23346550e-03,  4.24518064e-03,  1.42191602e-02],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "outputs = [layer.output for layer in model.layers] \n",
    "outputs\n",
    "\n",
    "print(model.layers[0].gamma, model.layers[0].beta,)\n",
    "print(model.layers[2].gamma, model.layers[2].beta,)\n",
    "print(model.layers[5].gamma, model.layers[5].beta,)\n",
    "print(model.layers[9].gamma, model.layers[9].beta,)\n",
    "print(model.layers[11].gamma, model.layers[11].beta,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Train the network without batch normalization but this time use dropout. For hidden layers use dropout probability of 0.5 and for input layer take it to be 0.2 Compare test accuracy using dropout to test accuracy obtained using batch normalization in part 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no batch normal not normalization with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape[1:])\n",
    "model = Sequential()\n",
    "# model.add(norm_layer)\n",
    "model.add(tf.keras.layers.Dropout(0.5,input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_10 (Dropout)        (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 32)        832       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 10, 10, 48)        38448     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 5, 48)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1200)              0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               307456    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 84)                21588     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 84)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 369,174\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "600/600 [==============================] - 40s 66ms/step - loss: 0.1225 - accuracy: 0.9639 - val_loss: 0.0944 - val_accuracy: 0.9800\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 38s 64ms/step - loss: 0.1216 - accuracy: 0.9655 - val_loss: 0.1308 - val_accuracy: 0.9814\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 39s 65ms/step - loss: 0.1130 - accuracy: 0.9666 - val_loss: 0.1036 - val_accuracy: 0.9822\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 38s 64ms/step - loss: 0.1082 - accuracy: 0.9674 - val_loss: 0.0949 - val_accuracy: 0.9840\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.1047 - accuracy: 0.9689 - val_loss: 0.0805 - val_accuracy: 0.9813\n"
     ]
    }
   ],
   "source": [
    "model.build()\n",
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'], optimizer='adam')\n",
    "model_history = model.fit(X_train, Y_train,epochs= 5,batch_size=100,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0805 - accuracy: 0.9813 - 2s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#getting the accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model_history.history['loss'], label='training_loss')\n",
    "plt.plot(model_history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ffe7499b5e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3iklEQVR4nO3deXxW1Z348c+XJBASspCFJGQBqsgSVk1x6bQg/uzgBoob1lq1Vaattlp/ztTamdZxdHSs/bV1tLbUlRmnarFY6s+liCj2V7eg7CiiIiRsIZCNkP37++OcJDchgQd4njxJ+L5fr+eV+9xz7r3nPvDkm7Pcc0RVMcYYY8JhQLQLYIwxpv+woGKMMSZsLKgYY4wJGwsqxhhjwsaCijHGmLCxoGKMMSZsIhpURGSWiHwkIptF5LYu0keIyDIRWSMir4tIXiDtPhFZLyIbReQBERG//3V/zlX+NczvHyQiz/hrvSMiIyN5b8YYYw4WsaAiIjHAQ8A5wHjgChEZ3ynb/cBCVZ0E3Anc4489A/gSMAmYAHwRmB447kpVneJfu/2+bwH7VPVE4BfAf0TmzowxxnQnkjWVacBmVf1UVRuAp4E5nfKMB17z28sD6QrEAwOBQUAcsOsw15sDPOm3FwFntdZujDHG9IzYCJ47F9gWeF8CnNopz2pgLvAr4CIgSUTSVfUtEVkO7AAEeFBVNwaOe1xEmoHngLvUTQvQdj1VbRKRSiAd2BO8oIjMB+YDJCYmnjJ27Niw3KwxxhwvVq5cuUdVM7tKi2RQCcWtwIMicg2wAigFmkXkRGAc0NrHslREvqyqb+KavkpFJAkXVK4CFoZ6QVVdACwAKCoq0uLi4rDdjDHGHA9E5PPu0iLZ/FUK5Afe5/l9bVR1u6rOVdWpwI/9vgpcreVtVa1R1RrgJeB0n17qf1YD/4NrZutwPRGJBVKA8ojcmTHGmC5FMqi8B4wWkVEiMhCYBywJZhCRDBFpLcOPgMf89lZguojEikgcrpN+o3+f4Y+NA84H1vljlgBX++1LgNfUZss0xpgeFbGgoqpNwI3AK8BG4FlVXS8id4rIbJ9tBvCRiGwCsoC7/f5FwCfAWly/y2pV/TOu0/4VEVkDrMLVTn7nj3kUSBeRzcAtwEFDmI0xxkSWHM9/zFufijHGHDkRWamqRV2l2RP1xhhjwsaCijHGmLCxoGKMMSZsov2cijHGHL2G/VC6EravgqxCGDUdYuzXWjTZp2+M6Tuqd8G2t2Grf+1YDdrcnp6YCYUXwYRLIH8a2ExNPc6CijGmd2ppgT2bYOtbsO0d93PfFpcWGw+5p8Df3Qz5p0HOZJdn3SJ4fyG8uwBSCmDCXJh4CWRNsADTQ2xIsQ0pNqZ3aKyD7R8EgsjbUFfh0hIyoOA092oNIrEDuz5PXRV8+H9dgPlkuavJZI51tZeJF0PaF3rslvqrQw0ptqBiQcWY6Nhf3l4D2faOCyjNDS4tfTQUnAoFp7sgkn7C0dU09u+BDc/D2udg69/cvuEnw8RLXTNZck7Ybud4YkGlGxZUjOkhqrD3U98X4oPInk0ubUAcDJ8aqImcCokZ4S9DxTZY/0dYuwh2rgEERv6dax4bNxsS0sJ/zX7Kgko3LKgYEyFNDe4X99a3XCDZ9g7sL3Np8akucLQGkeFTIW5wz5Zvz8cuuKxbBOWbXWA78SxXgxlzDgxM7Nny9DEWVLphQcWYMDlQASXv+SDyDpQWQ1OdSxs60jVhtQaRjDEwoJc8IqcKO1b5APNHqN4OcQkusEy4BE78X9333RzHLKh0w4KKMUdBFSq2tveHbH0Hdm8AFCQGcib5vhBfG0nKjnaJQ9PS4u5n3SJY/zwc2OtqVeNnuwAz8u9gQEy0S9krWFDphgUVY0LQ3AS71nUMItXbXdrAJMj/YnsQySvqH01HzY1u5Ni6RW4kWUMNDMl2nfsTL3HDmY/jIcqHCir2nIoxpqP6aigp9n0hb7vthhqXlpwHI05vDyJZhf3zr/eYODjpq+7VUAsfv+KayIofhXcedk16Ey5xAWbYuGiXtlexmorVVMzxrmp7+xPq296GnWtBWwBxDw0GR2Wl5h/2dP3agQr48AUXYD57w31Owwrd8y8TLnbB5jhgzV/dsKBijjstLVC2sWMQqdjq0uISXLNOwenuGZG8L0J8SnTL25vV7HZ9L2v/ACXvun1501ztpfAiGDIsqsWLpKgFFRGZBfwKiAEeUdV7O6WPwC0hnAnsBb6uqiU+7T7gPNxMykuBm4DBwB+AE4Bm4M+qepvPfw3wM9xqkAAPquojhyqfBRXT7zXUwvb32/tCSt6FukqXNiTLd6b7IJI9yTX7mCO373NY95x77VoHMgBGfcUNUR57PgxOjXYJwyoqQUVEYoBNwNlACW7N+itUdUMgzx+AF1T1SRGZCVyrqleJyBm4APEVn/WvuDXs3wVOVdXlft37ZcC/q+pLPqgUqeqNoZbRgorpd2rKOk24uApamlxa5tiOQWToqOO6szlidm9sfwZm3xaIGQijv+qax06aBQMTol3CYxatjvppwGZV/dQX4mlgDrAhkGc8bj15gOXA835bgXhgICBAHLBLVWt9PlS1QUTeB/IieA/G9F6q7iG+YBDZ+4lLixkEuSfDGd9zz4jkT7MnxnvKsHFw1r/AzH+G0vddcFn3R9cXM3AIjDnX1WBOOLNf1gwjGVRygW2B9yXAqZ3yrAbm4prILgKSRCRdVd8SkeXADlxQeVBVNwYPFJFU4AJ/bKuLReQruBrSD1Q1eP3W4+YD8wEKCgqO/u6M6WlN9W7dkOCEiwf2urTBaa4z/ZSrXRAZPgViB0WztEYE8k5xr6/eBZ//P9f/smEJrH3W/ZuNn+P6YArO6D0PhB6jaA8pvhV40DddrcD1hzSLyInAONprIUtF5Muq+iaAiMQCvwceaK0JAX8Gfq+q9SLyD8CTwMzOF1TVBcACcM1fEbszY45V7V7Y9m57ECl9H5rrXVraCe4v3tZJF9NPtKas3mxAjOtjGfUVOPfn8Mky10S25hlY+Tgk57Y/A5MzpU//W0YyqJQCwfGHebR3ogOgqttxNRVEZAhwsapWiMj1wNuqWuPTXgJOB970hy4APlbVXwbOVR449SPAfWG9G2PCqbkJ9u+Gqh1QHXztdEN8K7e5OakABsS6XzTTrm8f2tuPRxb1e7ED3TQwY85xK1d+9JILMO/8Ft560P3BMPES9xxM5knRLu0Ri2RQeQ8YLSKjcMFkHvC1YAYRyQD2qmoLriP+MZ+0FbheRO7BNX9NB37pj7kLSAGu63SuHFXd4d/OBjo0lxnTI1ThwD4XGKp3dgwYwQBSsxvXdRggMW5Kk6Rs16k++Qo/4eLJ/aJz13RhYKILIBMvcTXTjX92fTBv3Adv/IcbkTfxEtfJn9I3uo8jPaT4XFwwiAEeU9W7ReROoFhVl4jIJcA9uG/XCuAG33wVA/waN/pLgZdV9RYRycP103wI+HYAN3TYB6DZQBNuePJ3VPXDQ5XPRn+ZI9Kwv70mUb3TTVXS4b2vabQ2UQUlpENSjg8aOe6VnNO+nZTjpnvvj0+nmyNXtQPWL3YBpnSl21dwugsuhRdFZmmAI2APP3bDgooB3DxPNbsCNYluAkZ91cHHxiV2Cg7ZXQSMbOs0N0dv76fu+Ze1i6DsQ1ejPeFM1zw29jyIT+7xIllQ6YYFlX6upcWNjurc9BTsu6je6df56PQ9GBAbCBLZkDTc/Uwe3vH9oKQ+3alq+hBV2LXeD1F+zs2EEBvvnoGZeKn7GRffI0WxoNINCyp9WH11F01Pwb4Lv6+l8eBjEzIObnrqHDAS0vvNEE/TD6m69WvWLnLNZPt3w6Bk9/T+xIth1AyIiVyXuQWVblhQ6YWaGqBm52H6LnZCQ/XBxw5M8sGhU8BIDgSOIdm26JLpX5qbYMsKWPuc6+ivr3R/OBVe6GowedPC/geSBZVuWFDpQS0tULunU1NUMGD4fbV7Dj52QFwgOGR3HzAGJfX8fRnTmzTWweZX3UOWm152q2+m5MOEua4PJntiWJprLah0w4JKhNTsdpPq7VoPO/3PPR9Bc0OnjAKJmV33VQQDxuA0a4oy5kjVV8OHL7o+mE9ec3PAZYxpH6KcfsJRn9qCSjcsqByjpnoo+8gFjV3r2gPJ/rL2PEk5biGnYeMgpaBjABmS1S/nPjKm19lfDhv/5PpgPv8boPClm+Hsfz2q09nKj+bYqLomqmDg2LUe9mxqnwE3ZpALHKP/3gWRrEK3wFNienTLboxx38Oib7pXZSms/6ObpSECLKiYjhoPuLHwbU1XPoi0TlwIbknZrEI3zURr8Eg7IaKjTYwxYZKS62avjhD7LXC8UoXKkkDTlf9ZvtkvJQvEDoas8TDufBc4sia494OHRrfsxphey4LK8aBhP+z+EHatbW+62rWufQVAgNQRLmiMvzBQ+xhl04YYY46IBZX+RBUqPm8PHDt9ENn7KW1PjA8cAsPGu9EfrcFj2Dhbi9wYExYWVPqq+mrYtaFjx/mu9YGHAsXVNLIKYdJlvumq0NVIbHiuMSZCLKj0di0tsO+zTsFjnVv7utWgFBcwJs9zP7MnuqnTBw2JWrGNMccnCyq9yYEK2L2hY9PV7g3QWOvSZYAbZTV8Kkz9envtIyXfJjU0xvQKFlSioaUZyj85uPZRua09T3yqq3Gc/I324JE51hZrMsb0ahENKiIyC/gVbpGuR1T13k7pI3CrPWbiFtb6uqqW+LT7gPOAAcBS4CZVVRE5BXgCGAy8GNifBjwDjAS2AJep6r5I3l9Iavce/MT57o1uTh5wayNknOSWiC36pgsg2RPck+hW+zDG9DERCyp+9caHgLOBEuA9EVmiqhsC2e4HFqrqkyIyE7cK5FUicgbwJWCSz/dX3JLCrwMPA9cD7+CCyizgJeA2YJmq3isit/n3P4zU/R2kudE949EaQFrnvKre3p4nIcMFjC9e1/7UecaYHlsDwRhjIi2SNZVpwGZV/RRARJ4G5gDBoDIeuMVvLwee99sKxAMDcWvUxwG7RCQHSFbVt/05FwIX4oLKHGCGP/5JXACKTFCpq4TS9wNNV2vdHFitEyYOiIPMMTDqy+1NV1kTYMgwq30YY/q1SAaVXNx68q1KgFM75VkNzMU1kV0EJIlIuqq+JSLLgR24oPKgqm4UkSJ/nuA5c/12lqru8Ns7gayw3k3Qx0vhuW+57SHZLmh84cz2pqv00bZmhzHmuBTtjvpbgQdF5BpgBVAKNIvIicA4IM/nWyoiXwYOhHJS38fS5fTLIjIfmA9QUFBwdKUeNR2+8Sc/YWLG0Z3DGGP6oUg+BVcK5Afe5/l9bVR1u6rOVdWpwI/9vgpcreVtVa1R1Rpc89bp/vi8bs7Z2jyG/7m7q0Kp6gJVLVLVoszMzKO7syGZ8IUZFlCMMaaTSAaV94DRIjJKRAYC84AlwQwikiEirWX4EW4kGMBWYLqIxIpIHK6TfqNv3qoSkdNERIBvAH/yxywBrvbbVwf2G2OM6SERCyqq2gTcCLwCbASeVdX1InKniMz22WYAH4nIJlwfyN1+/yLgE2Atrt9ltar+2ad9F3gE2OzzvOT33wucLSIfA//LvzfGGNODbOVHW/nRGGOOyKFWfrSZBY0xxoSNBRVjjDFhY0HFGGNM2FhQMcYYEzYWVIwxxoSNBRVjjDFhY0HFGGNM2FhQMcYYEzYWVIwxxoSNBRVjjDFhY0HFGGNM2FhQMcYYEzYWVIwxxoSNBRVjjDFhY0HFGGNM2FhQMcYYEzYRDSoiMktEPhKRzSJyWxfpI0RkmYisEZHXRSTP7z9TRFYFXnUicqFPezOwf7uIPO/3zxCRykDaTyJ5b8YYYw4WG6kTi0gM8BBwNlACvCciS1R1QyDb/cBCVX1SRGYC9wBXqepyYIo/Txpu6eC/AKjqlwPXeI6Oa9G/qarnR+qejDHGHFokayrTgM2q+qmqNgBPA3M65RkPvOa3l3eRDnAJ8JKq1gZ3ikgyMBN4PpyFNsYYc/QiGVRygW2B9yV+X9BqYK7fvghIEpH0TnnmAb/v4vwXAstUtSqw73QRWS0iL4lIYVeFEpH5IlIsIsVlZWUh3ooxxphQRLuj/lZguoh8AEwHSoHm1kQRyQEmAq90cewVdAw27wMjVHUy8J90U4NR1QWqWqSqRZmZmWG5CWOMMU4kg0opkB94n+f3tVHV7ao6V1WnAj/2+yoCWS4DFqtqY/A4EcnANa/938C5qlS1xm+/CMT5fMYYY3pIJIPKe8BoERklIgNxzVhLghlEJENEWsvwI+CxTufoXBtpdQnwgqrWBc6VLSLit6fh7q08LHdijDEmJBELKqraBNyIa7raCDyrqutF5E4Rme2zzQA+EpFNQBZwd+vxIjISV9N5o4vTd9XPcgmwTkRWAw8A81RVw3dHxhhjDkeO59+7RUVFWlxcHO1iGGNMnyIiK1W1qKu0aHfUG2OM6UcsqBhjjAkbCyrGGGPCxoKKMcaYsLGgYowxJmwsqBhjjAkbCyrGGGPCxoKKMcaYsLGgYowxJmwOG1RE5ILA/FzGGGNMt0IJFpcDH4vIfSIyNtIFMsYY03cdNqio6teBqcAnwBMi8pZf6Cop4qUzxhjTp4TUrOVXV1yEWxI4B7dK4/si8r0Ils0YY0wfE0qfymwRWQy8DsQB01T1HGAy8L8jWzxjjDF9SWwIeS4GfqGqK4I7VbVWRL4VmWIZY4zpi0Jp/roDeLf1jYgM9gtooarLDnWgiMwSkY9EZLOI3NZF+ggRWSYia0TkdRHJ8/vPFJFVgVediFzo054Qkc8CaVP8fhGRB/y11ojIyaF9BMYYY8IllKDyB6Al8L7Z7zskEYkBHgLOAcYDV4jI+E7Z7gcWquok4E7gHgBVXa6qU1R1CjATqAX+EjjuH1vTVXWV33cOMNq/5gMPh3BvxhhjwiiUoBKrqg2tb/z2wBCOmwZsVtVP/TFPA3M65RkPvOa3l3eRDm6Z4JdUtfYw15uDC1Cqqm8DqSKSE0I5jTHGhEkoQaUssKY8IjIH2BPCcbnAtsD7Er8vaDUw129fBCSJSHqnPF2tR3+3b+L6hYgMOoLrGWOMiaBQgsq3gdtFZKuIbAN+CPxDmK5/KzBdRD4ApgOluOY1AHxNYyLwSuCYHwFjgS8Cab48IfPP2BSLSHFZWdkxFt8YY0zQYUd/qeonwGkiMsS/rwnx3KVAfuB9nt8XPPd2fE3Fn/9iVa0IZLkMWKyqjYFjdvjNehF5HBeYQrqeP34BsACgqKhIQ7wXY4wxIQhlSDEich5QCMSLCACqeudhDnsPGC0io3C/3OcBX+t03gxgr6q24Gogj3U6xxV+f/CYHFXdIa4gFwLrfNIS4EYReRo4FagMBCBjjDE94LBBRUR+AyQAZwKP4DrO3z3kQYCqNonIjbimqxjgMVVdLyJ3AsWqugSYAdwjIgqsAG4IXHckrubxRqdTPyUimYAAq3DNcwAvAucCm3Gjxa49XBmNMcaEl6geugVIRNao6qTAzyG40Vhf7pkiRk5RUZEWFxdHuxjGGNOniMhKVS3qKi2Ujvo6/7NWRIYDjbj5v4wxxpgOQulT+bOIpAI/A94HFPhdJAtljDGmbzpkUPGLcy3zI7KeE5EXgHhVreyJwhljjOlbDtn85UdlPRR4X28BxRhjTHdC6VNZJiIXS+tYYmOMMaYboQSVf8BNIFkvIlUiUi0iVREulzHGmD4olCfqbdlgY4wxIQnl4cevdLW/86JdxhhjTChDiv8xsB2Pm9J+JW6dE2OMMaZNKM1fFwTfi0g+8MtIFcgYY0zfFUpHfWclwLhwF8QYY0zfF0qfyn/inqIHF4Sm4J6sN8YYYzoIpU8lOONiE/B7Vf1/ESqPMcaYPiyUoLIIqFPVZgARiRGRhBDWjDfGGHOcCemJemBw4P1g4NXIFMcYY0xfFkpQiQ8uIey3EyJXJGOMMX1VKEFlv4ic3PpGRE4BDoRychGZJSIfichmEbmti/QRIrJMRNaIyOsikuf3nykiqwKvOhG50Kc95c+5TkQeE5E4v3+GiFQGjvlJKGU0xhgTPqH0qdwM/EFEtuOW8M0GLj/cQSISg5vh+GzcMOT3RGSJqm4IZLsfWKiqT4rITOAe4CpVXY4bZYaIpOGWCP6LP+Yp4Ot++3+A64CH/fs3VfX8EO7JGGNMBITy8ON7IjIWGON3faSqjSGcexqwWVU/BRCRp4E5QDCojAdu8dvLgee7OM8luOWLa315XmxNEJF3gbwQymKMMaYHHLb5S0RuABJVdZ2qrgOGiMh3Qzh3LrAt8L7E7wtaDcz12xcBSSKS3inPPOD3XZQrDrgKeDmw+3QRWS0iL4lIYTf3M19EikWkuKysLITbMMYYE6pQ+lSu9ys/AqCq+4Drw3T9W4HpIvIBMB0oBZpbE0UkB5gIvNLFsb8GVqjqm/79+8AIVZ0M/Cdd13pQ1QWqWqSqRZmZmWG6DWOMMRBaUIkJLtDl+0oGhnBcKZAfeJ/n97VR1e2qOldVpwI/9vsqAlkuAxZ3bm4TkZ8CmbQ3naGqVa2j1HwTWZyIZIRQTmOMMWESSlB5GXhGRM4SkbNwTVEvhXDce8BoERklIgNxzVhLghlEJENEWsvwI+CxTue4gk5NXyJyHfD3wBV+uePW/dmtwU9Epvl7Kw+hnMYYY8IklKDyQ+A14Nv+tZaOD0N2SVWbgBtxTVcbgWdVdb2I3Ckis322GcBHIrIJyALubj1eREbiajpvdDr1b3zetzoNHb4EWCciq4EHgHmqqhhjjOkxEsrvXRGZCnwN1xz1KfCcqj4Y4bJFXFFRkRYXFx8+ozHGmDYislJVi7pK63ZIsYichGt+ugLYAzwDoKpnRqKQxhhj+r5DPafyIfAmcL6qbgYQkR/0SKmMMcb0SYfqU5kL7ACWi8jvfCe9HCK/McaY41y3QUVVn1fVecBY3NPuNwPDRORhEflqD5XPGGNMH3LY0V+qul9V/8evVZ8HfIAbEWaMMcZ0cERr1KvqPv9E+lmRKpAxxpi+64iCijHGGHMoFlSMMcaEjQUVY4wxYWNBxRhjTNhYUDHGGBM2FlSMMcaEjQUVY4wxYWNBxRhjTNhYUDHGGBM2EQ0qIjJLRD4Skc0iclsX6SNEZJmIrBGR10Ukz+8/0y/A1fqqE5ELfdooEXnHn/MZv6okIjLIv9/s00dG8t6MMcYcLGJBxa9l/xBwDjAeuEJExnfKdj+wUFUnAXcC9wCo6nJVnaKqU4CZQC3wF3/MfwC/UNUTgX3At/z+bwH7/P5f+HzGGGN6UCRrKtOAzar6qao2AE8DczrlGY9bqhjcTMid08EtE/ySqtb6NehnAot82pPAhX57jn+PTz+rdc16Y4wxPSOSQSUX2BZ4X+L3Ba3GrdsCcBGQJCLpnfLMA37vt9OBClVt6uKcbdfz6ZU+vzHGmB4S7Y76W4HpIvIBMB0oBZpbE0UkB5gIvBKuC4rIfBEpFpHisrKycJ3WGGMMkQ0qpUB+4H2e39dGVber6lxVnQr82O+rCGS5DFisqo3+fTmQKiKtyyAHz9l2PZ+e4vN34KfuL1LVoszMzGO4PWOMMZ1FMqi8B4z2o7UG4pqxlgQziEiGiLSW4UfAY53OcQXtTV+oquL6Xi7xu64G/uS3l/j3+PTXfH5jjDE9JGJBxfdr3IhrutoIPKuq60XkThGZ7bPNAD4SkU1AFnB36/F+SHA+8EanU/8QuEVENuP6TB71+x8F0v3+W4CDhjAbY4yJLDme/5gvKirS4uLiaBfDGGP6FBFZqapFXaVFu6PeGGNMP2JBxRhjTNhYUDHGGBM2FlSMMcaETezhsxhjjOkPGptb+HhXDeu2V3JC5hBOGTE07NewoGKMMf1QXWMzm3ZVs660inXbK1lXWsmHO6tpaGoB4JozRlpQMcYYc7DahiY27qhyAaS0knXbq/h4VzVNLe6RkeT4WCbkpnDNGSMpHJ7MhNwURqUnRqQsFlSMMaYPqaprZMN2FzzW+5+flNXg4wfpiQMpzE1h5thMJgxPYUJuCnlDB9NTk7ZbUDHGmF5q3/4G33TlmrDWl1aypby2LT07OZ4JucmcOzGHCbkpTMhNJjs5vscCSFcsqBhjTC+wu7qO9W3NVy6QlFYcaEvPGzqYCcNTuLQon8LhyRQOTyEzaVAUS9w1CyrGGNODVJUdlXUuePj+j3Wlleyurm/L84WMRE4eMZRvnD6CCbkpFA5PJjVhYBRLHToLKsYYEyGqyta9tR1GYK3fXsXe/Q0ADBA4cdgQ/u7EDApzU5iYm8K4nCSS4uOiXPKjZ0HFGGPCoLlF+WzPftb74LHWB5DqOrdQbVyMcFJWEmePy2JCbjKFuSmMy05m8MCYKJc8vCyoGGPMEWpsbmHz7poOI7A27KiitsEtXDswdgDjcpKZPXk4E3wNZHTWEAbF9q8A0hULKsYYcwj1Tc1s2lnT1ny1rrSSjYGHCBMGxlA4PJnLivLbRmCdkDmEuJjjcxYsCyrGGOMdaGhmw46qtiasdaVVbAo8RJgUH8uE4Slc7TvQJ+SmMDI9kZgB0RvC29tENKiIyCzgV0AM8Iiq3tspfQRuCeFMYC/wdVUt8WkFwCO41R8VOFdVt4jIm0CSP8Uw4F1VvVBEZuCWFv7Mp/1RVe+M4O0ZY/qw6taHCLdXsd73gQQfIkxLHMiE3BRmjMl0AWR4CvlpPfcQYV8VsaAiIjHAQ8DZQAnwnogsUdUNgWz3AwtV9UkRmQncA1zl0xYCd6vqUhEZArQAqOqXA9d4jvY16gHeVNXzI3VPxpi+ad/+Btf3ERiB9dme/W3pWcmDmDA8hXMm5jDBT2OSkxLdhwj7qkjWVKYBm1X1UwAReRqYAwSDynjcevIAy4Hnfd7xQKyqLgVQ1ZrOJxeRZGAmcG2Eym+M6YPKquvbnj5vHcpbsu/ghwgvPjmXQv8MyLCk+CiWuH+JZFDJBbYF3pcAp3bKsxqYi2siuwhIEpF04CSgQkT+CIwCXgVuU9XmwLEXAstUtSqw73QRWQ1sB25V1fWdCyUi84H5AAUFBUd/d8aYqFBV9u5vYGdVHTsr69hZVcf2igN8uKOaddsr2VXV/hDhqIxEpuSn8vXTRjBhuAsgQxP7xkOEfVW0O+pvBR4UkWuAFUAp0Iwr15eBqcBW4BngGuDRwLFX4PpcWr0PjFDVGhE5F1frGd35gqq6AFgAUFRUpGG9G2PMMWlqbmF3dX17wPBBo8N2VV3byKtWAwROyBzCGSdk+P6PZMYPT+7TDxH2VZEMKqW4TvZWeX5fG1Xdjqup4PtNLlbVChEpAVYFms6eB07DBxURycA1r10UOFdVYPtFEfm1iGSo6p4I3Jsx5ggdaGhmZ1UdOyoPsKuqjh2Vdeyq9D/9+z019W0d5a0Gxg4gJyWerOR4phakkp0cT3ZKfPvPlHgyhwwi9jgdwtvbRDKovAeMFpFRuGAyD/haMIMPDntVtQX4EW4kWOuxqSKSqapluL6T4sChlwAvqGpd4FzZwC5VVRGZhlsquTwyt2aMaaWqVB5o9AHj4EDR+rPyQONBxybFx5KTEk92ymDGZCeRnTKY7OT4tiCSkxJPakKcdZj3IRELKqraJCI3Aq/ghhQ/pqrrReROoFhVlwAzgHtERHHNXzf4Y5tF5FZgmbj/TSuB3wVOPw/oMDwZF2i+IyJNwAFgnqpa85Yxx6C5RdlTU8+O1uanygPsrKr3P9ubpOoaOzZHiUDGkEFkJ8eTn5bAF0emtdUuclLiyfLbiYOi3QJvwk2O59+7RUVFWlxcfPiMxvRDdY3N7K6qZ0enABH8ubu6nuZO7VFxMdJWi+j4czDZKYPIThnMsKRBx+0T5ccDEVmpqkVdpdmfCcb0M6pKdX1Te+e2DxKdm6RaZ8oNShwYQ3aKCxBnnJDRVqvICfRfpCUMZIA9QW66YUHFmD6kpUUp398QqE0cOChg7Kysa5vYMCg9cSDZKfEMT4nn5GCHd0p7bSPao6UaGxspKSmhrq7u8JlNxMXHx5OXl0dcXOj/LyyoGNOLVB5oZGt5LZ/v3c9O3+EdHFK7u7qOxuaOzVGxA4RhSYPITolnbHYSM04a1tYMleP7LoYlD+oTM+SWlJSQlJTEyJEjrXM+ylSV8vJySkpKGDVqVMjHWVAxpgepKrur6/m8vJbPy/ezdW8tW8pr2Vq+n8/31lJR23GE1OC4mLZaxKmj0lxTVKAvIzs5nvQhg/rNhIZ1dXUWUHoJESE9PZ2ysrIjOs6CijFh1tTcQmnFARc49tby+R4XMLaW17J1by0HGtubpgYI5A4dzIi0RM6bmMOI9AQK0hIZkZ7A8NTBJMfHHne/YI+3++3NjubfwoKKMUfhQEOzr2Xsb2uucrWPWkorDnQYMTUodkBbsPi70RmMSE9gRHoiI9ISyB062EZJmX7Fgoox3aiobWBLazNVa62j3AWP3dX1HfKmDI5jRHoCk/JSuGByTlvQGJGeyLCkQTZayhw3LKiY41ZLi7Kruo7Py13T1Jby9maqz8v3U+XXFm+VlTyIEWmJfOWkTEamJ1DQFjgSSE2wSQrNkWlqaiI2tv/9Cu5/d2RMQEOT699oa6Yqr2Xr3v1sKa9l295a6gMTE8YOENe/ke5mtnVNVq62UZCWwOCBvX/0VH/yr39ez4btVYfPeATGD0/mpxcUHjbfhRdeyLZt26irq+Omm25i/vz5vPzyy9x+++00NzeTkZHBsmXLqKmp4Xvf+x7FxcWICD/96U+5+OKLGTJkCDU1bsWORYsW8cILL/DEE09wzTXXEB8fzwcffMCXvvQl5s2bx0033URdXR2DBw/m8ccfZ8yYMTQ3N/PDH/6Ql19+mQEDBnD99ddTWFjIAw88wPPPPw/A0qVL+fWvf83ixYvD+hkdKwsqps/bX9/UFiw+79RMtb3iQIcJCgfHxTAiPYEvZCRy5phMCtITGZmewIi0RIanxtukhAaAxx57jLS0NA4cOMAXv/hF5syZw/XXX8+KFSsYNWoUe/fuBeDf/u3fSElJYe3atQDs27fvsOcuKSnhb3/7GzExMVRVVfHmm28SGxvLq6++yu23385zzz3HggUL2LJlC6tWrSI2Npa9e/cydOhQvvvd71JWVkZmZiaPP/443/zmNyP6ORwNCyqm12tdP6O1aWpLhz6OWvbUdOzfGJoQR0F6IicXDGXu1FzXTJWewIi0BDKTBtnooj4ilBpFpDzwwANtNYBt27axYMECvvKVr7Q9r5GWlgbAq6++ytNPP9123NChQw977ksvvZSYGFfrrays5Oqrr+bjjz9GRGhsbGw777e//e225rHW61111VX893//N9deey1vvfUWCxcuDNMdh48FFdMrNLcoO6vq2obfdqh5lNdSU9+xfyMnJZ6CtATOGjuMgvQEHzQSKUhPIGWwraFhjt7rr7/Oq6++yltvvUVCQgIzZsxgypQpfPjhhyGfI/iHS+fZARITE9u2/+Vf/oUzzzyTxYsXs2XLFmbMmHHI81577bVccMEFxMfHc+mll/bKPpneVyLTb9U3NbNt74EOweJz3zlesvcADc3t/RtxMUL+0AQK0hMoGjG0rVN8ZEYCeUMTiI+z/g0TGZWVlQwdOpSEhAQ+/PBD3n77berq6lixYgWfffZZW/NXWloaZ599Ng899BC//OUvAdf8NXToULKysti4cSNjxoxh8eLFJCUldXut3NxcAJ544om2/WeffTa//e1vOfPMM9uav9LS0hg+fDjDhw/nrrvu4tVXX430R3FULKiYiKiua2RtaSWrt1WyelsFa0sr2V55gOCk2IkDYyhIT+SkYUmcPS7LDcP1nePDUwf3m6fETd8ya9YsfvOb3zBu3DjGjBnDaaedRmZmJgsWLGDu3Lm0tLQwbNgwli5dyj//8z9zww03MGHCBGJiYvjpT3/K3Llzuffeezn//PPJzMykqKiordO+s3/6p3/i6quv5q677uK8885r23/dddexadMmJk2aRFxcHNdffz033ngjAFdeeSVlZWWMGzeuRz6PI2VT39vU98esoamFD3dWsbrEBZDV2yrYXFbTFkBGpCcwMTeFEzKH+Af/3IOAGUMGWv+G6WDjxo299pdlb3HjjTcydepUvvWtb/XI9br6N7Gp703YtLQoW8r3s7qkgtXbKlm1rYINO6ra1gxPTxzIlPxUzp80nMn5KUzOS2Vooj3DYUw4nHLKKSQmJvLzn/882kXpVkSDiojMAn6FW/nxEVW9t1P6CNwSwpnAXuDrqlri0wqAR3Dr3CtwrqpuEZEngOlApT/NNaq6yq8Q+SvgXKDW738/kvd3PNhdXdfWhOUCSUXbQ4GD42KYmJfCNWeMZHJeKpPzU8hNHWy1D2MiZOXKldEuwmFFLKiISAzwEHA2UAK8JyJLVHVDINv9wEJVfVJEZgL3AFf5tIXA3aq6VESGAMH1Sv9RVRd1uuQ5wGj/OhV42P80Iaqpb2JtSWVb8Fi9rYLtlW7kSswAYUxWEudNGs6U/BQm56dyYuYQe67DGNNBJGsq04DNqvopgIg8DcwBgkFlPHCL314OPO/zjgdiVXUpgKp23cvV0RxcgFLgbRFJFZEcVd0RjpvpbxqbW/hoZzWrfPBYXVLBx7vb+0EK0hI4ZWQa38xLYUp+KoXDU+yJcmPMYUUyqOQC2wLvSzi45rAamItrtroISBKRdOAkoEJE/giMAl4FblPV1jnD7xaRnwDL/P76bq6XC3QIKiIyH5gPUFBQcKz32CeoKlvKa1m9rcIFkZIK1m9v7wdJSxzI5LwUzp2Yw+T8VCbnpZJm/SDGmKMQ7Y76W4EHReQaYAVQCjTjyvVlYCqwFXgGuAZ4FPgRsBMYCCwAfgjcGeoFVXWBP46ioqJ+OfStrLq+rfaxalsFa0oqqTzgntQdHBfDxNwUrj59RFsAyRtq/SDGmPCIZFApxXWyt8rz+9qo6nZcTQXfb3KxqlaISAmwKtB09jxwGvBooDmrXkQexwWmkK7XH+2vb/LPg1S0jcgqrTgAuAWgxmQnc+7EbN+RnsroYdYPYoyJnEgGlfeA0SIyCvfLfR7wtWAGEckA9qpqC64G8ljg2FQRyVTVMmAmUOyPyVHVHX6014XAOn/MEuBG33dzKlDZ3/pTWvtB2jvSK/l4d3XbhIn5aYOZWpDKtV8ayeT8VAqHJ5MwMNqVUWP6r+BsxMaJ2G8cVW0SkRuBV3BDih9T1fUicidQrKpLgBnAPSKiuOavG/yxzSJyK7DMB4+VwO/8qZ8SkUxAgFXAt/3+F3HDiTfjhhRfG6l76wmqyufltW1NWKu3uX6Q1qnahybEMTk/lVkTspmSn8qkvBTShwyKcqmNCaOXboOda8N7zuyJcM69h8/Xx/SmtVkiWgpVfRH3yz647yeB7UVA56HBrWlLgUld7J/ZTX7FB6W+aE9Nfdsw3lUllawpqaCi1vWDxMcNYGJuCled5vpBpuRbP4gxkXDbbbeRn5/PDTe4XyV33HEHsbGxLF++nH379tHY2Mhdd93FnDlzDnuumpoa5syZ0+VxCxcu5P7770dEmDRpEv/1X//Frl27+Pa3v82nn34KwMMPP8zw4cM5//zzWbfONcjcf//91NTUcMcdd7RNdPnXv/6VK664gpNOOom77rqLhoYG0tPTeeqpp8jKyupyzZfKykrWrFnTNmfZ7373OzZs2MAvfvGLY/4Me0doO87sr29iXWllh6fSg/0gJ2UlMaswu60j/aQs6wcxx6Eo1Cguv/xybr755rag8uyzz/LKK6/w/e9/n+TkZPbs2cNpp53G7NmzD/tHXXx8PIsXLz7ouA0bNnDXXXfxt7/9jYyMjLa1Wb7//e8zffp0Fi9eTHNzMzU1NYddn6WhoYHWqab27dvH22+/jYjwyCOPcN999/Hzn/+8yzVf4uLiuPvuu/nZz35GXFwcjz/+OL/97W+P9eMDLKhEXGNzC5t2VXd4Kn3TrvZ+kLyhg5lSkOqeSs9PZUKu9YMYEy1Tp05l9+7dbN++nbKyMoYOHUp2djY/+MEPWLFiBQMGDKC0tJRdu3aRnZ19yHOpKrfffvtBx7322mtceumlZGRkAO1rpbz22mtt66PExMSQkpJy2KBy+eWXt22XlJRw+eWXs2PHDhoaGtrWfuluzZeZM2fywgsvMG7cOBobG5k4ceIRflpds99eYaSqbN1b6/tAXBPWuu2V1DW6fpDUhDgm56Xy1cJspuSnMCkvlQzrBzGmV7n00ktZtGgRO3fu5PLLL+epp56irKyMlStXEhcXx8iRIw9aI6UrR3tcUGxsLC0t7ZOJHGptlu9973vccsstzJ49m9dff5077rjjkOe+7rrr+Pd//3fGjh3LtdeGrwvagsoxKK+p9x3p7bWQ1n6QQbGuH+TKU1ufB0mhIC3B+kGM6eUuv/xyrr/+evbs2cMbb7zBs88+y7Bhw4iLi2P58uV8/vnnIZ2nsrKyy+NmzpzJRRddxC233EJ6enrbWilnnXUWDz/8MDfffHNb81dWVha7d++mvLycIUOG8MILLzBr1qxur9e6NsuTTz7Ztr+7NV9OPfVUtm3bxvvvv8+aNWuO4RPryILKUXjtw1385E/rKdnXsR/k78f7fpD8FE7KSiLO+kGM6XMKCwuprq4mNzeXnJwcrrzySi644AImTpxIUVERY8eODek83R1XWFjIj3/8Y6ZPn05MTAxTp07liSee4Fe/+hXz58/n0UcfJSYmhocffpjTTz+dn/zkJ0ybNo3c3NxDXvuOO+7g0ksvZejQocycOZPPPvsMoNs1XwAuu+wyVq1aFdIyyKGy9VSOYj2VdaWVPPz6J21Tu0/ITSFxkMVnY46VrafSs84//3x+8IMfcNZZZ3Wbx9ZT6QETclN46MqTo10MY4w5KhUVFUybNo3JkycfMqAcDQsqxhhzDNauXctVV13VYd+gQYN45513olSiw0tNTWXTpk0RObcFFWNMr6KqfWpAy8SJE1m1alW0ixERR9M9Yj3JxpheIz4+nvLy8qP6ZWbCS1UpLy8nPj7+iI6zmooxptfIy8ujpKSEsrKyaBfF4IJ8Xl7eER1jQcUY02vExcW1PQlu+iZr/jLGGBM2FlSMMcaEjQUVY4wxYXNcP1EvImVAaBP5HCwD2BPG4oRLby0X9N6yWbmOjJXryPTHco1Q1cyuEo7roHIsRKS4u2kKoqm3lgt6b9msXEfGynVkjrdyWfOXMcaYsLGgYowxJmwsqBy9BdEuQDd6a7mg95bNynVkrFxH5rgql/WpGGOMCRurqRhjjAkbCyrGGGPCxoLKYYjILBH5SEQ2i8htXaQPEpFnfPo7IjKyl5TrGhEpE5FV/nVdD5XrMRHZLSLrukkXEXnAl3uNiPTIamchlGuGiFQGPq+f9ECZ8kVkuYhsEJH1InJTF3l6/PMKsVw9/nn568aLyLsistqX7V+7yNPj38kQyxWt72SMiHwgIi90kRb+z0pV7dXNC4gBPgG+AAwEVgPjO+X5LvAbvz0PeKaXlOsa4MEofGZfAU4G1nWTfi7wEiDAacA7vaRcM4AXevizygFO9ttJwKYu/h17/PMKsVw9/nn56wowxG/HAe8Ap3XKE43vZCjlitZ38hbgf7r694rEZ2U1lUObBmxW1U9VtQF4GpjTKc8c4Em/vQg4SyK/wlAo5YoKVV0B7D1EljnAQnXeBlJFJKcXlKvHqeoOVX3fb1cDG4HcTtl6/PMKsVxR4T+HGv82zr86jzbq8e9kiOXqcSKSB5wHPNJNlrB/VhZUDi0X2BZ4X8LBX662PKraBFQC6b2gXAAX+yaTRSKSH+EyhSrUskfD6b754iURKezJC/tmh6m4v3CDovp5HaJcEKXPyzfnrAJ2A0tVtdvPrAe/k6GUC3r+O/lL4J+Alm7Sw/5ZWVDpv/4MjFTVScBS2v8aMV17Hzef0WTgP4Hne+rCIjIEeA64WVWreuq6h3OYckXt81LVZlWdAuQB00RkQk9d+1BCKFePfidF5Hxgt6qujOR1OrOgcmilQPCviTy/r8s8IhILpADl0S6Xqparar1/+whwSoTLFKpQPtMep6pVrc0XqvoiECciGZG+rojE4X5xP6Wqf+wiS1Q+r8OVK1qfV6cyVADLgVmdkqLxnTxsuaLwnfwSMFtEtuCayGeKyH93yhP2z8qCyqG9B4wWkVEiMhDXkbWkU54lwNV++xLgNfW9XtEsV6d299m4dvHeYAnwDT+q6TSgUlV3RLtQIpLd2pYsItNw342I/iLy13sU2Kiq/6ebbD3+eYVSrmh8Xv5amSKS6rcHA2cDH3bK1uPfyVDK1dPfSVX9karmqepI3O+I11T1652yhf2zsuWED0FVm0TkRuAV3Iirx1R1vYjcCRSr6hLcl++/RGQzriN4Xi8p1/dFZDbQ5Mt1TaTLBSAiv8eNDMoQkRLgp7hOS1T1N8CLuBFNm4Fa4NpeUq5LgO+ISBNwAJjXA38cfAm4Cljr2+IBbgcKAuWKxucVSrmi8XmBG5n2pIjE4ALZs6r6QrS/kyGWKyrfyc4i/VnZNC3GGGPCxpq/jDHGhI0FFWOMMWFjQcUYY0zYWFAxxhgTNhZUjDHGhI0FFWMiSESaA7PSrpIuZpQ+hnOPlG5mXTYmWuw5FWMi64CfusOY44LVVIyJAhHZIiL3ichacetwnOj3jxSR1/ykg8tEpMDvzxKRxX4Cx9UicoY/VYyI/E7cGh5/8U9zGxM1FlSMiazBnZq/Lg+kVarqROBB3Gyy4CZnfNJPOvgU8IDf/wDwhp/A8WRgvd8/GnhIVQuBCuDiiN6NMYdhT9QbE0EiUqOqQ7rYvwWYqaqf+skbd6pquojsAXJUtdHv36GqGSJSBuQFJiRsnZZ+qaqO9u9/CMSp6l09cGvGdMlqKsZEj3azfSTqA9vNWD+piTILKsZEz+WBn2/57b/RPqnflcCbfnsZ8B1oWwwqpacKacyRsL9qjImswYGZfgFeVtXWYcVDRWQNrrZxhd/3PeBxEflHoIz2WYlvAhaIyLdwNZLvAFFfMsCYzqxPxZgo8H0qRaq6J9plMSacrPnLGGNM2FhNxRhjTNhYTcUYY0zYWFAxxhgTNhZUjDHGhI0FFWOMMWFjQcUYY0zY/H8gKFBFknsACQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['accuracy'], label='accuracy')\n",
    "plt.plot(model_history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. Now train the network using both batch normalization and dropout. How does the performance (test accuracy) of the network compare with the cases with dropout alone and with batch normalization alone ? \n",
    "\n",
    "add batch any case\n",
    "batch normalizaiotn and dropout. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0f08725565d2d00e70b9fae99b105541271f7be4baa13607a6e77e1d2c8c73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
