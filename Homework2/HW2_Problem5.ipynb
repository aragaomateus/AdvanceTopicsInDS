{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 - Weight Initialization, Dead Neurons, Leaky ReLU\n",
    "\n",
    "Read the two blogs, one by Andre Pernunicic and other by Daniel Godoy on weight initialization. You will reuse the code at github repo linked in the blog for explaining vanishing and exploding gradients. You can use the same 5 layer neural network model as in the repo and the same dataset.\n",
    "\n",
    "• Andre Perunicic. Understand neural network weight initialization. Available at https://intoli.com/blog/neural-network-initialization/\n",
    "• Daniel Godoy. Hyper-parameters in Action Part II — Weight Initializers.\n",
    "• Initializers - Keras documentation. https://keras.io/initializers/.\n",
    "• Lu Lu et al. Dying ReLU and Initialization: Theory and Numerical Examples ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \n",
    "Explain vanishing gradients phenomenon using standard normalization with different values of standard deviation as given in the reference. Train the model with tanh and sigmoid activation functions. Next, show how Xavier (aka Glorot normal) initialization of weights helps in dealing with this problem. You should plot the gradients at each of the 5 layers for all 4 experiments to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain vanishing gradients phenomenon using standard normalization with different values of standard deviation as given in the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (2.10.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Users/aragaom/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tensorflow in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.23.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: packaging in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (21.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Users/aragaom/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: deepreplay in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (0.1.2a2)\n",
      "Requirement already satisfied: seaborn in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from deepreplay) (0.11.2)\n",
      "Requirement already satisfied: numpy in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from deepreplay) (1.23.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from deepreplay) (0.23.2)\n",
      "Requirement already satisfied: h5py in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from deepreplay) (2.10.0)\n",
      "Requirement already satisfied: matplotlib in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from deepreplay) (3.5.3)\n",
      "Requirement already satisfied: keras in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from deepreplay) (2.10.0)\n",
      "Requirement already satisfied: six in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from h5py->deepreplay) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->deepreplay) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->deepreplay) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->deepreplay) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->deepreplay) (8.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->deepreplay) (4.33.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->deepreplay) (21.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->deepreplay) (1.3.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->deepreplay) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->deepreplay) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->deepreplay) (0.17.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from seaborn->deepreplay) (1.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/aragaom/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn->deepreplay) (2020.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Users/aragaom/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting utils\n",
      "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Users/aragaom/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install keras\n",
    "! pip install tensorflow\n",
    "! pip install deepreplay\n",
    "! pip install utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Godoys tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_model(n_layers, input_dim, units, activation, initializer):\n",
    "    if isinstance(units, list):\n",
    "        assert len(units) == n_layers\n",
    "    else:\n",
    "        units = [units] * n_layers\n",
    "        \n",
    "    model = Sequential()\n",
    "    # Adds first hidden layer with input_dim parameter\n",
    "    model.add(Dense(units=units[0], \n",
    "                    input_dim=input_dim, \n",
    "                    activation=activation,\n",
    "                    kernel_initializer=initializer, \n",
    "                    name='h1'))\n",
    "    \n",
    "    # Adds remaining hidden layers\n",
    "    for i in range(2, n_layers + 1):\n",
    "        model.add(Dense(units=units[i-1], \n",
    "                        activation=activation, \n",
    "                        kernel_initializer=initializer, \n",
    "                        name='h{}'.format(i)))\n",
    "    \n",
    "    # Adds output layer\n",
    "    model.add(Dense(units=1, activation='sigmoid', kernel_initializer=initializer, name='o'))\n",
    "    # Compiles the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deepreplay.datasets.ball import load_data\n",
    "\n",
    "X, y = load_data(n_dims=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal initializer and sigmoid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create group (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-083604e93bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Since we only need initial weights, we don't even need to train the model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# We still use the ReplayData callback, but we can pass the model as argument instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mreplaydata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Now we feed the data to the actual Replay object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/deepreplay/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, targets, filename, group_name, model)\u001b[0m\n\u001b[1;32m     60\u001b[0m             })\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_init'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/deepreplay/callbacks.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_group\u001b[0;34m(self, name, track_order)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mgcpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcpl_crt_order\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrack_order\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mgid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mGroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create group (name already exists)"
     ]
    }
   ],
   "source": [
    "from deepreplay.callbacks import ReplayData\n",
    "from deepreplay.replay import Replay\n",
    "from deepreplay.plot import compose_plots\n",
    "from keras.initializers import normal\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "filename = 'part2_weight_initializers.h5'\n",
    "group_name = 'sigmoid_stdev_0.01'\n",
    "\n",
    "# Uses normal initializer\n",
    "initializer = normal(mean=0, stddev=0.01, seed=13)\n",
    "\n",
    "# Builds BLOCK model\n",
    "model = build_model(n_layers=5, input_dim=10, units=100, \n",
    "                    activation='sigmoid', initializer=initializer)\n",
    "\n",
    "# Since we only need initial weights, we don't even need to train the model! \n",
    "# We still use the ReplayData callback, but we can pass the model as argument instead\n",
    "replaydata = ReplayData(X, y, filename=filename, group_name=group_name, model=model)\n",
    "\n",
    "# Now we feed the data to the actual Replay object\n",
    "# so we can build the visualizations\n",
    "replay = Replay(replay_filename=filename, group_name=group_name)\n",
    "\n",
    "# Using subplot2grid to assemble a complex figure...\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax_zvalues = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax_weights = plt.subplot2grid((2, 2), (0, 1))\n",
    "ax_activations = plt.subplot2grid((2, 2), (1, 0))\n",
    "ax_gradients = plt.subplot2grid((2, 2), (1, 1))\n",
    "\n",
    "wv = replay.build_weights(ax_weights)\n",
    "gv = replay.build_gradients(ax_gradients)\n",
    "# Z-values\n",
    "zv = replay.build_outputs(ax_zvalues, before_activation=True, \n",
    "                          exclude_outputs=True, include_inputs=False)\n",
    "# Activations\n",
    "av = replay.build_outputs(ax_activations, exclude_outputs=True, include_inputs=False)\n",
    "\n",
    "# Finally, we use compose_plots to update all\n",
    "# visualizations at once\n",
    "fig = compose_plots([zv, wv, av, gv], \n",
    "                    epoch=0, \n",
    "                    title=r'Activation: sigmoid - Initializer: Normal $\\sigma = 0.01$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal initializer and tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glorot and sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glorot and tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"model\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(10000, 784), dtype=float32, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-dfddbdd359f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0moutput_elts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mi_output_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AdvanceTopicsInDS/Homework2/functions.py\u001b[0m in \u001b[0;36mget_activations\u001b[0;34m(model, x, mode)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0moutput_elts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput_elts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4630\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4631\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;34mf'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;34mf\" but it received {len(inputs)} input tensors. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer \"model\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(10000, 784), dtype=float32, numpy=\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>]"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras import initializers\n",
    "from keras.datasets import mnist\n",
    "import functions as u\n",
    "# from utils import (\n",
    "#     compile_model,\n",
    "#     create_mlp_model,\n",
    "#     get_activations,\n",
    "#     grid_axes_it,\n",
    "# )\n",
    "\n",
    "\n",
    "seed = 10\n",
    "\n",
    "# Number of points to plot\n",
    "n_train = 1000\n",
    "n_test = 100\n",
    "n_classes = 10\n",
    "\n",
    "# Network params\n",
    "n_hidden_layers = 5\n",
    "dim_layer = 100\n",
    "batch_size = n_train\n",
    "epochs = 1\n",
    "\n",
    "# Load and prepare MNIST dataset.\n",
    "n_train = 60000\n",
    "n_test = 10000\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "num_classes = len(np.unique(y_test))\n",
    "data_dim = 28 * 28\n",
    "\n",
    "x_train = x_train.reshape(60000, 784).astype('float32')[:n_train]\n",
    "x_test = x_test.reshape(10000, 784).astype('float32')[:n_train]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Run the data through a few MLP models and save the activations from\n",
    "# each layer into a Pandas DataFrame.\n",
    "rows = []\n",
    "sigmas = [0.10, 0.14, 0.28]\n",
    "for stddev in sigmas:\n",
    "    init = initializers.RandomNormal(mean=0.0, stddev=stddev, seed=seed)\n",
    "    activation = 'relu'\n",
    "\n",
    "    model = u.create_mlp_model(\n",
    "        n_hidden_layers,\n",
    "        dim_layer,\n",
    "        (data_dim,),\n",
    "        n_classes,\n",
    "        init,\n",
    "        'zeros',\n",
    "        activation\n",
    "    )\n",
    "    u.compile_model(model)\n",
    "    output_elts = u.get_activations(model, x_test)\n",
    "    n_layers = len(model.layers)\n",
    "    i_output_layer = n_layers - 1\n",
    "\n",
    "    for i, out in enumerate(output_elts[:-1]):\n",
    "        if i > 0 and i != i_output_layer:\n",
    "            for out_i in out.ravel()[::20]:\n",
    "                rows.append([i, stddev, out_i])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['Hidden Layer', 'Standard Deviation', 'Output'])\n",
    "\n",
    "# Plot previously saved activations from the 5 hidden layers\n",
    "# using different initialization schemes.\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "axes = u.grid_axes_it(len(sigmas), 1, fig=fig)\n",
    "for sig in sigmas:\n",
    "    ax = next(axes)\n",
    "    ddf = df[df['Standard Deviation'] == sig]\n",
    "    sns.violinplot(x='Hidden Layer', y='Output', data=ddf, ax=ax, scale='count', inner=None)\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "\n",
    "    ax.set_title('Weights Drawn from $N(\\mu = 0, \\sigma = {%.2f})$' % sig, fontsize=13)\n",
    "\n",
    "    if sig == sigmas[1]:\n",
    "        ax.set_ylabel(\"ReLu Neuron Outputs\")\n",
    "    if sig != sigmas[-1]:\n",
    "        ax.set_xticklabels(())\n",
    "    else:\n",
    "        ax.set_xlabel(\"Hidden Layer\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    " The dying ReLU is a kind of vanishing gradient, which refers to a problem when ReLU neurons become\n",
    "inactive and only output 0 for any input. In the worst case of dying ReLU, ReLU neurons at a certain\n",
    "layer are all dead, i.e., the entire network dies and is referred as the dying ReLU neural networks in\n",
    "Lu et al (reference below). A dying ReLU neural network collapses to a constant function. Show this\n",
    "phenomenon using any one of the three 1-dimensional functions in page 13 of Lu et al. Use a ReLU\n",
    "network with 10 hidden layers, each of width 2 (hidden units per layer). Use minibatch of 64 and draw\n",
    "training data uniformly from [sqrt(− 7),sqrt() 7]. Perform 1000 independent training simulations each with\n",
    "3,000 training points. Out of these 1000 simulations, what fraction resulted in neural network collapse. Is your answer close to over 90% as was reported in Lu et al.? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Suppose f (x) = |x| is a target function we want to approximate using a ReLU network. \n",
    "Since |x|=ReLU(x)+ReLU(−x), a 2-layer ReLU network of width 2 can exactly represent |x|. \n",
    "However, when we train a deep ReLU network, we frequently observe\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    " Instead of ReLU consider Leaky ReLU activation as defined below: 􏰀 z ifz>0\n",
    " References:\n",
    "φ(z)= 0.01z ifz≤0.\n",
    "Run the 1000 training simulations in part 2 with Leaky ReLU activation and keeping everything else same. Again calculate the fraction of simulations that resulted in neural network collapse. Did Leaky ReLU help in preventing dying neurons ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0f08725565d2d00e70b9fae99b105541271f7be4baa13607a6e77e1d2c8c73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
